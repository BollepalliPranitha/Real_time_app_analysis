2025-05-08 04:58:15,939 - INFO - Callback Server Starting
2025-05-08 04:58:15,940 - INFO - Socket listening on ('127.0.0.1', 40411)
2025-05-08 04:58:19,539 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 04:58:23,358 - INFO - Closing down clientserver connection
2025-05-08 04:59:37,914 - INFO - Callback Server Starting
2025-05-08 04:59:37,919 - INFO - Socket listening on ('127.0.0.1', 37843)
2025-05-08 04:59:39,738 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 04:59:44,219 - INFO - Closing down clientserver connection
2025-05-08 05:00:57,568 - INFO - Callback Server Starting
2025-05-08 05:00:57,644 - INFO - Socket listening on ('127.0.0.1', 36649)
2025-05-08 05:01:00,461 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:01:05,671 - INFO - Closing down clientserver connection
2025-05-08 05:02:12,213 - INFO - Callback Server Starting
2025-05-08 05:02:12,296 - INFO - Socket listening on ('127.0.0.1', 32969)
2025-05-08 05:02:14,822 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:02:20,509 - INFO - Closing down clientserver connection
2025-05-08 05:03:29,875 - INFO - Callback Server Starting
2025-05-08 05:03:29,951 - INFO - Socket listening on ('127.0.0.1', 43711)
2025-05-08 05:03:32,161 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:03:35,064 - INFO - Closing down clientserver connection
2025-05-08 05:04:41,699 - INFO - Callback Server Starting
2025-05-08 05:04:41,701 - INFO - Socket listening on ('127.0.0.1', 38143)
2025-05-08 05:04:43,690 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:04:46,919 - INFO - Closing down clientserver connection
2025-05-08 05:05:54,261 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 05:05:54,265 - INFO - Closing down clientserver connection
2025-05-08 05:05:54,267 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 05:05:54,335 - INFO - Closing down clientserver connection
2025-05-08 05:05:54,339 - INFO - Closing down clientserver connection
2025-05-08 05:07:58,843 - INFO - Callback Server Starting
2025-05-08 05:07:58,844 - INFO - Socket listening on ('127.0.0.1', 41735)
2025-05-08 05:08:01,435 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:08:12,235 - INFO - Closing down clientserver connection
2025-05-08 05:09:19,490 - INFO - Callback Server Starting
2025-05-08 05:09:19,491 - INFO - Socket listening on ('127.0.0.1', 35263)
2025-05-08 05:09:21,361 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:09:33,295 - INFO - Closing down clientserver connection
2025-05-08 05:10:41,340 - INFO - Callback Server Starting
2025-05-08 05:10:41,341 - INFO - Socket listening on ('127.0.0.1', 32873)
2025-05-08 05:10:43,418 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:10:55,128 - INFO - Closing down clientserver connection
2025-05-08 05:11:35,366 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 05:11:35,372 - INFO - Closing down clientserver connection
2025-05-08 05:11:35,374 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 05:11:35,380 - INFO - Closing down clientserver connection
2025-05-08 05:11:35,382 - INFO - Closing down clientserver connection
2025-05-08 05:13:14,016 - INFO - Callback Server Starting
2025-05-08 05:13:14,017 - INFO - Socket listening on ('127.0.0.1', 40319)
2025-05-08 05:13:16,312 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:13:26,422 - INFO - Closing down clientserver connection
2025-05-08 05:15:57,324 - INFO - Callback Server Starting
2025-05-08 05:15:57,332 - INFO - Socket listening on ('127.0.0.1', 34685)
2025-05-08 05:16:02,834 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:16:10,232 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 05:16:10,236 - INFO - Closing down clientserver connection
2025-05-08 05:16:10,237 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 05:16:10,251 - INFO - Closing down clientserver connection
2025-05-08 05:16:10,254 - INFO - Closing down clientserver connection
2025-05-08 05:16:21,043 - INFO - Closing down clientserver connection
2025-05-08 05:17:08,355 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 05:17:08,360 - INFO - Closing down clientserver connection
2025-05-08 05:17:08,362 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 05:17:08,367 - INFO - Closing down clientserver connection
2025-05-08 05:17:08,371 - INFO - Closing down clientserver connection
2025-05-08 05:19:16,935 - INFO - Callback Server Starting
2025-05-08 05:19:16,936 - INFO - Socket listening on ('127.0.0.1', 44849)
2025-05-08 05:19:19,535 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:19:31,259 - INFO - Closing down clientserver connection
2025-05-08 05:20:40,099 - INFO - Callback Server Starting
2025-05-08 05:20:40,101 - INFO - Socket listening on ('127.0.0.1', 42441)
2025-05-08 05:20:41,489 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:20:52,784 - INFO - Closing down clientserver connection
2025-05-08 05:21:56,026 - INFO - Callback Server Starting
2025-05-08 05:21:56,028 - INFO - Socket listening on ('127.0.0.1', 41867)
2025-05-08 05:21:58,029 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:22:10,062 - INFO - Closing down clientserver connection
2025-05-08 05:23:10,476 - INFO - Callback Server Starting
2025-05-08 05:23:10,478 - INFO - Socket listening on ('127.0.0.1', 39903)
2025-05-08 05:23:12,282 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:23:25,391 - INFO - Closing down clientserver connection
2025-05-08 05:24:23,598 - INFO - Callback Server Starting
2025-05-08 05:24:23,607 - INFO - Socket listening on ('127.0.0.1', 35167)
2025-05-08 05:24:25,916 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:24:50,722 - INFO - Python Server ready to receive messages
2025-05-08 05:24:50,725 - INFO - Received command c on object id p0
2025-05-08 05:24:56,224 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:25:07,627 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 207, in process_batch
    .withColumn("Hour", hour(to_timestamp(col("WatchTime"), "HH:mm:ss"))) \
NameError: name 'to_timestamp' is not defined
2025-05-08 05:25:08,422 - INFO - Closing down clientserver connection
2025-05-08 05:26:13,764 - INFO - Callback Server Starting
2025-05-08 05:26:13,766 - INFO - Socket listening on ('127.0.0.1', 37619)
2025-05-08 05:26:16,465 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:26:33,681 - INFO - Python Server ready to receive messages
2025-05-08 05:26:33,683 - INFO - Received command c on object id p0
2025-05-08 05:26:39,377 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:26:49,897 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 207, in process_batch
    .withColumn("Hour", hour(to_timestamp(col("WatchTime"), "HH:mm:ss"))) \
NameError: name 'to_timestamp' is not defined
2025-05-08 05:26:52,176 - INFO - Closing down clientserver connection
2025-05-08 05:27:16,216 - INFO - Closing down clientserver connection
2025-05-08 05:27:16,294 - INFO - Closing down clientserver connection
2025-05-08 05:28:28,267 - INFO - Callback Server Starting
2025-05-08 05:28:28,268 - INFO - Socket listening on ('127.0.0.1', 38915)
2025-05-08 05:28:30,769 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:28:49,152 - INFO - Python Server ready to receive messages
2025-05-08 05:28:49,152 - INFO - Received command c on object id p0
2025-05-08 05:28:54,746 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:29:06,171 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 207, in process_batch
    .withColumn("Hour", hour(to_timestamp(col("WatchTime"), "HH:mm:ss"))) \
NameError: name 'to_timestamp' is not defined
2025-05-08 05:29:07,911 - INFO - Closing down clientserver connection
2025-05-08 05:29:54,480 - INFO - Callback Server Starting
2025-05-08 05:29:54,481 - INFO - Socket listening on ('127.0.0.1', 41021)
2025-05-08 05:29:55,821 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:30:06,701 - INFO - Python Server ready to receive messages
2025-05-08 05:30:06,702 - INFO - Received command c on object id p0
2025-05-08 05:30:10,100 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:30:12,209 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 05:30:12,210 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 05:30:12,212 - INFO - Closing down clientserver connection
2025-05-08 05:30:12,213 - INFO - Closing down clientserver connection
2025-05-08 05:30:12,214 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 05:30:12,215 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 05:30:12,218 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 204, in process_batch
    existing_time_df = spark.read.format("snowflake").options(**snowflake_options).option("dbtable", "PUBLIC.DIM_TIME").load().select("WatchTime")
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 307, in load
    return self._df(self._jreader.load())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 169, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o312.load
2025-05-08 05:30:12,220 - INFO - Closing down clientserver connection
2025-05-08 05:31:22,849 - INFO - Callback Server Starting
2025-05-08 05:31:22,850 - INFO - Socket listening on ('127.0.0.1', 33403)
2025-05-08 05:31:25,147 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:31:38,652 - INFO - Python Server ready to receive messages
2025-05-08 05:31:38,653 - INFO - Received command c on object id p0
2025-05-08 05:31:42,836 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:31:49,383 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 207, in process_batch
    .withColumn("Hour", hour(to_timestamp(col("WatchTime"), "HH:mm:ss"))) \
NameError: name 'to_timestamp' is not defined
2025-05-08 05:31:50,539 - INFO - Closing down clientserver connection
2025-05-08 05:32:29,791 - INFO - Callback Server Starting
2025-05-08 05:32:29,792 - INFO - Socket listening on ('127.0.0.1', 37415)
2025-05-08 05:32:31,194 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:32:41,705 - INFO - Python Server ready to receive messages
2025-05-08 05:32:41,706 - INFO - Received command c on object id p0
2025-05-08 05:32:45,669 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:32:54,799 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 207, in process_batch
    .withColumn("Hour", hour(to_timestamp(col("WatchTime"), "HH:mm:ss"))) \
NameError: name 'to_timestamp' is not defined
2025-05-08 05:32:56,105 - INFO - Closing down clientserver connection
2025-05-08 05:33:35,127 - INFO - Callback Server Starting
2025-05-08 05:33:35,129 - INFO - Socket listening on ('127.0.0.1', 42297)
2025-05-08 05:33:36,433 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:33:47,610 - INFO - Python Server ready to receive messages
2025-05-08 05:33:47,611 - INFO - Received command c on object id p0
2025-05-08 05:33:51,407 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:33:57,932 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 207, in process_batch
    .withColumn("Hour", hour(to_timestamp(col("WatchTime"), "HH:mm:ss"))) \
NameError: name 'to_timestamp' is not defined
2025-05-08 05:33:59,232 - INFO - Closing down clientserver connection
2025-05-08 05:34:20,349 - INFO - Closing down clientserver connection
2025-05-08 05:35:30,553 - INFO - Callback Server Starting
2025-05-08 05:35:30,572 - INFO - Socket listening on ('127.0.0.1', 44421)
2025-05-08 05:35:32,469 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:35:49,169 - INFO - Python Server ready to receive messages
2025-05-08 05:35:49,170 - INFO - Received command c on object id p0
2025-05-08 05:35:56,069 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:36:07,697 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 207, in process_batch
    .withColumn("Hour", hour(to_timestamp(col("WatchTime"), "HH:mm:ss"))) \
NameError: name 'to_timestamp' is not defined
2025-05-08 05:36:09,675 - INFO - Closing down clientserver connection
2025-05-08 05:36:56,626 - INFO - Callback Server Starting
2025-05-08 05:36:56,629 - INFO - Socket listening on ('127.0.0.1', 43921)
2025-05-08 05:36:57,816 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:37:10,834 - INFO - Python Server ready to receive messages
2025-05-08 05:37:10,835 - INFO - Received command c on object id p0
2025-05-08 05:37:16,823 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:37:23,997 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 207, in process_batch
    .withColumn("Hour", hour(to_timestamp(col("WatchTime"), "HH:mm:ss"))) \
NameError: name 'to_timestamp' is not defined
2025-05-08 05:37:25,324 - INFO - Closing down clientserver connection
2025-05-08 05:38:09,142 - INFO - Callback Server Starting
2025-05-08 05:38:09,145 - INFO - Socket listening on ('127.0.0.1', 40329)
2025-05-08 05:38:10,825 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:38:17,225 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 05:38:17,228 - INFO - Closing down clientserver connection
2025-05-08 05:38:17,229 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 05:38:17,233 - INFO - Closing down clientserver connection
2025-05-08 05:38:17,235 - INFO - Closing down clientserver connection
2025-05-08 05:40:01,189 - INFO - Callback Server Starting
2025-05-08 05:40:01,190 - INFO - Socket listening on ('127.0.0.1', 37507)
2025-05-08 05:40:02,702 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:40:17,697 - INFO - Python Server ready to receive messages
2025-05-08 05:40:17,699 - INFO - Received command c on object id p0
2025-05-08 05:40:23,499 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:40:36,909 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 207, in process_batch
    .withColumn("Hour", hour(to_timestamp(col("WatchTime"), "HH:mm:ss"))) \
NameError: name 'to_timestamp' is not defined
2025-05-08 05:40:38,730 - INFO - Closing down clientserver connection
2025-05-08 05:41:30,333 - INFO - Callback Server Starting
2025-05-08 05:41:30,336 - INFO - Socket listening on ('127.0.0.1', 32791)
2025-05-08 05:41:33,853 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:41:47,438 - INFO - Python Server ready to receive messages
2025-05-08 05:41:47,439 - INFO - Received command c on object id p0
2025-05-08 05:41:50,648 - INFO - Processing batch 0 with 0 rows
2025-05-08 05:42:00,478 - ERROR - There was an exception while executing the Python Proxy on the Python Side.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
    return_value = getattr(self.pool[obj_id], method)(*params)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 114, in call
    raise e
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 111, in call
    self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
  File "/app/scripts/stream_video_interactions.py", line 207, in process_batch
    .withColumn("Hour", hour(to_timestamp(col("WatchTime"), "HH:mm:ss"))) \
NameError: name 'to_timestamp' is not defined
2025-05-08 05:42:02,652 - INFO - Closing down clientserver connection
2025-05-08 05:42:50,154 - INFO - Callback Server Starting
2025-05-08 05:42:50,155 - INFO - Socket listening on ('127.0.0.1', 46713)
2025-05-08 05:42:51,950 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 05:42:51,953 - INFO - Closing down clientserver connection
2025-05-08 05:42:51,955 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 05:42:51,960 - INFO - Closing down clientserver connection
2025-05-08 05:42:51,968 - INFO - Closing down clientserver connection
2025-05-08 05:43:42,101 - DEBUG - Starting stream_video_interactions.py
2025-05-08 05:43:42,103 - DEBUG - Loading configurations
2025-05-08 05:43:42,110 - DEBUG - Configurations loaded
2025-05-08 05:43:42,111 - DEBUG - Initializing Spark session
2025-05-08 05:43:42,177 - DEBUG - GatewayClient.address is deprecated and will be removed in version 1.0. Use GatewayParameters instead.
2025-05-08 05:43:42,179 - DEBUG - Command to send: A
f67d3b1654e5b044a251a3e954a411c08b73739f136cc057d3e3a2e2e3fa4889

2025-05-08 05:43:42,286 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,290 - DEBUG - Command to send: j
i
rj
org.apache.spark.SparkConf
e

2025-05-08 05:43:42,296 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,297 - DEBUG - Command to send: j
i
rj
org.apache.spark.api.java.*
e

2025-05-08 05:43:42,298 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,299 - DEBUG - Command to send: j
i
rj
org.apache.spark.api.python.*
e

2025-05-08 05:43:42,300 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,301 - DEBUG - Command to send: j
i
rj
org.apache.spark.ml.python.*
e

2025-05-08 05:43:42,303 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,304 - DEBUG - Command to send: j
i
rj
org.apache.spark.mllib.api.python.*
e

2025-05-08 05:43:42,305 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,307 - DEBUG - Command to send: j
i
rj
org.apache.spark.resource.*
e

2025-05-08 05:43:42,308 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,309 - DEBUG - Command to send: j
i
rj
org.apache.spark.sql.*
e

2025-05-08 05:43:42,310 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,310 - DEBUG - Command to send: j
i
rj
org.apache.spark.sql.api.python.*
e

2025-05-08 05:43:42,311 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,312 - DEBUG - Command to send: j
i
rj
org.apache.spark.sql.hive.*
e

2025-05-08 05:43:42,313 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,314 - DEBUG - Command to send: j
i
rj
scala.Tuple2
e

2025-05-08 05:43:42,315 - DEBUG - Answer received: !yv
2025-05-08 05:43:42,316 - DEBUG - Command to send: r
u
SparkConf
rj
e

2025-05-08 05:43:42,320 - DEBUG - Answer received: !ycorg.apache.spark.SparkConf
2025-05-08 05:43:42,321 - DEBUG - Command to send: i
org.apache.spark.SparkConf
bTrue
e

2025-05-08 05:43:42,383 - DEBUG - Answer received: !yro0
2025-05-08 05:43:42,385 - DEBUG - Command to send: c
o0
set
sspark.app.name
sStreamVideoInteractions
e

2025-05-08 05:43:42,395 - DEBUG - Answer received: !yro1
2025-05-08 05:43:42,396 - DEBUG - Command to send: c
o0
set
sspark.sql.shuffle.partitions
s1
e

2025-05-08 05:43:42,397 - DEBUG - Answer received: !yro2
2025-05-08 05:43:42,399 - DEBUG - Command to send: c
o0
set
sspark.streaming.stopGracefullyOnShutdown
strue
e

2025-05-08 05:43:42,400 - DEBUG - Answer received: !yro3
2025-05-08 05:43:42,401 - DEBUG - Command to send: c
o0
contains
sspark.serializer.objectStreamReset
e

2025-05-08 05:43:42,406 - DEBUG - Answer received: !ybfalse
2025-05-08 05:43:42,407 - DEBUG - Command to send: c
o0
set
sspark.serializer.objectStreamReset
s100
e

2025-05-08 05:43:42,408 - DEBUG - Answer received: !yro4
2025-05-08 05:43:42,409 - DEBUG - Command to send: c
o0
contains
sspark.rdd.compress
e

2025-05-08 05:43:42,410 - DEBUG - Answer received: !ybfalse
2025-05-08 05:43:42,411 - DEBUG - Command to send: c
o0
set
sspark.rdd.compress
sTrue
e

2025-05-08 05:43:42,412 - DEBUG - Answer received: !yro5
2025-05-08 05:43:42,412 - DEBUG - Command to send: c
o0
contains
sspark.master
e

2025-05-08 05:43:42,414 - DEBUG - Answer received: !ybtrue
2025-05-08 05:43:42,414 - DEBUG - Command to send: c
o0
contains
sspark.app.name
e

2025-05-08 05:43:42,416 - DEBUG - Answer received: !ybtrue
2025-05-08 05:43:42,417 - DEBUG - Command to send: c
o0
contains
sspark.master
e

2025-05-08 05:43:42,418 - DEBUG - Answer received: !ybtrue
2025-05-08 05:43:42,421 - DEBUG - Command to send: c
o0
get
sspark.master
e

2025-05-08 05:43:42,424 - DEBUG - Answer received: !yslocal[*]
2025-05-08 05:43:42,425 - DEBUG - Command to send: c
o0
contains
sspark.app.name
e

2025-05-08 05:43:42,426 - DEBUG - Answer received: !ybtrue
2025-05-08 05:43:42,427 - DEBUG - Command to send: c
o0
get
sspark.app.name
e

2025-05-08 05:43:42,428 - DEBUG - Answer received: !ysStreamVideoInteractions
2025-05-08 05:43:42,477 - DEBUG - Command to send: c
o0
contains
sspark.home
e

2025-05-08 05:43:42,478 - DEBUG - Answer received: !ybfalse
2025-05-08 05:43:42,479 - DEBUG - Command to send: c
o0
getAll
e

2025-05-08 05:43:42,481 - DEBUG - Answer received: !yto6
2025-05-08 05:43:42,482 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,483 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,484 - DEBUG - Command to send: a
g
o6
i0
e

2025-05-08 05:43:42,485 - DEBUG - Answer received: !yro7
2025-05-08 05:43:42,485 - DEBUG - Command to send: c
o7
_1
e

2025-05-08 05:43:42,491 - DEBUG - Answer received: !ysspark.sql.shuffle.partitions
2025-05-08 05:43:42,492 - DEBUG - Command to send: c
o7
_2
e

2025-05-08 05:43:42,495 - DEBUG - Answer received: !ys1
2025-05-08 05:43:42,495 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,496 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,497 - DEBUG - Command to send: a
g
o6
i1
e

2025-05-08 05:43:42,498 - DEBUG - Answer received: !yro8
2025-05-08 05:43:42,499 - DEBUG - Command to send: c
o8
_1
e

2025-05-08 05:43:42,500 - DEBUG - Answer received: !ysspark.streaming.stopGracefullyOnShutdown
2025-05-08 05:43:42,501 - DEBUG - Command to send: c
o8
_2
e

2025-05-08 05:43:42,502 - DEBUG - Answer received: !ystrue
2025-05-08 05:43:42,505 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,506 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,507 - DEBUG - Command to send: a
g
o6
i2
e

2025-05-08 05:43:42,509 - DEBUG - Answer received: !yro9
2025-05-08 05:43:42,510 - DEBUG - Command to send: c
o9
_1
e

2025-05-08 05:43:42,512 - DEBUG - Answer received: !ysspark.rdd.compress
2025-05-08 05:43:42,512 - DEBUG - Command to send: c
o9
_2
e

2025-05-08 05:43:42,514 - DEBUG - Answer received: !ysTrue
2025-05-08 05:43:42,515 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,516 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,517 - DEBUG - Command to send: a
g
o6
i3
e

2025-05-08 05:43:42,518 - DEBUG - Answer received: !yro10
2025-05-08 05:43:42,519 - DEBUG - Command to send: c
o10
_1
e

2025-05-08 05:43:42,521 - DEBUG - Answer received: !ysspark.app.submitTime
2025-05-08 05:43:42,522 - DEBUG - Command to send: c
o10
_2
e

2025-05-08 05:43:42,523 - DEBUG - Answer received: !ys1746683019404
2025-05-08 05:43:42,524 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,525 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,526 - DEBUG - Command to send: a
g
o6
i4
e

2025-05-08 05:43:42,528 - DEBUG - Answer received: !yro11
2025-05-08 05:43:42,528 - DEBUG - Command to send: c
o11
_1
e

2025-05-08 05:43:42,529 - DEBUG - Answer received: !ysspark.serializer.objectStreamReset
2025-05-08 05:43:42,530 - DEBUG - Command to send: c
o11
_2
e

2025-05-08 05:43:42,531 - DEBUG - Answer received: !ys100
2025-05-08 05:43:42,532 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,534 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,534 - DEBUG - Command to send: a
g
o6
i5
e

2025-05-08 05:43:42,581 - DEBUG - Answer received: !yro12
2025-05-08 05:43:42,585 - DEBUG - Command to send: c
o12
_1
e

2025-05-08 05:43:42,589 - DEBUG - Answer received: !ysspark.master
2025-05-08 05:43:42,590 - DEBUG - Command to send: c
o12
_2
e

2025-05-08 05:43:42,593 - DEBUG - Answer received: !yslocal[*]
2025-05-08 05:43:42,593 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,594 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,595 - DEBUG - Command to send: a
g
o6
i6
e

2025-05-08 05:43:42,596 - DEBUG - Answer received: !yro13
2025-05-08 05:43:42,597 - DEBUG - Command to send: c
o13
_1
e

2025-05-08 05:43:42,598 - DEBUG - Answer received: !ysspark.submit.pyFiles
2025-05-08 05:43:42,599 - DEBUG - Command to send: c
o13
_2
e

2025-05-08 05:43:42,600 - DEBUG - Answer received: !ys
2025-05-08 05:43:42,600 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,601 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,602 - DEBUG - Command to send: a
g
o6
i7
e

2025-05-08 05:43:42,606 - DEBUG - Answer received: !yro14
2025-05-08 05:43:42,608 - DEBUG - Command to send: c
o14
_1
e

2025-05-08 05:43:42,610 - DEBUG - Answer received: !ysspark.submit.deployMode
2025-05-08 05:43:42,611 - DEBUG - Command to send: c
o14
_2
e

2025-05-08 05:43:42,613 - DEBUG - Answer received: !ysclient
2025-05-08 05:43:42,615 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,617 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,619 - DEBUG - Command to send: a
g
o6
i8
e

2025-05-08 05:43:42,620 - DEBUG - Answer received: !yro15
2025-05-08 05:43:42,623 - DEBUG - Command to send: c
o15
_1
e

2025-05-08 05:43:42,626 - DEBUG - Answer received: !ysspark.app.name
2025-05-08 05:43:42,626 - DEBUG - Command to send: c
o15
_2
e

2025-05-08 05:43:42,628 - DEBUG - Answer received: !ysStreamVideoInteractions
2025-05-08 05:43:42,628 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,629 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,630 - DEBUG - Command to send: a
g
o6
i9
e

2025-05-08 05:43:42,676 - DEBUG - Answer received: !yro16
2025-05-08 05:43:42,684 - DEBUG - Command to send: c
o16
_1
e

2025-05-08 05:43:42,687 - DEBUG - Answer received: !ysspark.driver.extraJavaOptions
2025-05-08 05:43:42,690 - DEBUG - Command to send: c
o16
_2
e

2025-05-08 05:43:42,693 - DEBUG - Answer received: !ys--add-exports java.base/sun.nio.ch=ALL-UNNAMED
2025-05-08 05:43:42,695 - DEBUG - Command to send: a
e
o6
e

2025-05-08 05:43:42,696 - DEBUG - Answer received: !yi10
2025-05-08 05:43:42,698 - DEBUG - Command to send: r
u
JavaSparkContext
rj
e

2025-05-08 05:43:42,798 - DEBUG - Answer received: !ycorg.apache.spark.api.java.JavaSparkContext
2025-05-08 05:43:42,799 - DEBUG - Command to send: i
org.apache.spark.api.java.JavaSparkContext
ro0
e

2025-05-08 05:43:43,181 - DEBUG - Command to send: A
f67d3b1654e5b044a251a3e954a411c08b73739f136cc057d3e3a2e2e3fa4889

2025-05-08 05:43:43,192 - DEBUG - Answer received: !yv
2025-05-08 05:43:43,193 - DEBUG - Command to send: m
d
o1
e

2025-05-08 05:43:43,199 - DEBUG - Answer received: !yv
2025-05-08 05:43:43,200 - DEBUG - Command to send: m
d
o2
e

2025-05-08 05:43:43,202 - DEBUG - Answer received: !yv
2025-05-08 05:43:43,202 - DEBUG - Command to send: m
d
o3
e

2025-05-08 05:43:43,204 - DEBUG - Answer received: !yv
2025-05-08 05:43:43,204 - DEBUG - Command to send: m
d
o4
e

2025-05-08 05:43:43,206 - DEBUG - Answer received: !yv
2025-05-08 05:43:43,207 - DEBUG - Command to send: m
d
o5
e

2025-05-08 05:43:43,278 - DEBUG - Answer received: !yv
2025-05-08 05:43:43,280 - DEBUG - Command to send: m
d
o6
e

2025-05-08 05:43:43,286 - DEBUG - Answer received: !yv
2025-05-08 05:43:54,606 - DEBUG - Answer received: !yro17
2025-05-08 05:43:54,608 - DEBUG - Command to send: c
o17
sc
e

2025-05-08 05:43:54,692 - DEBUG - Answer received: !yro18
2025-05-08 05:43:54,693 - DEBUG - Command to send: c
o18
conf
e

2025-05-08 05:43:54,806 - DEBUG - Answer received: !yro19
2025-05-08 05:43:54,816 - DEBUG - Command to send: r
u
PythonAccumulatorV2
rj
e

2025-05-08 05:43:54,826 - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonAccumulatorV2
2025-05-08 05:43:54,828 - DEBUG - Command to send: i
org.apache.spark.api.python.PythonAccumulatorV2
s127.0.0.1
i37791
sf67d3b1654e5b044a251a3e954a411c08b73739f136cc057d3e3a2e2e3fa4889
e

2025-05-08 05:43:54,830 - DEBUG - Answer received: !yro20
2025-05-08 05:43:54,831 - DEBUG - Command to send: c
o17
sc
e

2025-05-08 05:43:54,893 - DEBUG - Answer received: !yro21
2025-05-08 05:43:54,894 - DEBUG - Command to send: c
o21
register
ro20
e

2025-05-08 05:43:54,899 - DEBUG - Answer received: !yv
2025-05-08 05:43:54,900 - DEBUG - Command to send: r
u
PythonUtils
rj
e

2025-05-08 05:43:54,902 - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonUtils
2025-05-08 05:43:54,903 - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonUtils
isEncryptionEnabled
e

2025-05-08 05:43:54,904 - DEBUG - Answer received: !ym
2025-05-08 05:43:54,905 - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonUtils
isEncryptionEnabled
ro17
e

2025-05-08 05:43:54,907 - DEBUG - Answer received: !ybfalse
2025-05-08 05:43:54,908 - DEBUG - Command to send: r
u
PythonUtils
rj
e

2025-05-08 05:43:54,911 - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonUtils
2025-05-08 05:43:54,912 - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonUtils
getPythonAuthSocketTimeout
e

2025-05-08 05:43:54,913 - DEBUG - Answer received: !ym
2025-05-08 05:43:54,914 - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonUtils
getPythonAuthSocketTimeout
ro17
e

2025-05-08 05:43:54,915 - DEBUG - Answer received: !yL15
2025-05-08 05:43:54,916 - DEBUG - Command to send: r
u
PythonUtils
rj
e

2025-05-08 05:43:54,918 - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonUtils
2025-05-08 05:43:54,919 - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonUtils
getSparkBufferSize
e

2025-05-08 05:43:54,920 - DEBUG - Answer received: !ym
2025-05-08 05:43:54,921 - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonUtils
getSparkBufferSize
ro17
e

2025-05-08 05:43:54,922 - DEBUG - Answer received: !yi65536
2025-05-08 05:43:54,923 - DEBUG - Command to send: r
u
org
rj
e

2025-05-08 05:43:54,927 - DEBUG - Answer received: !yp
2025-05-08 05:43:54,928 - DEBUG - Command to send: r
u
org.apache
rj
e

2025-05-08 05:43:54,930 - DEBUG - Answer received: !yp
2025-05-08 05:43:54,930 - DEBUG - Command to send: r
u
org.apache.spark
rj
e

2025-05-08 05:43:54,993 - DEBUG - Answer received: !yp
2025-05-08 05:43:54,995 - DEBUG - Command to send: r
u
org.apache.spark.SparkFiles
rj
e

2025-05-08 05:43:54,998 - DEBUG - Answer received: !ycorg.apache.spark.SparkFiles
2025-05-08 05:43:54,998 - DEBUG - Command to send: r
m
org.apache.spark.SparkFiles
getRootDirectory
e

2025-05-08 05:43:54,999 - DEBUG - Answer received: !ym
2025-05-08 05:43:55,000 - DEBUG - Command to send: c
z:org.apache.spark.SparkFiles
getRootDirectory
e

2025-05-08 05:43:55,002 - DEBUG - Answer received: !ys/tmp/spark-73d3ebe0-0834-4ceb-8730-7ab37e00df51/userFiles-77aeb7bd-f91e-4e10-b7b3-f0085661ad8a
2025-05-08 05:43:55,003 - DEBUG - Command to send: c
o19
get
sspark.submit.pyFiles
s
e

2025-05-08 05:43:55,005 - DEBUG - Answer received: !ys
2025-05-08 05:43:55,006 - DEBUG - Command to send: r
u
org
rj
e

2025-05-08 05:43:55,011 - DEBUG - Answer received: !yp
2025-05-08 05:43:55,012 - DEBUG - Command to send: r
u
org.apache
rj
e

2025-05-08 05:43:55,014 - DEBUG - Answer received: !yp
2025-05-08 05:43:55,014 - DEBUG - Command to send: r
u
org.apache.spark
rj
e

2025-05-08 05:43:55,016 - DEBUG - Answer received: !yp
2025-05-08 05:43:55,017 - DEBUG - Command to send: r
u
org.apache.spark.util
rj
e

2025-05-08 05:43:55,018 - DEBUG - Answer received: !yp
2025-05-08 05:43:55,019 - DEBUG - Command to send: r
u
org.apache.spark.util.Utils
rj
e

2025-05-08 05:43:55,095 - DEBUG - Answer received: !ycorg.apache.spark.util.Utils
2025-05-08 05:43:55,096 - DEBUG - Command to send: r
m
org.apache.spark.util.Utils
getLocalDir
e

2025-05-08 05:43:55,101 - DEBUG - Answer received: !ym
2025-05-08 05:43:55,102 - DEBUG - Command to send: c
o17
sc
e

2025-05-08 05:43:55,103 - DEBUG - Answer received: !yro22
2025-05-08 05:43:55,104 - DEBUG - Command to send: c
o22
conf
e

2025-05-08 05:43:55,105 - DEBUG - Answer received: !yro23
2025-05-08 05:43:55,107 - DEBUG - Command to send: c
z:org.apache.spark.util.Utils
getLocalDir
ro23
e

2025-05-08 05:43:55,110 - DEBUG - Answer received: !ys/tmp/spark-73d3ebe0-0834-4ceb-8730-7ab37e00df51
2025-05-08 05:43:55,111 - DEBUG - Command to send: r
u
org
rj
e

2025-05-08 05:43:55,117 - DEBUG - Answer received: !yp
2025-05-08 05:43:55,117 - DEBUG - Command to send: r
u
org.apache
rj
e

2025-05-08 05:43:55,120 - DEBUG - Answer received: !yp
2025-05-08 05:43:55,126 - DEBUG - Command to send: r
u
org.apache.spark
rj
e

2025-05-08 05:43:55,193 - DEBUG - Answer received: !yp
2025-05-08 05:43:55,194 - DEBUG - Command to send: r
u
org.apache.spark.util
rj
e

2025-05-08 05:43:55,196 - DEBUG - Answer received: !yp
2025-05-08 05:43:55,198 - DEBUG - Command to send: r
u
org.apache.spark.util.Utils
rj
e

2025-05-08 05:43:55,201 - DEBUG - Answer received: !ycorg.apache.spark.util.Utils
2025-05-08 05:43:55,204 - DEBUG - Command to send: r
m
org.apache.spark.util.Utils
createTempDir
e

2025-05-08 05:43:55,209 - DEBUG - Answer received: !ym
2025-05-08 05:43:55,211 - DEBUG - Command to send: c
z:org.apache.spark.util.Utils
createTempDir
s/tmp/spark-73d3ebe0-0834-4ceb-8730-7ab37e00df51
spyspark
e

2025-05-08 05:43:55,213 - DEBUG - Answer received: !yro24
2025-05-08 05:43:55,214 - DEBUG - Command to send: c
o24
getAbsolutePath
e

2025-05-08 05:43:55,216 - DEBUG - Answer received: !ys/tmp/spark-73d3ebe0-0834-4ceb-8730-7ab37e00df51/pyspark-4bc4f8a2-4831-49dc-a29b-4feb20bd85fd
2025-05-08 05:43:55,218 - DEBUG - Command to send: c
o19
get
sspark.python.profile
sfalse
e

2025-05-08 05:43:55,220 - DEBUG - Answer received: !ysfalse
2025-05-08 05:43:55,221 - DEBUG - Command to send: c
o19
get
sspark.python.profile.memory
sfalse
e

2025-05-08 05:43:55,224 - DEBUG - Answer received: !ysfalse
2025-05-08 05:43:55,225 - DEBUG - Command to send: r
u
SparkSession
rj
e

2025-05-08 05:43:55,293 - DEBUG - Command to send: m
d
o0
e

2025-05-08 05:43:55,304 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,305 - DEBUG - Command to send: m
d
o7
e

2025-05-08 05:43:55,306 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,307 - DEBUG - Command to send: m
d
o8
e

2025-05-08 05:43:55,309 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,310 - DEBUG - Command to send: m
d
o9
e

2025-05-08 05:43:55,311 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,316 - DEBUG - Command to send: m
d
o10
e

2025-05-08 05:43:55,317 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,329 - DEBUG - Command to send: m
d
o11
e

2025-05-08 05:43:55,393 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,394 - DEBUG - Command to send: m
d
o12
e

2025-05-08 05:43:55,401 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,402 - DEBUG - Command to send: m
d
o13
e

2025-05-08 05:43:55,409 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,410 - DEBUG - Command to send: m
d
o14
e

2025-05-08 05:43:55,411 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,423 - DEBUG - Command to send: m
d
o15
e

2025-05-08 05:43:55,424 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,424 - DEBUG - Command to send: m
d
o16
e

2025-05-08 05:43:55,426 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,427 - DEBUG - Command to send: m
d
o18
e

2025-05-08 05:43:55,428 - DEBUG - Answer received: !yv
2025-05-08 05:43:55,517 - DEBUG - Answer received: !ycorg.apache.spark.sql.SparkSession
2025-05-08 05:43:55,518 - DEBUG - Command to send: r
m
org.apache.spark.sql.SparkSession
getDefaultSession
e

2025-05-08 05:43:55,706 - DEBUG - Answer received: !ym
2025-05-08 05:43:55,706 - DEBUG - Command to send: c
z:org.apache.spark.sql.SparkSession
getDefaultSession
e

2025-05-08 05:43:55,711 - DEBUG - Answer received: !yro25
2025-05-08 05:43:55,712 - DEBUG - Command to send: c
o25
isDefined
e

2025-05-08 05:43:55,714 - DEBUG - Answer received: !ybfalse
2025-05-08 05:43:55,715 - DEBUG - Command to send: r
u
SparkSession
rj
e

2025-05-08 05:43:55,719 - DEBUG - Answer received: !ycorg.apache.spark.sql.SparkSession
2025-05-08 05:43:55,720 - DEBUG - Command to send: c
o17
sc
e

2025-05-08 05:43:55,721 - DEBUG - Answer received: !yro26
2025-05-08 05:43:55,792 - DEBUG - Command to send: i
java.util.HashMap
e

2025-05-08 05:43:55,809 - DEBUG - Answer received: !yao27
2025-05-08 05:43:55,810 - DEBUG - Command to send: c
o27
put
sspark.app.name
sStreamVideoInteractions
e

2025-05-08 05:43:55,828 - DEBUG - Answer received: !yn
2025-05-08 05:43:55,829 - DEBUG - Command to send: c
o27
put
sspark.sql.shuffle.partitions
s1
e

2025-05-08 05:43:55,831 - DEBUG - Answer received: !yn
2025-05-08 05:43:55,832 - DEBUG - Command to send: c
o27
put
sspark.streaming.stopGracefullyOnShutdown
strue
e

2025-05-08 05:43:55,892 - DEBUG - Answer received: !yn
2025-05-08 05:43:55,894 - DEBUG - Command to send: i
org.apache.spark.sql.SparkSession
ro26
ro27
e

2025-05-08 05:43:56,703 - DEBUG - Answer received: !yro28
2025-05-08 05:43:56,704 - DEBUG - Command to send: r
u
SparkSession
rj
e

2025-05-08 05:43:56,711 - DEBUG - Answer received: !ycorg.apache.spark.sql.SparkSession
2025-05-08 05:43:56,712 - DEBUG - Command to send: r
m
org.apache.spark.sql.SparkSession
setDefaultSession
e

2025-05-08 05:43:56,713 - DEBUG - Answer received: !ym
2025-05-08 05:43:56,714 - DEBUG - Command to send: c
z:org.apache.spark.sql.SparkSession
setDefaultSession
ro28
e

2025-05-08 05:43:56,716 - DEBUG - Answer received: !yv
2025-05-08 05:43:56,717 - DEBUG - Command to send: r
u
SparkSession
rj
e

2025-05-08 05:43:56,720 - DEBUG - Answer received: !ycorg.apache.spark.sql.SparkSession
2025-05-08 05:43:56,792 - DEBUG - Command to send: r
m
org.apache.spark.sql.SparkSession
setActiveSession
e

2025-05-08 05:43:56,797 - DEBUG - Answer received: !ym
2025-05-08 05:43:56,799 - DEBUG - Command to send: c
z:org.apache.spark.sql.SparkSession
setActiveSession
ro28
e

2025-05-08 05:43:56,802 - DEBUG - Answer received: !yv
2025-05-08 05:43:56,803 - DEBUG - Spark session initialized
2025-05-08 05:43:56,812 - DEBUG - Schema defined
2025-05-08 05:43:56,816 - DEBUG - Reading from Kafka
2025-05-08 05:43:56,817 - DEBUG - Command to send: c
o28
readStream
e

2025-05-08 05:43:57,492 - DEBUG - Command to send: m
d
o27
e

2025-05-08 05:43:57,498 - DEBUG - Answer received: !yv
2025-05-08 05:44:03,626 - DEBUG - Answer received: !yro29
2025-05-08 05:44:03,627 - DEBUG - Command to send: c
o29
format
skafka
e

2025-05-08 05:44:03,693 - DEBUG - Answer received: !yro30
2025-05-08 05:44:03,694 - DEBUG - Command to send: c
o30
option
skafka.bootstrap.servers
skafka:9092
e

2025-05-08 05:44:03,697 - DEBUG - Answer received: !yro31
2025-05-08 05:44:03,698 - DEBUG - Command to send: c
o31
option
ssubscribe
svideo_interactions
e

2025-05-08 05:44:03,700 - DEBUG - Answer received: !yro32
2025-05-08 05:44:03,701 - DEBUG - Command to send: c
o32
option
sstartingOffsets
slatest
e

2025-05-08 05:44:03,703 - DEBUG - Answer received: !yro33
2025-05-08 05:44:03,704 - DEBUG - Command to send: c
o33
option
sfailOnDataLoss
sfalse
e

2025-05-08 05:44:03,706 - DEBUG - Answer received: !yro34
2025-05-08 05:44:03,706 - DEBUG - Command to send: c
o34
load
e

2025-05-08 05:44:18,698 - DEBUG - Answer received: !yro35
2025-05-08 05:44:18,699 - DEBUG - Kafka stream initialized
2025-05-08 05:44:18,700 - DEBUG - Parsing JSON data
2025-05-08 05:44:18,702 - DEBUG - Command to send: r
u
functions
rj
e

2025-05-08 05:44:18,714 - DEBUG - Answer received: !ycorg.apache.spark.sql.functions
2025-05-08 05:44:18,715 - DEBUG - Command to send: r
m
org.apache.spark.sql.functions
col
e

2025-05-08 05:44:18,723 - DEBUG - Answer received: !ym
2025-05-08 05:44:18,725 - DEBUG - Command to send: c
z:org.apache.spark.sql.functions
col
svalue
e

2025-05-08 05:44:18,919 - DEBUG - Answer received: !yro36
2025-05-08 05:44:18,921 - DEBUG - Command to send: c
o36
cast
sstring
e

2025-05-08 05:44:19,004 - DEBUG - Answer received: !yro37
2025-05-08 05:44:19,006 - DEBUG - Command to send: r
u
functions
rj
e

2025-05-08 05:44:19,019 - DEBUG - Answer received: !ycorg.apache.spark.sql.functions
2025-05-08 05:44:19,020 - DEBUG - Command to send: r
m
org.apache.spark.sql.functions
from_json
e

2025-05-08 05:44:19,022 - DEBUG - Answer received: !ym
2025-05-08 05:44:19,024 - DEBUG - Command to send: i
java.util.HashMap
e

2025-05-08 05:44:19,025 - DEBUG - Answer received: !yao38
2025-05-08 05:44:19,026 - DEBUG - Command to send: c
z:org.apache.spark.sql.functions
from_json
ro37
s{"fields":[{"metadata":{},"name":"UserID","nullable":true,"type":"long"},{"metadata":{},"name":"Age","nullable":true,"type":"long"},{"metadata":{},"name":"Gender","nullable":true,"type":"string"},{"metadata":{},"name":"Location","nullable":true,"type":"string"},{"metadata":{},"name":"Income","nullable":true,"type":"long"},{"metadata":{},"name":"Debt","nullable":true,"type":"boolean"},{"metadata":{},"name":"OwnsProperty","nullable":true,"type":"boolean"},{"metadata":{},"name":"Profession","nullable":true,"type":"string"},{"metadata":{},"name":"Demographics","nullable":true,"type":"string"},{"metadata":{},"name":"Platform","nullable":true,"type":"string"},{"metadata":{},"name":"TotalTimeSpent","nullable":true,"type":"long"},{"metadata":{},"name":"NumberOfSessions","nullable":true,"type":"long"},{"metadata":{},"name":"VideoID","nullable":true,"type":"long"},{"metadata":{},"name":"VideoCategory","nullable":true,"type":"string"},{"metadata":{},"name":"VideoLength","nullable":true,"type":"long"},{"metadata":{},"name":"Engagement","nullable":true,"type":"long"},{"metadata":{},"name":"ImportanceScore","nullable":true,"type":"long"},{"metadata":{},"name":"TimeSpentOnVideo","nullable":true,"type":"long"},{"metadata":{},"name":"NumberOfVideosWatched","nullable":true,"type":"long"},{"metadata":{},"name":"ScrollRate","nullable":true,"type":"long"},{"metadata":{},"name":"Frequency","nullable":true,"type":"string"},{"metadata":{},"name":"ProductivityLoss","nullable":true,"type":"long"},{"metadata":{},"name":"Satisfaction","nullable":true,"type":"long"},{"metadata":{},"name":"WatchReason","nullable":true,"type":"string"},{"metadata":{},"name":"DeviceType","nullable":true,"type":"string"},{"metadata":{},"name":"OS","nullable":true,"type":"string"},{"metadata":{},"name":"WatchTime","nullable":true,"type":"string"},{"metadata":{},"name":"SelfControl","nullable":true,"type":"long"},{"metadata":{},"name":"AddictionLevel","nullable":true,"type":"long"},{"metadata":{},"name":"CurrentActivity","nullable":true,"type":"string"},{"metadata":{},"name":"ConnectionType","nullable":true,"type":"string"}],"type":"struct"}
ro38
e

2025-05-08 05:44:19,397 - DEBUG - Answer received: !yro39
2025-05-08 05:44:19,399 - DEBUG - Command to send: c
o39
as
sdata
e

2025-05-08 05:44:19,401 - DEBUG - Answer received: !yro40
2025-05-08 05:44:19,402 - DEBUG - Command to send: r
u
PythonUtils
rj
e

2025-05-08 05:44:19,405 - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonUtils
2025-05-08 05:44:19,405 - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

2025-05-08 05:44:19,407 - DEBUG - Answer received: !ym
2025-05-08 05:44:19,408 - DEBUG - Command to send: i
java.util.ArrayList
e

2025-05-08 05:44:19,410 - DEBUG - Answer received: !ylo41
2025-05-08 05:44:19,411 - DEBUG - Command to send: c
o41
add
ro40
e

2025-05-08 05:44:19,420 - DEBUG - Answer received: !ybtrue
2025-05-08 05:44:19,421 - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro41
e

2025-05-08 05:44:19,424 - DEBUG - Answer received: !yro42
2025-05-08 05:44:19,424 - DEBUG - Command to send: c
o35
select
ro42
e

2025-05-08 05:44:19,612 - DEBUG - Command to send: m
d
o38
e

2025-05-08 05:44:19,622 - DEBUG - Answer received: !yv
2025-05-08 05:44:19,624 - DEBUG - Command to send: m
d
o41
e

2025-05-08 05:44:19,693 - DEBUG - Answer received: !yv
2025-05-08 05:44:21,027 - DEBUG - Answer received: !yro43
2025-05-08 05:44:21,028 - DEBUG - Command to send: r
u
functions
rj
e

2025-05-08 05:44:21,033 - DEBUG - Answer received: !ycorg.apache.spark.sql.functions
2025-05-08 05:44:21,034 - DEBUG - Command to send: r
m
org.apache.spark.sql.functions
col
e

2025-05-08 05:44:21,035 - DEBUG - Answer received: !ym
2025-05-08 05:44:21,036 - DEBUG - Command to send: c
z:org.apache.spark.sql.functions
col
sdata.*
e

2025-05-08 05:44:21,097 - DEBUG - Answer received: !yro44
2025-05-08 05:44:21,106 - DEBUG - Command to send: r
u
PythonUtils
rj
e

2025-05-08 05:44:21,111 - DEBUG - Answer received: !ycorg.apache.spark.api.python.PythonUtils
2025-05-08 05:44:21,114 - DEBUG - Command to send: r
m
org.apache.spark.api.python.PythonUtils
toSeq
e

2025-05-08 05:44:21,118 - DEBUG - Answer received: !ym
2025-05-08 05:44:21,121 - DEBUG - Command to send: i
java.util.ArrayList
e

2025-05-08 05:44:21,123 - DEBUG - Answer received: !ylo45
2025-05-08 05:44:21,124 - DEBUG - Command to send: c
o45
add
ro44
e

2025-05-08 05:44:21,127 - DEBUG - Answer received: !ybtrue
2025-05-08 05:44:21,129 - DEBUG - Command to send: c
z:org.apache.spark.api.python.PythonUtils
toSeq
ro45
e

2025-05-08 05:44:21,130 - DEBUG - Answer received: !yro46
2025-05-08 05:44:21,132 - DEBUG - Command to send: c
o43
select
ro46
e

2025-05-08 05:44:21,592 - DEBUG - Answer received: !yro47
2025-05-08 05:44:21,594 - DEBUG - Command to send: r
u
functions
rj
e

2025-05-08 05:44:21,598 - DEBUG - Answer received: !ycorg.apache.spark.sql.functions
2025-05-08 05:44:21,599 - DEBUG - Command to send: r
m
org.apache.spark.sql.functions
current_timestamp
e

2025-05-08 05:44:21,601 - DEBUG - Answer received: !ym
2025-05-08 05:44:21,602 - DEBUG - Command to send: c
z:org.apache.spark.sql.functions
current_timestamp
e

2025-05-08 05:44:21,605 - DEBUG - Answer received: !yro48
2025-05-08 05:44:21,606 - DEBUG - Command to send: c
o47
withColumn
sIngestionTimestamp
ro48
e

2025-05-08 05:44:21,698 - DEBUG - Command to send: m
d
o45
e

2025-05-08 05:44:21,701 - DEBUG - Answer received: !yv
2025-05-08 05:44:21,820 - DEBUG - Answer received: !yro49
2025-05-08 05:44:21,822 - DEBUG - JSON parsed
2025-05-08 05:44:21,823 - INFO - Started streaming for video_interactions to Snowflake
2025-05-08 05:44:21,824 - DEBUG - Command to send: c
o49
writeStream
e

2025-05-08 05:44:22,017 - DEBUG - Answer received: !yro50
2025-05-08 05:44:22,025 - DEBUG - Command to send: c
o50
option
scheckpointLocation
s/app/checkpoints/stream_video_interactions
e

2025-05-08 05:44:22,094 - DEBUG - Answer received: !yro51
2025-05-08 05:44:22,095 - DEBUG - Command to send: c
o51
format
sconsole
e

2025-05-08 05:44:22,097 - DEBUG - Answer received: !yro52
2025-05-08 05:44:22,099 - DEBUG - Command to send: r
u
org
rj
e

2025-05-08 05:44:22,110 - DEBUG - Answer received: !yp
2025-05-08 05:44:22,113 - DEBUG - Command to send: r
u
org.apache
rj
e

2025-05-08 05:44:22,116 - DEBUG - Answer received: !yp
2025-05-08 05:44:22,118 - DEBUG - Command to send: r
u
org.apache.spark
rj
e

2025-05-08 05:44:22,119 - DEBUG - Answer received: !yp
2025-05-08 05:44:22,120 - DEBUG - Command to send: r
u
org.apache.spark.sql
rj
e

2025-05-08 05:44:22,125 - DEBUG - Answer received: !yp
2025-05-08 05:44:22,126 - DEBUG - Command to send: r
u
org.apache.spark.sql.streaming
rj
e

2025-05-08 05:44:22,132 - DEBUG - Answer received: !yp
2025-05-08 05:44:22,133 - DEBUG - Command to send: r
u
org.apache.spark.sql.streaming.Trigger
rj
e

2025-05-08 05:44:22,193 - DEBUG - Answer received: !ycorg.apache.spark.sql.streaming.Trigger
2025-05-08 05:44:22,195 - DEBUG - Command to send: r
m
org.apache.spark.sql.streaming.Trigger
ProcessingTime
e

2025-05-08 05:44:22,207 - DEBUG - Answer received: !ym
2025-05-08 05:44:22,208 - DEBUG - Command to send: c
z:org.apache.spark.sql.streaming.Trigger
ProcessingTime
s10 seconds
e

2025-05-08 05:44:22,227 - DEBUG - Answer received: !yro53
2025-05-08 05:44:22,229 - DEBUG - Command to send: c
o52
trigger
ro53
e

2025-05-08 05:44:22,231 - DEBUG - Answer received: !yro54
2025-05-08 05:44:22,231 - DEBUG - Command to send: c
o54
start
e

2025-05-08 05:44:23,911 - DEBUG - Answer received: !yro55
2025-05-08 05:44:23,916 - DEBUG - Command to send: c
o55
awaitTermination
e

2025-05-08 05:57:50,545 - DEBUG - Answer received: 
2025-05-08 05:57:50,546 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 05:57:50,548 - INFO - Closing down clientserver connection
2025-05-08 05:57:50,548 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 05:57:50,551 - INFO - Closing down clientserver connection
2025-05-08 05:57:50,552 - ERROR - Error in stream_video_interactions.py: An error occurred while calling o55.awaitTermination
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 110, in <module>
    cleaned_df = parsed_df.dropna(subset=critical_columns)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 201, in awaitTermination
    return self._jsq.awaitTermination()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 169, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o55.awaitTermination
2025-05-08 05:57:50,597 - INFO - Closing down clientserver connection
2025-05-08 05:58:38,881 - INFO - Starting stream_video_interactions.py
2025-05-08 05:58:38,895 - INFO - Configurations loaded
2025-05-08 05:58:51,698 - INFO - Spark session initialized
2025-05-08 05:58:51,699 - INFO - Schema defined
2025-05-08 05:59:15,803 - INFO - Kafka stream initialized
2025-05-08 05:59:15,805 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 05:59:15,822 - INFO - Closing down clientserver connection
2025-05-08 05:59:38,915 - INFO - Starting stream_video_interactions.py
2025-05-08 05:59:38,930 - INFO - Configurations loaded
2025-05-08 06:00:00,418 - INFO - Spark session initialized
2025-05-08 06:00:00,419 - INFO - Schema defined
2025-05-08 06:00:49,923 - INFO - Kafka stream initialized
2025-05-08 06:00:49,933 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:00:50,124 - INFO - Closing down clientserver connection
2025-05-08 06:00:56,658 - INFO - Starting stream_video_interactions.py
2025-05-08 06:00:56,748 - INFO - Configurations loaded
2025-05-08 06:01:25,746 - INFO - Spark session initialized
2025-05-08 06:01:25,753 - INFO - Schema defined
2025-05-08 06:01:41,746 - INFO - Starting stream_video_interactions.py
2025-05-08 06:01:41,765 - INFO - Configurations loaded
2025-05-08 06:02:05,156 - INFO - Spark session initialized
2025-05-08 06:02:05,163 - INFO - Schema defined
2025-05-08 06:02:05,269 - INFO - Kafka stream initialized
2025-05-08 06:02:05,297 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:02:05,472 - INFO - Closing down clientserver connection
2025-05-08 06:02:28,376 - INFO - Kafka stream initialized
2025-05-08 06:02:28,378 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:02:28,460 - INFO - Closing down clientserver connection
2025-05-08 06:02:49,665 - INFO - Starting stream_video_interactions.py
2025-05-08 06:02:49,677 - INFO - Configurations loaded
2025-05-08 06:03:02,178 - INFO - Spark session initialized
2025-05-08 06:03:02,179 - INFO - Schema defined
2025-05-08 06:03:22,994 - INFO - Kafka stream initialized
2025-05-08 06:03:22,999 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:03:23,081 - INFO - Closing down clientserver connection
2025-05-08 06:03:46,189 - INFO - Starting stream_video_interactions.py
2025-05-08 06:03:46,209 - INFO - Configurations loaded
2025-05-08 06:03:57,509 - INFO - Spark session initialized
2025-05-08 06:03:57,511 - INFO - Schema defined
2025-05-08 06:04:16,295 - INFO - Kafka stream initialized
2025-05-08 06:04:16,296 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:04:16,304 - INFO - Closing down clientserver connection
2025-05-08 06:04:40,228 - INFO - Starting stream_video_interactions.py
2025-05-08 06:04:40,244 - INFO - Configurations loaded
2025-05-08 06:04:52,721 - INFO - Spark session initialized
2025-05-08 06:04:52,724 - INFO - Schema defined
2025-05-08 06:05:13,821 - INFO - Kafka stream initialized
2025-05-08 06:05:13,825 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:05:13,832 - INFO - Closing down clientserver connection
2025-05-08 06:05:35,472 - INFO - Starting stream_video_interactions.py
2025-05-08 06:05:35,536 - INFO - Configurations loaded
2025-05-08 06:05:47,149 - INFO - Spark session initialized
2025-05-08 06:05:47,150 - INFO - Schema defined
2025-05-08 06:06:05,366 - INFO - Kafka stream initialized
2025-05-08 06:06:05,367 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:06:05,449 - INFO - Closing down clientserver connection
2025-05-08 06:06:26,385 - INFO - Starting stream_video_interactions.py
2025-05-08 06:06:26,397 - INFO - Configurations loaded
2025-05-08 06:06:37,759 - INFO - Spark session initialized
2025-05-08 06:06:37,760 - INFO - Schema defined
2025-05-08 06:06:59,070 - INFO - Kafka stream initialized
2025-05-08 06:06:59,072 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:06:59,086 - INFO - Closing down clientserver connection
2025-05-08 06:07:23,008 - INFO - Starting stream_video_interactions.py
2025-05-08 06:07:23,077 - INFO - Configurations loaded
2025-05-08 06:07:35,479 - INFO - Spark session initialized
2025-05-08 06:07:35,481 - INFO - Schema defined
2025-05-08 06:07:54,810 - INFO - Kafka stream initialized
2025-05-08 06:07:54,825 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:07:54,898 - INFO - Closing down clientserver connection
2025-05-08 06:08:18,500 - INFO - Starting stream_video_interactions.py
2025-05-08 06:08:18,515 - INFO - Configurations loaded
2025-05-08 06:08:30,213 - INFO - Spark session initialized
2025-05-08 06:08:30,214 - INFO - Schema defined
2025-05-08 06:08:49,817 - INFO - Kafka stream initialized
2025-05-08 06:08:49,818 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:08:49,830 - INFO - Closing down clientserver connection
2025-05-08 06:09:12,728 - INFO - Starting stream_video_interactions.py
2025-05-08 06:09:12,740 - INFO - Configurations loaded
2025-05-08 06:09:25,330 - INFO - Spark session initialized
2025-05-08 06:09:25,331 - INFO - Schema defined
2025-05-08 06:09:44,143 - INFO - Kafka stream initialized
2025-05-08 06:09:44,145 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:09:44,223 - INFO - Closing down clientserver connection
2025-05-08 06:10:08,876 - INFO - Starting stream_video_interactions.py
2025-05-08 06:10:08,940 - INFO - Configurations loaded
2025-05-08 06:10:21,866 - INFO - Spark session initialized
2025-05-08 06:10:21,935 - INFO - Schema defined
2025-05-08 06:10:42,837 - INFO - Kafka stream initialized
2025-05-08 06:10:42,839 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:10:42,861 - INFO - Closing down clientserver connection
2025-05-08 06:11:04,689 - INFO - Starting stream_video_interactions.py
2025-05-08 06:11:04,750 - INFO - Configurations loaded
2025-05-08 06:11:17,481 - INFO - Spark session initialized
2025-05-08 06:11:17,482 - INFO - Schema defined
2025-05-08 06:11:37,070 - INFO - Kafka stream initialized
2025-05-08 06:11:37,071 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:11:37,084 - INFO - Closing down clientserver connection
2025-05-08 06:12:00,675 - INFO - Starting stream_video_interactions.py
2025-05-08 06:12:00,687 - INFO - Configurations loaded
2025-05-08 06:12:12,175 - INFO - Spark session initialized
2025-05-08 06:12:12,176 - INFO - Schema defined
2025-05-08 06:12:33,101 - INFO - Kafka stream initialized
2025-05-08 06:12:33,102 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:12:33,111 - INFO - Closing down clientserver connection
2025-05-08 06:12:54,551 - INFO - Starting stream_video_interactions.py
2025-05-08 06:12:54,564 - INFO - Configurations loaded
2025-05-08 06:13:06,216 - INFO - Spark session initialized
2025-05-08 06:13:06,217 - INFO - Schema defined
2025-05-08 06:13:25,714 - INFO - Kafka stream initialized
2025-05-08 06:13:25,715 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:13:25,726 - INFO - Closing down clientserver connection
2025-05-08 06:13:50,014 - INFO - Starting stream_video_interactions.py
2025-05-08 06:13:50,027 - INFO - Configurations loaded
2025-05-08 06:14:02,112 - INFO - Spark session initialized
2025-05-08 06:14:02,115 - INFO - Schema defined
2025-05-08 06:14:25,421 - INFO - Kafka stream initialized
2025-05-08 06:14:25,422 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:14:25,435 - INFO - Closing down clientserver connection
2025-05-08 06:14:51,249 - INFO - Starting stream_video_interactions.py
2025-05-08 06:14:51,258 - INFO - Configurations loaded
2025-05-08 06:15:04,237 - INFO - Spark session initialized
2025-05-08 06:15:04,238 - INFO - Schema defined
2025-05-08 06:15:24,639 - INFO - Kafka stream initialized
2025-05-08 06:15:24,640 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:15:24,684 - INFO - Closing down clientserver connection
2025-05-08 06:15:46,499 - INFO - Starting stream_video_interactions.py
2025-05-08 06:15:46,509 - INFO - Configurations loaded
2025-05-08 06:15:58,050 - INFO - Spark session initialized
2025-05-08 06:15:58,052 - INFO - Schema defined
2025-05-08 06:16:20,464 - INFO - Kafka stream initialized
2025-05-08 06:16:20,465 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:16:20,549 - INFO - Closing down clientserver connection
2025-05-08 06:16:45,351 - INFO - Starting stream_video_interactions.py
2025-05-08 06:16:45,372 - INFO - Configurations loaded
2025-05-08 06:16:57,387 - INFO - Spark session initialized
2025-05-08 06:16:57,388 - INFO - Schema defined
2025-05-08 06:17:20,694 - INFO - Kafka stream initialized
2025-05-08 06:17:20,771 - ERROR - Error in stream_video_interactions.py: name 'from_json' is not defined
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 104, in <module>
    from_json(col("value").cast("string"), video_interactions_schema).alias("data")
NameError: name 'from_json' is not defined
2025-05-08 06:17:20,786 - INFO - Closing down clientserver connection
2025-05-08 06:17:45,008 - INFO - Starting stream_video_interactions.py
2025-05-08 06:17:45,019 - INFO - Configurations loaded
2025-05-08 06:17:58,085 - INFO - Spark session initialized
2025-05-08 06:17:58,091 - INFO - Schema defined
2025-05-08 06:18:09,882 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 06:18:09,884 - INFO - Closing down clientserver connection
2025-05-08 06:18:09,886 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 06:18:09,892 - INFO - Closing down clientserver connection
2025-05-08 06:18:09,893 - ERROR - Error in stream_video_interactions.py: An error occurred while calling o42.load
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 93, in <module>
    kafka_df = spark.readStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 277, in load
    return self._df(self._jreader.load())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 169, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o42.load
2025-05-08 06:18:09,984 - INFO - Closing down clientserver connection
2025-05-08 06:18:56,944 - INFO - Starting stream_video_interactions.py
2025-05-08 06:18:56,999 - INFO - Configurations loaded
2025-05-08 06:19:10,505 - INFO - Spark session initialized
2025-05-08 06:19:10,506 - INFO - Schema defined
2025-05-08 06:19:47,625 - INFO - Kafka stream initialized
2025-05-08 06:19:55,016 - INFO - JSON parsing completed
2025-05-08 06:20:21,837 - INFO - Starting stream_video_interactions.py
2025-05-08 06:20:21,942 - INFO - Configurations loaded
2025-05-08 06:20:33,238 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:20:34,726 - ERROR - Error in stream_video_interactions.py: requirement failed: Private key must be specified in Snowflake streaming
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 435, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 426, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: requirement failed: Private key must be specified in Snowflake streaming
2025-05-08 06:20:34,924 - INFO - Closing down clientserver connection
2025-05-08 06:20:54,056 - INFO - Spark session initialized
2025-05-08 06:20:54,058 - INFO - Schema defined
2025-05-08 06:21:29,644 - INFO - Starting stream_video_interactions.py
2025-05-08 06:21:29,761 - INFO - Configurations loaded
2025-05-08 06:21:39,673 - INFO - Kafka stream initialized
2025-05-08 06:21:46,647 - INFO - JSON parsing completed
2025-05-08 06:22:02,253 - INFO - Spark session initialized
2025-05-08 06:22:02,255 - INFO - Schema defined
2025-05-08 06:22:21,581 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:22:22,281 - ERROR - Error in stream_video_interactions.py: requirement failed: Private key must be specified in Snowflake streaming
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 435, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 426, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: requirement failed: Private key must be specified in Snowflake streaming
2025-05-08 06:22:22,481 - INFO - Closing down clientserver connection
2025-05-08 06:22:36,762 - INFO - Kafka stream initialized
2025-05-08 06:22:39,386 - INFO - JSON parsing completed
2025-05-08 06:22:58,981 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:22:59,469 - ERROR - Error in stream_video_interactions.py: requirement failed: Private key must be specified in Snowflake streaming
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 435, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 426, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: requirement failed: Private key must be specified in Snowflake streaming
2025-05-08 06:22:59,572 - INFO - Closing down clientserver connection
2025-05-08 06:23:23,707 - INFO - Starting stream_video_interactions.py
2025-05-08 06:23:23,720 - INFO - Configurations loaded
2025-05-08 06:23:34,909 - INFO - Spark session initialized
2025-05-08 06:23:34,911 - INFO - Schema defined
2025-05-08 06:23:58,328 - INFO - Kafka stream initialized
2025-05-08 06:24:01,394 - INFO - JSON parsing completed
2025-05-08 06:24:19,117 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:24:19,714 - ERROR - Error in stream_video_interactions.py: requirement failed: Private key must be specified in Snowflake streaming
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 435, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 426, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: requirement failed: Private key must be specified in Snowflake streaming
2025-05-08 06:24:19,904 - INFO - Closing down clientserver connection
2025-05-08 06:24:43,498 - INFO - Starting stream_video_interactions.py
2025-05-08 06:24:43,508 - INFO - Configurations loaded
2025-05-08 06:24:56,420 - INFO - Spark session initialized
2025-05-08 06:24:56,421 - INFO - Schema defined
2025-05-08 06:25:20,726 - INFO - Kafka stream initialized
2025-05-08 06:25:23,615 - INFO - JSON parsing completed
2025-05-08 06:25:40,547 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:25:41,316 - ERROR - Error in stream_video_interactions.py: requirement failed: Private key must be specified in Snowflake streaming
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 435, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 426, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: requirement failed: Private key must be specified in Snowflake streaming
2025-05-08 06:25:41,431 - INFO - Closing down clientserver connection
2025-05-08 06:26:08,349 - INFO - Starting stream_video_interactions.py
2025-05-08 06:26:08,382 - INFO - Configurations loaded
2025-05-08 06:26:23,255 - INFO - Spark session initialized
2025-05-08 06:26:23,256 - INFO - Schema defined
2025-05-08 06:26:45,766 - INFO - Kafka stream initialized
2025-05-08 06:26:47,251 - INFO - JSON parsing completed
2025-05-08 06:27:05,571 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:27:06,160 - ERROR - Error in stream_video_interactions.py: requirement failed: Private key must be specified in Snowflake streaming
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 435, in <module>
    # Write dimension and fact tables to Snowflake
  File "/app/scripts/stream_video_interactions.py", line 426, in write_to_snowflake
    col("ScrollRate").cast("float"),
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: requirement failed: Private key must be specified in Snowflake streaming
2025-05-08 06:27:06,341 - INFO - Closing down clientserver connection
2025-05-08 06:27:27,945 - INFO - Starting stream_video_interactions.py
2025-05-08 06:27:27,953 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:27:27,954 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:27:48,685 - INFO - Starting stream_video_interactions.py
2025-05-08 06:27:48,694 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:27:48,695 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:28:42,217 - INFO - Starting stream_video_interactions.py
2025-05-08 06:28:42,266 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:28:42,266 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:29:03,957 - INFO - Starting stream_video_interactions.py
2025-05-08 06:29:03,966 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:29:03,967 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:29:26,073 - INFO - Starting stream_video_interactions.py
2025-05-08 06:29:26,084 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:29:26,085 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:29:48,203 - INFO - Starting stream_video_interactions.py
2025-05-08 06:29:48,211 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:29:48,213 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:30:08,594 - INFO - Starting stream_video_interactions.py
2025-05-08 06:30:08,600 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:30:08,601 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:30:30,399 - INFO - Starting stream_video_interactions.py
2025-05-08 06:30:30,408 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:30:30,409 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:30:50,970 - INFO - Starting stream_video_interactions.py
2025-05-08 06:30:50,976 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:30:50,976 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:31:11,565 - INFO - Starting stream_video_interactions.py
2025-05-08 06:31:11,570 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:31:11,571 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:31:31,275 - INFO - Starting stream_video_interactions.py
2025-05-08 06:31:31,281 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:31:31,282 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:31:52,964 - INFO - Starting stream_video_interactions.py
2025-05-08 06:31:52,972 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:31:52,972 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:32:16,187 - INFO - Starting stream_video_interactions.py
2025-05-08 06:32:16,193 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:32:16,194 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:32:38,966 - INFO - Starting stream_video_interactions.py
2025-05-08 06:32:38,972 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:32:38,973 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:33:00,758 - INFO - Starting stream_video_interactions.py
2025-05-08 06:33:00,766 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:33:00,766 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:33:22,402 - INFO - Starting stream_video_interactions.py
2025-05-08 06:33:22,410 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:33:22,411 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:33:44,299 - INFO - Starting stream_video_interactions.py
2025-05-08 06:33:44,306 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:33:44,307 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:34:06,467 - INFO - Starting stream_video_interactions.py
2025-05-08 06:34:06,474 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:34:06,475 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:34:27,689 - INFO - Starting stream_video_interactions.py
2025-05-08 06:34:27,696 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:34:27,697 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:35:01,437 - INFO - Starting stream_video_interactions.py
2025-05-08 06:35:01,444 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:35:01,445 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:35:26,161 - INFO - Starting stream_video_interactions.py
2025-05-08 06:35:26,169 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:35:26,169 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:36:18,776 - INFO - Starting stream_video_interactions.py
2025-05-08 06:36:18,784 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:36:18,785 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:36:39,163 - INFO - Starting stream_video_interactions.py
2025-05-08 06:36:39,170 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:36:39,171 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:36:59,388 - INFO - Starting stream_video_interactions.py
2025-05-08 06:36:59,395 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:36:59,395 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:37:19,548 - INFO - Starting stream_video_interactions.py
2025-05-08 06:37:19,555 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:37:19,555 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:37:40,408 - INFO - Starting stream_video_interactions.py
2025-05-08 06:37:40,415 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:37:40,416 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:38:43,075 - INFO - Starting stream_video_interactions.py
2025-05-08 06:38:43,083 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:38:43,084 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:39:04,122 - INFO - Starting stream_video_interactions.py
2025-05-08 06:39:04,133 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:39:04,134 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:39:50,189 - INFO - Starting stream_video_interactions.py
2025-05-08 06:39:50,203 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:39:50,203 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:40:00,998 - INFO - Starting stream_video_interactions.py
2025-05-08 06:40:01,008 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:40:01,087 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:40:15,649 - INFO - Starting stream_video_interactions.py
2025-05-08 06:40:15,657 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:40:15,694 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:40:36,429 - INFO - Starting stream_video_interactions.py
2025-05-08 06:40:36,435 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:40:36,436 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:40:56,663 - INFO - Starting stream_video_interactions.py
2025-05-08 06:40:56,668 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:40:56,669 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:41:16,544 - INFO - Starting stream_video_interactions.py
2025-05-08 06:41:16,553 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:41:16,554 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:41:36,215 - INFO - Starting stream_video_interactions.py
2025-05-08 06:41:36,222 - ERROR - Snowflake private key path is missing or invalid
2025-05-08 06:41:36,223 - ERROR - Error in stream_video_interactions.py: Snowflake private key path is missing or invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 35, in <module>
    raise ValueError("Snowflake private key path is missing or invalid")
ValueError: Snowflake private key path is missing or invalid
2025-05-08 06:42:46,830 - INFO - Starting stream_video_interactions.py
2025-05-08 06:42:46,849 - INFO - Snowflake configurations loaded
2025-05-08 06:42:46,856 - INFO - AWS configurations loaded
2025-05-08 06:43:08,841 - INFO - Spark session initialized
2025-05-08 06:43:08,920 - INFO - Schema defined
2025-05-08 06:43:54,343 - INFO - Starting stream_video_interactions.py
2025-05-08 06:43:54,542 - INFO - Snowflake configurations loaded
2025-05-08 06:43:54,547 - INFO - AWS configurations loaded
2025-05-08 06:43:59,838 - INFO - Kafka stream initialized
2025-05-08 06:44:07,732 - INFO - JSON parsing completed
2025-05-08 06:44:33,337 - INFO - Spark session initialized
2025-05-08 06:44:33,340 - INFO - Schema defined
2025-05-08 06:44:51,848 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:44:53,052 - ERROR - Error in stream_video_interactions.py: A snowflake password or private key path or OAuth token must be provided with 'sfpassword or pem_private_key' or 'sftoken' parameter, e.g. 'password'
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 450, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 441, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: A snowflake password or private key path or OAuth token must be provided with 'sfpassword or pem_private_key' or 'sftoken' parameter, e.g. 'password'
2025-05-08 06:44:53,455 - INFO - Closing down clientserver connection
2025-05-08 06:45:20,574 - INFO - Kafka stream initialized
2025-05-08 06:45:25,650 - INFO - JSON parsing completed
2025-05-08 06:45:44,770 - INFO - Starting stream_video_interactions.py
2025-05-08 06:45:44,873 - INFO - Snowflake configurations loaded
2025-05-08 06:45:44,958 - INFO - AWS configurations loaded
2025-05-08 06:45:56,460 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:45:57,359 - ERROR - Error in stream_video_interactions.py: A snowflake password or private key path or OAuth token must be provided with 'sfpassword or pem_private_key' or 'sftoken' parameter, e.g. 'password'
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 450, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 441, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: A snowflake password or private key path or OAuth token must be provided with 'sfpassword or pem_private_key' or 'sftoken' parameter, e.g. 'password'
2025-05-08 06:45:57,594 - INFO - Closing down clientserver connection
2025-05-08 06:46:03,663 - INFO - Spark session initialized
2025-05-08 06:46:03,664 - INFO - Schema defined
2025-05-08 06:46:30,961 - INFO - Kafka stream initialized
2025-05-08 06:46:33,565 - INFO - JSON parsing completed
2025-05-08 06:46:52,067 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:46:52,468 - ERROR - Error in stream_video_interactions.py: A snowflake password or private key path or OAuth token must be provided with 'sfpassword or pem_private_key' or 'sftoken' parameter, e.g. 'password'
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 450, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 441, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: A snowflake password or private key path or OAuth token must be provided with 'sfpassword or pem_private_key' or 'sftoken' parameter, e.g. 'password'
2025-05-08 06:46:52,506 - INFO - Closing down clientserver connection
2025-05-08 06:47:15,573 - INFO - Starting stream_video_interactions.py
2025-05-08 06:47:15,587 - INFO - Snowflake configurations loaded
2025-05-08 06:47:15,593 - INFO - AWS configurations loaded
2025-05-08 06:47:27,182 - INFO - Spark session initialized
2025-05-08 06:47:27,185 - INFO - Schema defined
2025-05-08 06:47:49,201 - INFO - Kafka stream initialized
2025-05-08 06:47:52,483 - INFO - JSON parsing completed
2025-05-08 06:48:08,091 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:48:08,680 - ERROR - Error in stream_video_interactions.py: A snowflake password or private key path or OAuth token must be provided with 'sfpassword or pem_private_key' or 'sftoken' parameter, e.g. 'password'
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 450, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 441, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: A snowflake password or private key path or OAuth token must be provided with 'sfpassword or pem_private_key' or 'sftoken' parameter, e.g. 'password'
2025-05-08 06:48:08,794 - INFO - Closing down clientserver connection
2025-05-08 06:48:31,723 - INFO - Starting stream_video_interactions.py
2025-05-08 06:48:31,803 - INFO - Snowflake configurations loaded
2025-05-08 06:48:31,818 - INFO - AWS configurations loaded
2025-05-08 06:48:44,821 - INFO - Spark session initialized
2025-05-08 06:48:44,823 - INFO - Schema defined
2025-05-08 06:49:09,795 - INFO - Kafka stream initialized
2025-05-08 06:49:12,627 - INFO - JSON parsing completed
2025-05-08 06:49:28,518 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:49:28,999 - ERROR - Error in stream_video_interactions.py: A snowflake password or private key path or OAuth token must be provided with 'sfpassword or pem_private_key' or 'sftoken' parameter, e.g. 'password'
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 450, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 441, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: A snowflake password or private key path or OAuth token must be provided with 'sfpassword or pem_private_key' or 'sftoken' parameter, e.g. 'password'
2025-05-08 06:49:29,219 - INFO - Closing down clientserver connection
2025-05-08 06:49:50,801 - INFO - Starting stream_video_interactions.py
2025-05-08 06:49:50,813 - INFO - Snowflake configurations loaded
2025-05-08 06:49:50,819 - INFO - AWS configurations loaded
2025-05-08 06:50:04,820 - INFO - Spark session initialized
2025-05-08 06:50:04,899 - INFO - Schema defined
2025-05-08 06:50:28,939 - INFO - Kafka stream initialized
2025-05-08 06:50:31,431 - INFO - JSON parsing completed
2025-05-08 06:50:48,144 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:50:49,724 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 450, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 441, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 06:50:49,836 - INFO - Closing down clientserver connection
2025-05-08 06:51:09,039 - INFO - Starting stream_video_interactions.py
2025-05-08 06:51:09,052 - INFO - Snowflake configurations loaded
2025-05-08 06:51:09,059 - INFO - AWS configurations loaded
2025-05-08 06:51:22,127 - INFO - Spark session initialized
2025-05-08 06:51:22,129 - INFO - Schema defined
2025-05-08 06:51:42,755 - INFO - Kafka stream initialized
2025-05-08 06:51:45,046 - INFO - JSON parsing completed
2025-05-08 06:52:02,823 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:52:04,939 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 450, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 441, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 06:52:05,062 - INFO - Closing down clientserver connection
2025-05-08 06:52:29,054 - INFO - Starting stream_video_interactions.py
2025-05-08 06:52:29,069 - INFO - Snowflake configurations loaded
2025-05-08 06:52:29,076 - INFO - AWS configurations loaded
2025-05-08 06:52:42,643 - INFO - Spark session initialized
2025-05-08 06:52:42,645 - INFO - Schema defined
2025-05-08 06:53:03,674 - INFO - Kafka stream initialized
2025-05-08 06:53:07,233 - INFO - JSON parsing completed
2025-05-08 06:53:22,452 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 06:53:22,456 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 06:53:22,460 - INFO - Closing down clientserver connection
2025-05-08 06:53:22,462 - INFO - Closing down clientserver connection
2025-05-08 06:53:22,463 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 06:53:22,464 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 06:53:22,467 - INFO - Closing down clientserver connection
2025-05-08 06:53:22,468 - INFO - Closing down clientserver connection
2025-05-08 06:53:22,469 - INFO - Closing down clientserver connection
2025-05-08 06:53:22,471 - INFO - Closing down clientserver connection
2025-05-08 06:53:22,472 - INFO - Closing down clientserver connection
2025-05-08 06:53:22,472 - INFO - Closing down clientserver connection
2025-05-08 06:53:22,469 - ERROR - Error in stream_video_interactions.py: An error occurred while calling o570.select
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 382, in <module>
    # Create dim_connection_type
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 3036, in select
    jdf = self._jdf.select(self._jcols(*cols))
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 169, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o570.select
2025-05-08 06:54:11,683 - INFO - Starting stream_video_interactions.py
2025-05-08 06:54:11,693 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 06:54:11,703 - INFO - Private key loaded successfully
2025-05-08 06:54:11,704 - INFO - Snowflake configurations loaded
2025-05-08 06:54:11,712 - INFO - AWS configurations loaded
2025-05-08 06:54:28,643 - INFO - Spark session initialized
2025-05-08 06:54:28,647 - INFO - Schema defined
2025-05-08 06:55:00,843 - INFO - Kafka stream initialized
2025-05-08 06:55:07,253 - INFO - JSON parsing completed
2025-05-08 06:55:33,059 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:55:36,360 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 06:55:36,478 - INFO - Closing down clientserver connection
2025-05-08 06:56:11,880 - INFO - Starting stream_video_interactions.py
2025-05-08 06:56:11,887 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 06:56:11,964 - INFO - Private key loaded successfully
2025-05-08 06:56:11,965 - INFO - Snowflake configurations loaded
2025-05-08 06:56:11,972 - INFO - AWS configurations loaded
2025-05-08 06:56:24,162 - INFO - Spark session initialized
2025-05-08 06:56:24,163 - INFO - Schema defined
2025-05-08 06:56:48,785 - INFO - Kafka stream initialized
2025-05-08 06:56:51,765 - INFO - JSON parsing completed
2025-05-08 06:57:07,661 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:57:10,473 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 06:57:10,586 - INFO - Closing down clientserver connection
2025-05-08 06:57:31,985 - INFO - Starting stream_video_interactions.py
2025-05-08 06:57:31,991 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 06:57:31,997 - INFO - Private key loaded successfully
2025-05-08 06:57:31,998 - INFO - Snowflake configurations loaded
2025-05-08 06:57:32,061 - INFO - AWS configurations loaded
2025-05-08 06:57:42,071 - INFO - Spark session initialized
2025-05-08 06:57:42,078 - INFO - Schema defined
2025-05-08 06:58:07,590 - INFO - Kafka stream initialized
2025-05-08 06:58:11,083 - INFO - JSON parsing completed
2025-05-08 06:58:29,315 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:58:30,781 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 06:58:31,105 - INFO - Closing down clientserver connection
2025-05-08 06:58:51,099 - INFO - Starting stream_video_interactions.py
2025-05-08 06:58:51,105 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 06:58:51,111 - INFO - Private key loaded successfully
2025-05-08 06:58:51,112 - INFO - Snowflake configurations loaded
2025-05-08 06:58:51,117 - INFO - AWS configurations loaded
2025-05-08 06:59:01,897 - INFO - Spark session initialized
2025-05-08 06:59:01,898 - INFO - Schema defined
2025-05-08 06:59:24,887 - INFO - Kafka stream initialized
2025-05-08 06:59:27,999 - INFO - JSON parsing completed
2025-05-08 06:59:43,190 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 06:59:45,211 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 06:59:45,395 - INFO - Closing down clientserver connection
2025-05-08 07:00:05,894 - INFO - Starting stream_video_interactions.py
2025-05-08 07:00:05,899 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:00:05,905 - INFO - Private key loaded successfully
2025-05-08 07:00:05,906 - INFO - Snowflake configurations loaded
2025-05-08 07:00:05,911 - INFO - AWS configurations loaded
2025-05-08 07:00:19,191 - INFO - Spark session initialized
2025-05-08 07:00:19,221 - INFO - Schema defined
2025-05-08 07:00:41,409 - INFO - Kafka stream initialized
2025-05-08 07:00:43,489 - INFO - JSON parsing completed
2025-05-08 07:00:59,716 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:01:01,905 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:01:02,094 - INFO - Closing down clientserver connection
2025-05-08 07:01:24,312 - INFO - Starting stream_video_interactions.py
2025-05-08 07:01:24,319 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:01:24,327 - INFO - Private key loaded successfully
2025-05-08 07:01:24,328 - INFO - Snowflake configurations loaded
2025-05-08 07:01:24,334 - INFO - AWS configurations loaded
2025-05-08 07:01:38,308 - INFO - Spark session initialized
2025-05-08 07:01:38,309 - INFO - Schema defined
2025-05-08 07:02:00,202 - INFO - Kafka stream initialized
2025-05-08 07:02:03,603 - INFO - JSON parsing completed
2025-05-08 07:02:23,103 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:02:24,744 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:02:24,833 - INFO - Closing down clientserver connection
2025-05-08 07:02:50,048 - INFO - Starting stream_video_interactions.py
2025-05-08 07:02:50,054 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:02:50,062 - INFO - Private key loaded successfully
2025-05-08 07:02:50,063 - INFO - Snowflake configurations loaded
2025-05-08 07:02:50,068 - INFO - AWS configurations loaded
2025-05-08 07:03:04,705 - INFO - Spark session initialized
2025-05-08 07:03:04,720 - INFO - Schema defined
2025-05-08 07:03:27,936 - INFO - Kafka stream initialized
2025-05-08 07:03:30,827 - INFO - JSON parsing completed
2025-05-08 07:03:49,931 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:03:52,233 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:03:52,525 - INFO - Closing down clientserver connection
2025-05-08 07:04:18,348 - INFO - Starting stream_video_interactions.py
2025-05-08 07:04:18,416 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:04:18,426 - INFO - Private key loaded successfully
2025-05-08 07:04:18,426 - INFO - Snowflake configurations loaded
2025-05-08 07:04:18,432 - INFO - AWS configurations loaded
2025-05-08 07:04:31,522 - INFO - Spark session initialized
2025-05-08 07:04:31,523 - INFO - Schema defined
2025-05-08 07:04:54,522 - INFO - Kafka stream initialized
2025-05-08 07:04:57,910 - INFO - JSON parsing completed
2025-05-08 07:05:15,935 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:05:17,837 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:05:17,947 - INFO - Closing down clientserver connection
2025-05-08 07:05:43,945 - INFO - Starting stream_video_interactions.py
2025-05-08 07:05:44,021 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:05:44,028 - INFO - Private key loaded successfully
2025-05-08 07:05:44,029 - INFO - Snowflake configurations loaded
2025-05-08 07:05:44,035 - INFO - AWS configurations loaded
2025-05-08 07:05:56,630 - INFO - Spark session initialized
2025-05-08 07:05:56,631 - INFO - Schema defined
2025-05-08 07:06:18,838 - INFO - Kafka stream initialized
2025-05-08 07:06:21,425 - INFO - JSON parsing completed
2025-05-08 07:06:39,537 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:06:41,643 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:06:41,936 - INFO - Closing down clientserver connection
2025-05-08 07:07:04,242 - INFO - Starting stream_video_interactions.py
2025-05-08 07:07:04,249 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:07:04,257 - INFO - Private key loaded successfully
2025-05-08 07:07:04,259 - INFO - Snowflake configurations loaded
2025-05-08 07:07:04,268 - INFO - AWS configurations loaded
2025-05-08 07:07:15,951 - INFO - Spark session initialized
2025-05-08 07:07:15,951 - INFO - Schema defined
2025-05-08 07:07:38,328 - INFO - Kafka stream initialized
2025-05-08 07:07:41,259 - INFO - JSON parsing completed
2025-05-08 07:07:59,527 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:08:01,947 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:08:02,135 - INFO - Closing down clientserver connection
2025-05-08 07:08:24,979 - INFO - Starting stream_video_interactions.py
2025-05-08 07:08:25,037 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:08:25,043 - INFO - Private key loaded successfully
2025-05-08 07:08:25,044 - INFO - Snowflake configurations loaded
2025-05-08 07:08:25,049 - INFO - AWS configurations loaded
2025-05-08 07:08:35,258 - INFO - Spark session initialized
2025-05-08 07:08:35,259 - INFO - Schema defined
2025-05-08 07:08:56,446 - INFO - Kafka stream initialized
2025-05-08 07:08:59,339 - INFO - JSON parsing completed
2025-05-08 07:09:17,640 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:09:19,967 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:09:20,075 - INFO - Closing down clientserver connection
2025-05-08 07:09:42,053 - INFO - Starting stream_video_interactions.py
2025-05-08 07:09:42,129 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:09:42,138 - INFO - Private key loaded successfully
2025-05-08 07:09:42,139 - INFO - Snowflake configurations loaded
2025-05-08 07:09:42,146 - INFO - AWS configurations loaded
2025-05-08 07:09:54,924 - INFO - Spark session initialized
2025-05-08 07:09:54,926 - INFO - Schema defined
2025-05-08 07:10:18,437 - INFO - Kafka stream initialized
2025-05-08 07:10:21,137 - INFO - JSON parsing completed
2025-05-08 07:10:39,678 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:10:41,249 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:10:41,366 - INFO - Closing down clientserver connection
2025-05-08 07:11:03,276 - INFO - Starting stream_video_interactions.py
2025-05-08 07:11:03,283 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:11:03,288 - INFO - Private key loaded successfully
2025-05-08 07:11:03,336 - INFO - Snowflake configurations loaded
2025-05-08 07:11:03,352 - INFO - AWS configurations loaded
2025-05-08 07:11:16,142 - INFO - Spark session initialized
2025-05-08 07:11:16,144 - INFO - Schema defined
2025-05-08 07:11:40,069 - INFO - Kafka stream initialized
2025-05-08 07:11:43,069 - INFO - JSON parsing completed
2025-05-08 07:11:59,856 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:12:01,953 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:12:02,157 - INFO - Closing down clientserver connection
2025-05-08 07:12:23,581 - INFO - Starting stream_video_interactions.py
2025-05-08 07:12:23,589 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:12:23,657 - INFO - Private key loaded successfully
2025-05-08 07:12:23,659 - INFO - Snowflake configurations loaded
2025-05-08 07:12:23,666 - INFO - AWS configurations loaded
2025-05-08 07:12:36,070 - INFO - Spark session initialized
2025-05-08 07:12:36,071 - INFO - Schema defined
2025-05-08 07:12:58,478 - INFO - Kafka stream initialized
2025-05-08 07:13:01,768 - INFO - JSON parsing completed
2025-05-08 07:13:17,485 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:13:18,978 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:13:19,070 - INFO - Closing down clientserver connection
2025-05-08 07:13:39,394 - INFO - Starting stream_video_interactions.py
2025-05-08 07:13:39,404 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:13:39,463 - INFO - Private key loaded successfully
2025-05-08 07:13:39,465 - INFO - Snowflake configurations loaded
2025-05-08 07:13:39,473 - INFO - AWS configurations loaded
2025-05-08 07:13:51,676 - INFO - Spark session initialized
2025-05-08 07:13:51,677 - INFO - Schema defined
2025-05-08 07:14:13,060 - INFO - Kafka stream initialized
2025-05-08 07:14:15,665 - INFO - JSON parsing completed
2025-05-08 07:14:33,296 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:14:35,566 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:14:35,676 - INFO - Closing down clientserver connection
2025-05-08 07:14:57,992 - INFO - Starting stream_video_interactions.py
2025-05-08 07:14:58,000 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:14:58,007 - INFO - Private key loaded successfully
2025-05-08 07:14:58,067 - INFO - Snowflake configurations loaded
2025-05-08 07:14:58,074 - INFO - AWS configurations loaded
2025-05-08 07:15:11,576 - INFO - Spark session initialized
2025-05-08 07:15:11,578 - INFO - Schema defined
2025-05-08 07:15:34,488 - INFO - Kafka stream initialized
2025-05-08 07:15:37,389 - INFO - JSON parsing completed
2025-05-08 07:15:53,408 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:15:55,297 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:15:55,475 - INFO - Closing down clientserver connection
2025-05-08 07:16:20,584 - INFO - Starting stream_video_interactions.py
2025-05-08 07:16:20,604 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:16:20,615 - INFO - Private key loaded successfully
2025-05-08 07:16:20,677 - INFO - Snowflake configurations loaded
2025-05-08 07:16:20,686 - INFO - AWS configurations loaded
2025-05-08 07:16:34,687 - INFO - Spark session initialized
2025-05-08 07:16:34,688 - INFO - Schema defined
2025-05-08 07:16:54,413 - INFO - Kafka stream initialized
2025-05-08 07:16:57,380 - INFO - JSON parsing completed
2025-05-08 07:17:15,086 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:17:16,710 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:17:16,813 - INFO - Closing down clientserver connection
2025-05-08 07:17:40,405 - INFO - Starting stream_video_interactions.py
2025-05-08 07:17:40,411 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:17:40,418 - INFO - Private key loaded successfully
2025-05-08 07:17:40,419 - INFO - Snowflake configurations loaded
2025-05-08 07:17:40,424 - INFO - AWS configurations loaded
2025-05-08 07:17:51,896 - INFO - Spark session initialized
2025-05-08 07:17:51,898 - INFO - Schema defined
2025-05-08 07:18:15,001 - INFO - Kafka stream initialized
2025-05-08 07:18:18,798 - INFO - JSON parsing completed
2025-05-08 07:18:36,522 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:18:38,437 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:18:38,540 - INFO - Closing down clientserver connection
2025-05-08 07:19:01,635 - INFO - Starting stream_video_interactions.py
2025-05-08 07:19:01,644 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:19:01,651 - INFO - Private key loaded successfully
2025-05-08 07:19:01,652 - INFO - Snowflake configurations loaded
2025-05-08 07:19:01,658 - INFO - AWS configurations loaded
2025-05-08 07:19:14,306 - INFO - Spark session initialized
2025-05-08 07:19:14,311 - INFO - Schema defined
2025-05-08 07:19:35,428 - INFO - Kafka stream initialized
2025-05-08 07:19:38,517 - INFO - JSON parsing completed
2025-05-08 07:19:56,625 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:19:59,027 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:19:59,224 - INFO - Closing down clientserver connection
2025-05-08 07:20:20,442 - INFO - Starting stream_video_interactions.py
2025-05-08 07:20:20,512 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:20:20,522 - INFO - Private key loaded successfully
2025-05-08 07:20:20,523 - INFO - Snowflake configurations loaded
2025-05-08 07:20:20,531 - INFO - AWS configurations loaded
2025-05-08 07:20:32,716 - INFO - Spark session initialized
2025-05-08 07:20:32,718 - INFO - Schema defined
2025-05-08 07:20:52,819 - INFO - Kafka stream initialized
2025-05-08 07:20:56,219 - INFO - JSON parsing completed
2025-05-08 07:21:11,812 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:21:14,034 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:21:14,231 - INFO - Closing down clientserver connection
2025-05-08 07:21:37,133 - INFO - Starting stream_video_interactions.py
2025-05-08 07:21:37,140 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:21:37,146 - INFO - Private key loaded successfully
2025-05-08 07:21:37,147 - INFO - Snowflake configurations loaded
2025-05-08 07:21:37,218 - INFO - AWS configurations loaded
2025-05-08 07:21:47,427 - INFO - Spark session initialized
2025-05-08 07:21:47,429 - INFO - Schema defined
2025-05-08 07:22:09,146 - INFO - Kafka stream initialized
2025-05-08 07:22:12,323 - INFO - JSON parsing completed
2025-05-08 07:22:27,422 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:22:29,031 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:22:29,236 - INFO - Closing down clientserver connection
2025-05-08 07:22:50,638 - INFO - Starting stream_video_interactions.py
2025-05-08 07:22:50,646 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:22:50,656 - INFO - Private key loaded successfully
2025-05-08 07:22:50,657 - INFO - Snowflake configurations loaded
2025-05-08 07:22:50,665 - INFO - AWS configurations loaded
2025-05-08 07:23:00,932 - INFO - Spark session initialized
2025-05-08 07:23:00,933 - INFO - Schema defined
2025-05-08 07:23:21,055 - INFO - Kafka stream initialized
2025-05-08 07:23:24,248 - INFO - JSON parsing completed
2025-05-08 07:23:41,650 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:23:42,733 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:23:42,858 - INFO - Closing down clientserver connection
2025-05-08 07:24:04,558 - INFO - Starting stream_video_interactions.py
2025-05-08 07:24:04,632 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:24:04,639 - INFO - Private key loaded successfully
2025-05-08 07:24:04,641 - INFO - Snowflake configurations loaded
2025-05-08 07:24:04,648 - INFO - AWS configurations loaded
2025-05-08 07:24:16,854 - INFO - Spark session initialized
2025-05-08 07:24:16,855 - INFO - Schema defined
2025-05-08 07:24:37,426 - INFO - Kafka stream initialized
2025-05-08 07:24:40,536 - INFO - JSON parsing completed
2025-05-08 07:24:56,755 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:24:58,838 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:24:58,956 - INFO - Closing down clientserver connection
2025-05-08 07:25:20,453 - INFO - Starting stream_video_interactions.py
2025-05-08 07:25:20,461 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:25:20,472 - INFO - Private key loaded successfully
2025-05-08 07:25:20,529 - INFO - Snowflake configurations loaded
2025-05-08 07:25:20,537 - INFO - AWS configurations loaded
2025-05-08 07:25:33,043 - INFO - Spark session initialized
2025-05-08 07:25:33,044 - INFO - Schema defined
2025-05-08 07:25:53,465 - INFO - Kafka stream initialized
2025-05-08 07:25:55,830 - INFO - JSON parsing completed
2025-05-08 07:26:10,834 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:26:13,141 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:26:13,338 - INFO - Closing down clientserver connection
2025-05-08 07:26:34,061 - INFO - Starting stream_video_interactions.py
2025-05-08 07:26:34,068 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:26:34,078 - INFO - Private key loaded successfully
2025-05-08 07:26:34,127 - INFO - Snowflake configurations loaded
2025-05-08 07:26:34,134 - INFO - AWS configurations loaded
2025-05-08 07:26:45,750 - INFO - Spark session initialized
2025-05-08 07:26:45,751 - INFO - Schema defined
2025-05-08 07:27:08,653 - INFO - Kafka stream initialized
2025-05-08 07:27:11,753 - INFO - JSON parsing completed
2025-05-08 07:27:28,254 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:27:29,939 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:27:30,044 - INFO - Closing down clientserver connection
2025-05-08 07:27:50,733 - INFO - Starting stream_video_interactions.py
2025-05-08 07:27:50,740 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:27:50,748 - INFO - Private key loaded successfully
2025-05-08 07:27:50,750 - INFO - Snowflake configurations loaded
2025-05-08 07:27:50,754 - INFO - AWS configurations loaded
2025-05-08 07:28:02,643 - INFO - Spark session initialized
2025-05-08 07:28:02,644 - INFO - Schema defined
2025-05-08 07:28:22,658 - INFO - Kafka stream initialized
2025-05-08 07:28:25,534 - INFO - JSON parsing completed
2025-05-08 07:28:40,647 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:28:42,141 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:28:42,266 - INFO - Closing down clientserver connection
2025-05-08 07:29:01,352 - INFO - Starting stream_video_interactions.py
2025-05-08 07:29:01,362 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:29:01,369 - INFO - Private key loaded successfully
2025-05-08 07:29:01,370 - INFO - Snowflake configurations loaded
2025-05-08 07:29:01,377 - INFO - AWS configurations loaded
2025-05-08 07:29:14,644 - INFO - Spark session initialized
2025-05-08 07:29:14,645 - INFO - Schema defined
2025-05-08 07:29:33,661 - INFO - Kafka stream initialized
2025-05-08 07:29:35,971 - INFO - JSON parsing completed
2025-05-08 07:29:50,767 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:29:52,274 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:29:52,373 - INFO - Closing down clientserver connection
2025-05-08 07:30:10,373 - INFO - Starting stream_video_interactions.py
2025-05-08 07:30:10,381 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:30:10,453 - INFO - Private key loaded successfully
2025-05-08 07:30:10,454 - INFO - Snowflake configurations loaded
2025-05-08 07:30:10,461 - INFO - AWS configurations loaded
2025-05-08 07:30:21,664 - INFO - Spark session initialized
2025-05-08 07:30:21,665 - INFO - Schema defined
2025-05-08 07:30:39,346 - INFO - Kafka stream initialized
2025-05-08 07:30:41,956 - INFO - JSON parsing completed
2025-05-08 07:30:56,063 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:30:57,740 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:30:57,858 - INFO - Closing down clientserver connection
2025-05-08 07:31:17,944 - INFO - Starting stream_video_interactions.py
2025-05-08 07:31:17,950 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:31:17,957 - INFO - Private key loaded successfully
2025-05-08 07:31:17,958 - INFO - Snowflake configurations loaded
2025-05-08 07:31:17,964 - INFO - AWS configurations loaded
2025-05-08 07:31:28,266 - INFO - Spark session initialized
2025-05-08 07:31:28,267 - INFO - Schema defined
2025-05-08 07:31:46,951 - INFO - Kafka stream initialized
2025-05-08 07:31:49,668 - INFO - JSON parsing completed
2025-05-08 07:32:04,237 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:32:05,934 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:32:06,043 - INFO - Closing down clientserver connection
2025-05-08 07:32:25,043 - INFO - Starting stream_video_interactions.py
2025-05-08 07:32:25,049 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:32:25,061 - INFO - Private key loaded successfully
2025-05-08 07:32:25,062 - INFO - Snowflake configurations loaded
2025-05-08 07:32:25,067 - INFO - AWS configurations loaded
2025-05-08 07:32:35,541 - INFO - Spark session initialized
2025-05-08 07:32:35,542 - INFO - Schema defined
2025-05-08 07:32:52,242 - INFO - Kafka stream initialized
2025-05-08 07:32:54,858 - INFO - JSON parsing completed
2025-05-08 07:33:10,055 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:33:11,956 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:33:12,148 - INFO - Closing down clientserver connection
2025-05-08 07:33:32,544 - INFO - Starting stream_video_interactions.py
2025-05-08 07:33:32,556 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:33:32,562 - INFO - Private key loaded successfully
2025-05-08 07:33:32,563 - INFO - Snowflake configurations loaded
2025-05-08 07:33:32,567 - INFO - AWS configurations loaded
2025-05-08 07:33:42,844 - INFO - Spark session initialized
2025-05-08 07:33:42,845 - INFO - Schema defined
2025-05-08 07:34:00,736 - INFO - Kafka stream initialized
2025-05-08 07:34:03,555 - INFO - JSON parsing completed
2025-05-08 07:34:19,553 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:34:21,738 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:34:21,866 - INFO - Closing down clientserver connection
2025-05-08 07:34:42,443 - INFO - Starting stream_video_interactions.py
2025-05-08 07:34:42,468 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:34:42,534 - INFO - Private key loaded successfully
2025-05-08 07:34:42,535 - INFO - Snowflake configurations loaded
2025-05-08 07:34:42,543 - INFO - AWS configurations loaded
2025-05-08 07:34:51,860 - INFO - Spark session initialized
2025-05-08 07:34:51,860 - INFO - Schema defined
2025-05-08 07:35:12,838 - INFO - Kafka stream initialized
2025-05-08 07:35:15,370 - INFO - JSON parsing completed
2025-05-08 07:35:32,247 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:35:33,854 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:35:33,961 - INFO - Closing down clientserver connection
2025-05-08 07:35:52,350 - INFO - Starting stream_video_interactions.py
2025-05-08 07:35:52,356 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:35:52,363 - INFO - Private key loaded successfully
2025-05-08 07:35:52,364 - INFO - Snowflake configurations loaded
2025-05-08 07:35:52,369 - INFO - AWS configurations loaded
2025-05-08 07:36:02,460 - INFO - Spark session initialized
2025-05-08 07:36:02,461 - INFO - Schema defined
2025-05-08 07:36:22,246 - INFO - Kafka stream initialized
2025-05-08 07:36:25,257 - INFO - JSON parsing completed
2025-05-08 07:36:42,336 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:36:44,237 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:36:44,357 - INFO - Closing down clientserver connection
2025-05-08 07:37:04,270 - INFO - Starting stream_video_interactions.py
2025-05-08 07:37:04,277 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:37:04,284 - INFO - Private key loaded successfully
2025-05-08 07:37:04,331 - INFO - Snowflake configurations loaded
2025-05-08 07:37:04,336 - INFO - AWS configurations loaded
2025-05-08 07:37:15,037 - INFO - Spark session initialized
2025-05-08 07:37:15,038 - INFO - Schema defined
2025-05-08 07:37:33,345 - INFO - Kafka stream initialized
2025-05-08 07:37:36,248 - INFO - JSON parsing completed
2025-05-08 07:37:50,546 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:37:52,839 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:37:52,957 - INFO - Closing down clientserver connection
2025-05-08 07:38:11,443 - INFO - Starting stream_video_interactions.py
2025-05-08 07:38:11,451 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:38:11,459 - INFO - Private key loaded successfully
2025-05-08 07:38:11,460 - INFO - Snowflake configurations loaded
2025-05-08 07:38:11,465 - INFO - AWS configurations loaded
2025-05-08 07:38:22,148 - INFO - Spark session initialized
2025-05-08 07:38:22,149 - INFO - Schema defined
2025-05-08 07:38:42,131 - INFO - Kafka stream initialized
2025-05-08 07:38:43,945 - INFO - JSON parsing completed
2025-05-08 07:38:59,744 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:39:01,253 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:39:01,349 - INFO - Closing down clientserver connection
2025-05-08 07:39:23,143 - INFO - Starting stream_video_interactions.py
2025-05-08 07:39:23,149 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:39:23,233 - INFO - Private key loaded successfully
2025-05-08 07:39:23,235 - INFO - Snowflake configurations loaded
2025-05-08 07:39:23,247 - INFO - AWS configurations loaded
2025-05-08 07:39:33,257 - INFO - Spark session initialized
2025-05-08 07:39:33,258 - INFO - Schema defined
2025-05-08 07:39:53,250 - INFO - Kafka stream initialized
2025-05-08 07:39:55,726 - INFO - JSON parsing completed
2025-05-08 07:40:10,138 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:40:11,942 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:40:12,060 - INFO - Closing down clientserver connection
2025-05-08 07:40:32,556 - INFO - Starting stream_video_interactions.py
2025-05-08 07:40:32,626 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:40:32,631 - INFO - Private key loaded successfully
2025-05-08 07:40:32,632 - INFO - Snowflake configurations loaded
2025-05-08 07:40:32,636 - INFO - AWS configurations loaded
2025-05-08 07:40:42,953 - INFO - Spark session initialized
2025-05-08 07:40:42,955 - INFO - Schema defined
2025-05-08 07:41:02,151 - INFO - Kafka stream initialized
2025-05-08 07:41:05,324 - INFO - JSON parsing completed
2025-05-08 07:41:19,151 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:41:20,729 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:41:20,847 - INFO - Closing down clientserver connection
2025-05-08 07:41:40,540 - INFO - Starting stream_video_interactions.py
2025-05-08 07:41:40,550 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:41:40,556 - INFO - Private key loaded successfully
2025-05-08 07:41:40,557 - INFO - Snowflake configurations loaded
2025-05-08 07:41:40,564 - INFO - AWS configurations loaded
2025-05-08 07:41:53,160 - INFO - Spark session initialized
2025-05-08 07:41:53,161 - INFO - Schema defined
2025-05-08 07:42:11,349 - INFO - Kafka stream initialized
2025-05-08 07:42:13,145 - INFO - JSON parsing completed
2025-05-08 07:42:28,329 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:42:30,030 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:42:30,145 - INFO - Closing down clientserver connection
2025-05-08 07:42:48,955 - INFO - Starting stream_video_interactions.py
2025-05-08 07:42:48,963 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:42:49,031 - INFO - Private key loaded successfully
2025-05-08 07:42:49,032 - INFO - Snowflake configurations loaded
2025-05-08 07:42:49,038 - INFO - AWS configurations loaded
2025-05-08 07:42:59,232 - INFO - Spark session initialized
2025-05-08 07:42:59,233 - INFO - Schema defined
2025-05-08 07:43:18,449 - INFO - Kafka stream initialized
2025-05-08 07:43:21,252 - INFO - JSON parsing completed
2025-05-08 07:43:37,525 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:43:39,627 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:43:39,734 - INFO - Closing down clientserver connection
2025-05-08 07:43:59,957 - INFO - Starting stream_video_interactions.py
2025-05-08 07:44:00,024 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:44:00,032 - INFO - Private key loaded successfully
2025-05-08 07:44:00,033 - INFO - Snowflake configurations loaded
2025-05-08 07:44:00,038 - INFO - AWS configurations loaded
2025-05-08 07:44:10,534 - INFO - Spark session initialized
2025-05-08 07:44:10,535 - INFO - Schema defined
2025-05-08 07:44:28,622 - INFO - Kafka stream initialized
2025-05-08 07:44:30,938 - INFO - JSON parsing completed
2025-05-08 07:44:47,019 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:44:48,523 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:44:48,632 - INFO - Closing down clientserver connection
2025-05-08 07:45:10,528 - INFO - Starting stream_video_interactions.py
2025-05-08 07:45:10,536 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:45:10,541 - INFO - Private key loaded successfully
2025-05-08 07:45:10,542 - INFO - Snowflake configurations loaded
2025-05-08 07:45:10,547 - INFO - AWS configurations loaded
2025-05-08 07:45:21,623 - INFO - Spark session initialized
2025-05-08 07:45:21,625 - INFO - Schema defined
2025-05-08 07:45:38,532 - INFO - Kafka stream initialized
2025-05-08 07:45:41,214 - INFO - JSON parsing completed
2025-05-08 07:45:55,432 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:45:57,015 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:45:57,121 - INFO - Closing down clientserver connection
2025-05-08 07:46:18,146 - INFO - Starting stream_video_interactions.py
2025-05-08 07:46:18,151 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:46:18,156 - INFO - Private key loaded successfully
2025-05-08 07:46:18,157 - INFO - Snowflake configurations loaded
2025-05-08 07:46:18,218 - INFO - AWS configurations loaded
2025-05-08 07:46:27,934 - INFO - Spark session initialized
2025-05-08 07:46:27,935 - INFO - Schema defined
2025-05-08 07:46:47,419 - INFO - Kafka stream initialized
2025-05-08 07:46:49,834 - INFO - JSON parsing completed
2025-05-08 07:47:05,410 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:47:07,321 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:47:07,440 - INFO - Closing down clientserver connection
2025-05-08 07:47:27,651 - INFO - Starting stream_video_interactions.py
2025-05-08 07:47:27,657 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:47:27,665 - INFO - Private key loaded successfully
2025-05-08 07:47:27,666 - INFO - Snowflake configurations loaded
2025-05-08 07:47:27,717 - INFO - AWS configurations loaded
2025-05-08 07:47:38,336 - INFO - Spark session initialized
2025-05-08 07:47:38,337 - INFO - Schema defined
2025-05-08 07:47:57,923 - INFO - Kafka stream initialized
2025-05-08 07:48:00,613 - INFO - JSON parsing completed
2025-05-08 07:48:17,432 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:48:18,838 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:48:18,950 - INFO - Closing down clientserver connection
2025-05-08 07:48:38,438 - INFO - Starting stream_video_interactions.py
2025-05-08 07:48:38,443 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:48:38,448 - INFO - Private key loaded successfully
2025-05-08 07:48:38,507 - INFO - Snowflake configurations loaded
2025-05-08 07:48:38,512 - INFO - AWS configurations loaded
2025-05-08 07:48:48,620 - INFO - Spark session initialized
2025-05-08 07:48:48,621 - INFO - Schema defined
2025-05-08 07:49:07,813 - INFO - Kafka stream initialized
2025-05-08 07:49:10,931 - INFO - JSON parsing completed
2025-05-08 07:49:24,507 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:49:26,429 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:49:26,621 - INFO - Closing down clientserver connection
2025-05-08 07:49:45,143 - INFO - Starting stream_video_interactions.py
2025-05-08 07:49:45,210 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:49:45,218 - INFO - Private key loaded successfully
2025-05-08 07:49:45,219 - INFO - Snowflake configurations loaded
2025-05-08 07:49:45,227 - INFO - AWS configurations loaded
2025-05-08 07:49:55,626 - INFO - Spark session initialized
2025-05-08 07:49:55,630 - INFO - Schema defined
2025-05-08 07:50:18,205 - INFO - Kafka stream initialized
2025-05-08 07:50:21,427 - INFO - JSON parsing completed
2025-05-08 07:50:36,312 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:50:37,799 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:50:37,918 - INFO - Closing down clientserver connection
2025-05-08 07:50:55,030 - INFO - Starting stream_video_interactions.py
2025-05-08 07:50:55,038 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:50:55,097 - INFO - Private key loaded successfully
2025-05-08 07:50:55,098 - INFO - Snowflake configurations loaded
2025-05-08 07:50:55,103 - INFO - AWS configurations loaded
2025-05-08 07:51:05,423 - INFO - Spark session initialized
2025-05-08 07:51:05,424 - INFO - Schema defined
2025-05-08 07:51:25,650 - INFO - Kafka stream initialized
2025-05-08 07:51:27,499 - INFO - JSON parsing completed
2025-05-08 07:51:42,720 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:51:44,018 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:51:44,120 - INFO - Closing down clientserver connection
2025-05-08 07:52:02,594 - INFO - Starting stream_video_interactions.py
2025-05-08 07:52:02,604 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:52:02,612 - INFO - Private key loaded successfully
2025-05-08 07:52:02,613 - INFO - Snowflake configurations loaded
2025-05-08 07:52:02,617 - INFO - AWS configurations loaded
2025-05-08 07:52:13,421 - INFO - Spark session initialized
2025-05-08 07:52:13,423 - INFO - Schema defined
2025-05-08 07:52:32,710 - INFO - Kafka stream initialized
2025-05-08 07:52:35,191 - INFO - JSON parsing completed
2025-05-08 07:52:50,709 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:52:52,604 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:52:52,721 - INFO - Closing down clientserver connection
2025-05-08 07:53:13,157 - INFO - Starting stream_video_interactions.py
2025-05-08 07:53:13,163 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:53:13,169 - INFO - Private key loaded successfully
2025-05-08 07:53:13,170 - INFO - Snowflake configurations loaded
2025-05-08 07:53:13,176 - INFO - AWS configurations loaded
2025-05-08 07:53:24,521 - INFO - Spark session initialized
2025-05-08 07:53:24,523 - INFO - Schema defined
2025-05-08 07:53:43,597 - INFO - Kafka stream initialized
2025-05-08 07:53:46,009 - INFO - JSON parsing completed
2025-05-08 07:54:00,201 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:54:02,297 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:54:02,335 - INFO - Closing down clientserver connection
2025-05-08 07:54:21,693 - INFO - Starting stream_video_interactions.py
2025-05-08 07:54:21,701 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:54:21,710 - INFO - Private key loaded successfully
2025-05-08 07:54:21,711 - INFO - Snowflake configurations loaded
2025-05-08 07:54:21,717 - INFO - AWS configurations loaded
2025-05-08 07:54:33,400 - INFO - Spark session initialized
2025-05-08 07:54:33,401 - INFO - Schema defined
2025-05-08 07:54:51,593 - INFO - Kafka stream initialized
2025-05-08 07:54:53,701 - INFO - JSON parsing completed
2025-05-08 07:55:08,599 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:55:10,212 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:55:10,321 - INFO - Closing down clientserver connection
2025-05-08 07:55:32,301 - INFO - Starting stream_video_interactions.py
2025-05-08 07:55:32,307 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:55:32,314 - INFO - Private key loaded successfully
2025-05-08 07:55:32,315 - INFO - Snowflake configurations loaded
2025-05-08 07:55:32,377 - INFO - AWS configurations loaded
2025-05-08 07:55:42,691 - INFO - Spark session initialized
2025-05-08 07:55:42,692 - INFO - Schema defined
2025-05-08 07:55:59,897 - INFO - Kafka stream initialized
2025-05-08 07:56:02,488 - INFO - JSON parsing completed
2025-05-08 07:56:17,792 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:56:19,136 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:56:19,209 - INFO - Closing down clientserver connection
2025-05-08 07:56:41,081 - INFO - Starting stream_video_interactions.py
2025-05-08 07:56:41,089 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:56:41,096 - INFO - Private key loaded successfully
2025-05-08 07:56:41,097 - INFO - Snowflake configurations loaded
2025-05-08 07:56:41,102 - INFO - AWS configurations loaded
2025-05-08 07:56:51,793 - INFO - Spark session initialized
2025-05-08 07:56:51,794 - INFO - Schema defined
2025-05-08 07:57:07,915 - INFO - Kafka stream initialized
2025-05-08 07:57:10,079 - INFO - JSON parsing completed
2025-05-08 07:57:24,278 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:57:26,289 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:57:26,481 - INFO - Closing down clientserver connection
2025-05-08 07:57:48,388 - INFO - Starting stream_video_interactions.py
2025-05-08 07:57:48,395 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:57:48,401 - INFO - Private key loaded successfully
2025-05-08 07:57:48,402 - INFO - Snowflake configurations loaded
2025-05-08 07:57:48,462 - INFO - AWS configurations loaded
2025-05-08 07:57:56,662 - INFO - Spark session initialized
2025-05-08 07:57:56,666 - INFO - Schema defined
2025-05-08 07:58:16,160 - INFO - Kafka stream initialized
2025-05-08 07:58:18,359 - INFO - JSON parsing completed
2025-05-08 07:58:35,252 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:58:37,162 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:58:37,272 - INFO - Closing down clientserver connection
2025-05-08 07:58:55,896 - INFO - Starting stream_video_interactions.py
2025-05-08 07:58:55,957 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 07:58:55,967 - INFO - Private key loaded successfully
2025-05-08 07:58:55,968 - INFO - Snowflake configurations loaded
2025-05-08 07:58:55,975 - INFO - AWS configurations loaded
2025-05-08 07:59:07,563 - INFO - Spark session initialized
2025-05-08 07:59:07,564 - INFO - Schema defined
2025-05-08 07:59:27,766 - INFO - Kafka stream initialized
2025-05-08 07:59:30,274 - INFO - JSON parsing completed
2025-05-08 07:59:45,452 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 07:59:47,375 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 07:59:47,565 - INFO - Closing down clientserver connection
2025-05-08 08:00:07,057 - INFO - Starting stream_video_interactions.py
2025-05-08 08:00:07,063 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:00:07,070 - INFO - Private key loaded successfully
2025-05-08 08:00:07,071 - INFO - Snowflake configurations loaded
2025-05-08 08:00:07,076 - INFO - AWS configurations loaded
2025-05-08 08:00:18,069 - INFO - Spark session initialized
2025-05-08 08:00:18,070 - INFO - Schema defined
2025-05-08 08:00:36,769 - INFO - Kafka stream initialized
2025-05-08 08:00:39,645 - INFO - JSON parsing completed
2025-05-08 08:00:53,143 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:00:54,760 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:00:54,950 - INFO - Closing down clientserver connection
2025-05-08 08:01:12,677 - INFO - Starting stream_video_interactions.py
2025-05-08 08:01:12,742 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:01:12,752 - INFO - Private key loaded successfully
2025-05-08 08:01:12,753 - INFO - Snowflake configurations loaded
2025-05-08 08:01:12,757 - INFO - AWS configurations loaded
2025-05-08 08:01:23,946 - INFO - Spark session initialized
2025-05-08 08:01:23,948 - INFO - Schema defined
2025-05-08 08:01:42,951 - INFO - Kafka stream initialized
2025-05-08 08:01:45,665 - INFO - JSON parsing completed
2025-05-08 08:02:01,258 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:02:03,554 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:02:03,680 - INFO - Closing down clientserver connection
2025-05-08 08:02:23,959 - INFO - Starting stream_video_interactions.py
2025-05-08 08:02:23,965 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:02:23,973 - INFO - Private key loaded successfully
2025-05-08 08:02:23,974 - INFO - Snowflake configurations loaded
2025-05-08 08:02:23,979 - INFO - AWS configurations loaded
2025-05-08 08:02:33,540 - INFO - Spark session initialized
2025-05-08 08:02:33,541 - INFO - Schema defined
2025-05-08 08:02:52,433 - INFO - Kafka stream initialized
2025-05-08 08:02:54,939 - INFO - JSON parsing completed
2025-05-08 08:03:09,859 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:03:11,460 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:03:11,558 - INFO - Closing down clientserver connection
2025-05-08 08:03:33,050 - INFO - Starting stream_video_interactions.py
2025-05-08 08:03:33,059 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:03:33,065 - INFO - Private key loaded successfully
2025-05-08 08:03:33,123 - INFO - Snowflake configurations loaded
2025-05-08 08:03:33,128 - INFO - AWS configurations loaded
2025-05-08 08:03:44,537 - INFO - Spark session initialized
2025-05-08 08:03:44,538 - INFO - Schema defined
2025-05-08 08:04:03,139 - INFO - Kafka stream initialized
2025-05-08 08:04:06,448 - INFO - JSON parsing completed
2025-05-08 08:04:20,043 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:04:21,941 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:04:22,060 - INFO - Closing down clientserver connection
2025-05-08 08:04:41,722 - INFO - Starting stream_video_interactions.py
2025-05-08 08:04:41,731 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:04:41,740 - INFO - Private key loaded successfully
2025-05-08 08:04:41,741 - INFO - Snowflake configurations loaded
2025-05-08 08:04:41,747 - INFO - AWS configurations loaded
2025-05-08 08:04:53,946 - INFO - Spark session initialized
2025-05-08 08:04:53,953 - INFO - Schema defined
2025-05-08 08:05:11,713 - INFO - Kafka stream initialized
2025-05-08 08:05:14,230 - INFO - JSON parsing completed
2025-05-08 08:05:28,919 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:05:31,218 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:05:31,336 - INFO - Closing down clientserver connection
2025-05-08 08:05:52,516 - INFO - Starting stream_video_interactions.py
2025-05-08 08:05:52,524 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:05:52,532 - INFO - Private key loaded successfully
2025-05-08 08:05:52,533 - INFO - Snowflake configurations loaded
2025-05-08 08:05:52,607 - INFO - AWS configurations loaded
2025-05-08 08:06:02,640 - INFO - Spark session initialized
2025-05-08 08:06:02,641 - INFO - Schema defined
2025-05-08 08:06:19,544 - INFO - Kafka stream initialized
2025-05-08 08:06:22,216 - INFO - JSON parsing completed
2025-05-08 08:06:36,502 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:06:38,524 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:06:38,725 - INFO - Closing down clientserver connection
2025-05-08 08:06:59,729 - INFO - Starting stream_video_interactions.py
2025-05-08 08:06:59,737 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:06:59,742 - INFO - Private key loaded successfully
2025-05-08 08:06:59,791 - INFO - Snowflake configurations loaded
2025-05-08 08:06:59,799 - INFO - AWS configurations loaded
2025-05-08 08:07:09,509 - INFO - Spark session initialized
2025-05-08 08:07:09,511 - INFO - Schema defined
2025-05-08 08:07:26,496 - INFO - Kafka stream initialized
2025-05-08 08:07:28,907 - INFO - JSON parsing completed
2025-05-08 08:07:44,814 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:07:45,794 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:07:45,834 - INFO - Closing down clientserver connection
2025-05-08 08:08:07,419 - INFO - Starting stream_video_interactions.py
2025-05-08 08:08:07,489 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:08:07,495 - INFO - Private key loaded successfully
2025-05-08 08:08:07,497 - INFO - Snowflake configurations loaded
2025-05-08 08:08:07,503 - INFO - AWS configurations loaded
2025-05-08 08:08:19,011 - INFO - Spark session initialized
2025-05-08 08:08:19,013 - INFO - Schema defined
2025-05-08 08:08:37,308 - INFO - Kafka stream initialized
2025-05-08 08:08:40,100 - INFO - JSON parsing completed
2025-05-08 08:08:55,200 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:08:56,692 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:08:56,798 - INFO - Closing down clientserver connection
2025-05-08 08:09:17,075 - INFO - Starting stream_video_interactions.py
2025-05-08 08:09:17,083 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:09:17,091 - INFO - Private key loaded successfully
2025-05-08 08:09:17,092 - INFO - Snowflake configurations loaded
2025-05-08 08:09:17,099 - INFO - AWS configurations loaded
2025-05-08 08:09:26,777 - INFO - Spark session initialized
2025-05-08 08:09:26,786 - INFO - Schema defined
2025-05-08 08:09:47,280 - INFO - Kafka stream initialized
2025-05-08 08:09:50,270 - INFO - JSON parsing completed
2025-05-08 08:10:05,700 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:10:07,692 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:10:07,791 - INFO - Closing down clientserver connection
2025-05-08 08:10:27,487 - INFO - Starting stream_video_interactions.py
2025-05-08 08:10:27,493 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:10:27,499 - INFO - Private key loaded successfully
2025-05-08 08:10:27,500 - INFO - Snowflake configurations loaded
2025-05-08 08:10:27,505 - INFO - AWS configurations loaded
2025-05-08 08:10:38,084 - INFO - Spark session initialized
2025-05-08 08:10:38,085 - INFO - Schema defined
2025-05-08 08:10:56,059 - INFO - Kafka stream initialized
2025-05-08 08:10:58,982 - INFO - JSON parsing completed
2025-05-08 08:11:14,678 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:11:16,071 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:11:16,170 - INFO - Closing down clientserver connection
2025-05-08 08:11:35,785 - INFO - Starting stream_video_interactions.py
2025-05-08 08:11:35,790 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:11:35,796 - INFO - Private key loaded successfully
2025-05-08 08:11:35,856 - INFO - Snowflake configurations loaded
2025-05-08 08:11:35,864 - INFO - AWS configurations loaded
2025-05-08 08:11:46,985 - INFO - Spark session initialized
2025-05-08 08:11:46,986 - INFO - Schema defined
2025-05-08 08:12:05,978 - INFO - Kafka stream initialized
2025-05-08 08:12:08,467 - INFO - JSON parsing completed
2025-05-08 08:12:22,168 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:12:24,054 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:12:24,186 - INFO - Closing down clientserver connection
2025-05-08 08:12:43,558 - INFO - Starting stream_video_interactions.py
2025-05-08 08:12:43,567 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:12:43,574 - INFO - Private key loaded successfully
2025-05-08 08:12:43,575 - INFO - Snowflake configurations loaded
2025-05-08 08:12:43,581 - INFO - AWS configurations loaded
2025-05-08 08:12:54,578 - INFO - Spark session initialized
2025-05-08 08:12:54,579 - INFO - Schema defined
2025-05-08 08:13:13,261 - INFO - Kafka stream initialized
2025-05-08 08:13:15,077 - INFO - JSON parsing completed
2025-05-08 08:13:29,644 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:13:31,243 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:13:31,285 - INFO - Closing down clientserver connection
2025-05-08 08:13:51,841 - INFO - Starting stream_video_interactions.py
2025-05-08 08:13:51,847 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:13:51,852 - INFO - Private key loaded successfully
2025-05-08 08:13:51,854 - INFO - Snowflake configurations loaded
2025-05-08 08:13:51,862 - INFO - AWS configurations loaded
2025-05-08 08:14:02,937 - INFO - Spark session initialized
2025-05-08 08:14:02,958 - INFO - Schema defined
2025-05-08 08:14:22,572 - INFO - Kafka stream initialized
2025-05-08 08:14:25,338 - INFO - JSON parsing completed
2025-05-08 08:14:39,731 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:14:41,255 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:14:41,530 - INFO - Closing down clientserver connection
2025-05-08 08:15:01,947 - INFO - Starting stream_video_interactions.py
2025-05-08 08:15:01,952 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:15:01,957 - INFO - Private key loaded successfully
2025-05-08 08:15:01,958 - INFO - Snowflake configurations loaded
2025-05-08 08:15:01,962 - INFO - AWS configurations loaded
2025-05-08 08:15:13,635 - INFO - Spark session initialized
2025-05-08 08:15:13,640 - INFO - Schema defined
2025-05-08 08:15:34,128 - INFO - Kafka stream initialized
2025-05-08 08:15:36,630 - INFO - JSON parsing completed
2025-05-08 08:15:50,945 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:15:52,856 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:15:52,949 - INFO - Closing down clientserver connection
2025-05-08 08:16:14,618 - INFO - Starting stream_video_interactions.py
2025-05-08 08:16:14,632 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:16:14,721 - INFO - Private key loaded successfully
2025-05-08 08:16:14,724 - INFO - Snowflake configurations loaded
2025-05-08 08:16:14,731 - INFO - AWS configurations loaded
2025-05-08 08:16:26,713 - INFO - Spark session initialized
2025-05-08 08:16:26,714 - INFO - Schema defined
2025-05-08 08:16:47,827 - INFO - Kafka stream initialized
2025-05-08 08:16:50,829 - INFO - JSON parsing completed
2025-05-08 08:17:09,128 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:17:11,302 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:17:11,409 - INFO - Closing down clientserver connection
2025-05-08 08:17:36,101 - INFO - Starting stream_video_interactions.py
2025-05-08 08:17:36,106 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:17:36,113 - INFO - Private key loaded successfully
2025-05-08 08:17:36,114 - INFO - Snowflake configurations loaded
2025-05-08 08:17:36,118 - INFO - AWS configurations loaded
2025-05-08 08:17:46,998 - INFO - Spark session initialized
2025-05-08 08:17:47,001 - INFO - Schema defined
2025-05-08 08:18:07,395 - INFO - Kafka stream initialized
2025-05-08 08:18:09,891 - INFO - JSON parsing completed
2025-05-08 08:18:25,995 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:18:27,905 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:18:28,112 - INFO - Closing down clientserver connection
2025-05-08 08:18:48,409 - INFO - Starting stream_video_interactions.py
2025-05-08 08:18:48,490 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:18:48,500 - INFO - Private key loaded successfully
2025-05-08 08:18:48,501 - INFO - Snowflake configurations loaded
2025-05-08 08:18:48,510 - INFO - AWS configurations loaded
2025-05-08 08:19:01,394 - INFO - Spark session initialized
2025-05-08 08:19:01,397 - INFO - Schema defined
2025-05-08 08:19:20,683 - INFO - Kafka stream initialized
2025-05-08 08:19:23,197 - INFO - JSON parsing completed
2025-05-08 08:19:40,392 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:19:42,290 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:19:42,580 - INFO - Closing down clientserver connection
2025-05-08 08:20:05,768 - INFO - Starting stream_video_interactions.py
2025-05-08 08:20:05,781 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:20:05,787 - INFO - Private key loaded successfully
2025-05-08 08:20:05,789 - INFO - Snowflake configurations loaded
2025-05-08 08:20:05,864 - INFO - AWS configurations loaded
2025-05-08 08:20:15,465 - INFO - Spark session initialized
2025-05-08 08:20:15,466 - INFO - Schema defined
2025-05-08 08:20:34,860 - INFO - Kafka stream initialized
2025-05-08 08:20:37,062 - INFO - JSON parsing completed
2025-05-08 08:20:51,862 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:20:53,778 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:20:53,892 - INFO - Closing down clientserver connection
2025-05-08 08:21:13,299 - INFO - Starting stream_video_interactions.py
2025-05-08 08:21:13,305 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:21:13,315 - INFO - Private key loaded successfully
2025-05-08 08:21:13,316 - INFO - Snowflake configurations loaded
2025-05-08 08:21:13,354 - INFO - AWS configurations loaded
2025-05-08 08:21:22,671 - INFO - Spark session initialized
2025-05-08 08:21:22,672 - INFO - Schema defined
2025-05-08 08:21:41,444 - INFO - Kafka stream initialized
2025-05-08 08:21:43,872 - INFO - JSON parsing completed
2025-05-08 08:22:01,253 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:22:02,391 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:22:02,445 - INFO - Closing down clientserver connection
2025-05-08 08:22:22,462 - INFO - Starting stream_video_interactions.py
2025-05-08 08:22:22,534 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:22:22,541 - INFO - Private key loaded successfully
2025-05-08 08:22:22,542 - INFO - Snowflake configurations loaded
2025-05-08 08:22:22,548 - INFO - AWS configurations loaded
2025-05-08 08:22:33,428 - INFO - Spark session initialized
2025-05-08 08:22:33,430 - INFO - Schema defined
2025-05-08 08:22:52,539 - INFO - Kafka stream initialized
2025-05-08 08:22:55,316 - INFO - JSON parsing completed
2025-05-08 08:23:12,341 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:23:13,845 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:23:13,949 - INFO - Closing down clientserver connection
2025-05-08 08:23:34,230 - INFO - Starting stream_video_interactions.py
2025-05-08 08:23:34,236 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:23:34,241 - INFO - Private key loaded successfully
2025-05-08 08:23:34,242 - INFO - Snowflake configurations loaded
2025-05-08 08:23:34,247 - INFO - AWS configurations loaded
2025-05-08 08:23:44,912 - INFO - Spark session initialized
2025-05-08 08:23:44,914 - INFO - Schema defined
2025-05-08 08:24:08,017 - INFO - Kafka stream initialized
2025-05-08 08:24:11,414 - INFO - JSON parsing completed
2025-05-08 08:24:28,805 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:24:30,912 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:24:31,030 - INFO - Closing down clientserver connection
2025-05-08 08:24:53,137 - INFO - Starting stream_video_interactions.py
2025-05-08 08:24:53,143 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:24:53,205 - INFO - Private key loaded successfully
2025-05-08 08:24:53,206 - INFO - Snowflake configurations loaded
2025-05-08 08:24:53,211 - INFO - AWS configurations loaded
2025-05-08 08:25:03,999 - INFO - Spark session initialized
2025-05-08 08:25:04,001 - INFO - Schema defined
2025-05-08 08:25:22,734 - INFO - Kafka stream initialized
2025-05-08 08:25:24,691 - INFO - JSON parsing completed
2025-05-08 08:25:40,804 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:25:42,142 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:25:42,233 - INFO - Closing down clientserver connection
2025-05-08 08:26:01,929 - INFO - Starting stream_video_interactions.py
2025-05-08 08:26:01,948 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:26:01,989 - INFO - Private key loaded successfully
2025-05-08 08:26:01,990 - INFO - Snowflake configurations loaded
2025-05-08 08:26:01,996 - INFO - AWS configurations loaded
2025-05-08 08:26:13,690 - INFO - Spark session initialized
2025-05-08 08:26:13,692 - INFO - Schema defined
2025-05-08 08:26:34,282 - INFO - Kafka stream initialized
2025-05-08 08:26:37,687 - INFO - JSON parsing completed
2025-05-08 08:26:53,677 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:26:55,577 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:26:55,680 - INFO - Closing down clientserver connection
2025-05-08 08:27:17,207 - INFO - Starting stream_video_interactions.py
2025-05-08 08:27:17,268 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 08:27:17,274 - INFO - Private key loaded successfully
2025-05-08 08:27:17,276 - INFO - Snowflake configurations loaded
2025-05-08 08:27:17,281 - INFO - AWS configurations loaded
2025-05-08 08:27:29,974 - INFO - Spark session initialized
2025-05-08 08:27:29,975 - INFO - Schema defined
2025-05-08 08:27:51,357 - INFO - Kafka stream initialized
2025-05-08 08:27:53,660 - INFO - JSON parsing completed
2025-05-08 08:28:08,048 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 08:28:10,472 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 08:28:10,588 - INFO - Closing down clientserver connection
2025-05-08 11:20:54,685 - INFO - Starting stream_video_interactions.py
2025-05-08 11:20:54,764 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 11:20:54,776 - INFO - Private key loaded successfully
2025-05-08 11:20:54,777 - INFO - Snowflake configurations loaded
2025-05-08 11:20:54,782 - INFO - AWS configurations loaded
2025-05-08 11:21:15,573 - INFO - Spark session initialized
2025-05-08 11:21:15,576 - INFO - Schema defined
2025-05-08 11:21:32,651 - INFO - Kafka stream initialized
2025-05-08 11:21:34,835 - INFO - JSON parsing completed
2025-05-08 11:21:51,249 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 11:21:52,768 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 11:21:52,931 - INFO - Closing down clientserver connection
2025-05-08 11:22:13,644 - INFO - Starting stream_video_interactions.py
2025-05-08 11:22:13,652 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 11:22:13,660 - INFO - Private key loaded successfully
2025-05-08 11:22:13,661 - INFO - Snowflake configurations loaded
2025-05-08 11:22:13,666 - INFO - AWS configurations loaded
2025-05-08 11:22:24,240 - INFO - Spark session initialized
2025-05-08 11:22:24,241 - INFO - Schema defined
2025-05-08 11:22:41,340 - INFO - Kafka stream initialized
2025-05-08 11:22:43,358 - INFO - JSON parsing completed
2025-05-08 11:22:57,656 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 11:22:59,452 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 11:22:59,631 - INFO - Closing down clientserver connection
2025-05-08 11:23:17,449 - INFO - Starting stream_video_interactions.py
2025-05-08 11:23:17,455 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 11:23:17,463 - INFO - Private key loaded successfully
2025-05-08 11:23:17,464 - INFO - Snowflake configurations loaded
2025-05-08 11:23:17,518 - INFO - AWS configurations loaded
2025-05-08 11:23:29,525 - INFO - Spark session initialized
2025-05-08 11:23:29,528 - INFO - Schema defined
2025-05-08 11:23:49,841 - INFO - Kafka stream initialized
2025-05-08 11:23:52,431 - INFO - JSON parsing completed
2025-05-08 11:24:08,429 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 11:24:09,812 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 11:24:09,914 - INFO - Closing down clientserver connection
2025-05-08 11:24:31,718 - INFO - Starting stream_video_interactions.py
2025-05-08 11:24:31,678 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 11:24:31,688 - INFO - Private key loaded successfully
2025-05-08 11:24:31,688 - INFO - Snowflake configurations loaded
2025-05-08 11:24:31,695 - INFO - AWS configurations loaded
2025-05-08 11:24:41,675 - INFO - Spark session initialized
2025-05-08 11:24:41,677 - INFO - Schema defined
2025-05-08 11:25:00,166 - INFO - Kafka stream initialized
2025-05-08 11:25:02,747 - INFO - JSON parsing completed
2025-05-08 11:25:18,547 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 11:25:20,355 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 11:25:20,467 - INFO - Closing down clientserver connection
2025-05-08 11:25:41,031 - INFO - Starting stream_video_interactions.py
2025-05-08 11:25:41,037 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 11:25:41,044 - INFO - Private key loaded successfully
2025-05-08 11:25:41,044 - INFO - Snowflake configurations loaded
2025-05-08 11:25:41,051 - INFO - AWS configurations loaded
2025-05-08 11:25:51,014 - INFO - Spark session initialized
2025-05-08 11:25:51,015 - INFO - Schema defined
2025-05-08 11:26:11,004 - INFO - Kafka stream initialized
2025-05-08 11:26:13,891 - INFO - JSON parsing completed
2025-05-08 11:26:30,503 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 11:26:31,592 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 11:26:31,625 - INFO - Closing down clientserver connection
2025-05-08 11:26:51,299 - INFO - Starting stream_video_interactions.py
2025-05-08 11:26:51,367 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 11:26:51,375 - INFO - Private key loaded successfully
2025-05-08 11:26:51,376 - INFO - Snowflake configurations loaded
2025-05-08 11:26:51,384 - INFO - AWS configurations loaded
2025-05-08 11:27:02,370 - INFO - Spark session initialized
2025-05-08 11:27:02,371 - INFO - Schema defined
2025-05-08 11:27:22,359 - INFO - Kafka stream initialized
2025-05-08 11:27:25,255 - INFO - JSON parsing completed
2025-05-08 11:27:39,908 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 11:27:41,608 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 11:27:41,912 - INFO - Closing down clientserver connection
2025-05-08 11:28:02,016 - INFO - Starting stream_video_interactions.py
2025-05-08 11:28:02,094 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 11:28:02,103 - INFO - Private key loaded successfully
2025-05-08 11:28:02,104 - INFO - Snowflake configurations loaded
2025-05-08 11:28:02,111 - INFO - AWS configurations loaded
2025-05-08 11:28:14,392 - INFO - Spark session initialized
2025-05-08 11:28:14,393 - INFO - Schema defined
2025-05-08 11:28:34,481 - INFO - Kafka stream initialized
2025-05-08 11:28:37,073 - INFO - JSON parsing completed
2025-05-08 11:28:51,374 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 11:28:53,483 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 11:28:53,781 - INFO - Closing down clientserver connection
2025-05-08 12:00:31,691 - INFO - Starting stream_video_interactions.py
2025-05-08 12:00:31,699 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:00:31,769 - INFO - Private key loaded successfully
2025-05-08 12:00:31,770 - INFO - Snowflake configurations loaded
2025-05-08 12:00:31,781 - INFO - AWS configurations loaded
2025-05-08 12:00:44,664 - INFO - Spark session initialized
2025-05-08 12:00:44,665 - INFO - Schema defined
2025-05-08 12:01:12,113 - INFO - Kafka stream initialized
2025-05-08 12:01:16,508 - INFO - JSON parsing completed
2025-05-08 12:01:38,728 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:01:42,236 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:01:42,535 - INFO - Closing down clientserver connection
2025-05-08 12:02:12,870 - INFO - Starting stream_video_interactions.py
2025-05-08 12:02:12,877 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:02:12,948 - INFO - Private key loaded successfully
2025-05-08 12:02:12,949 - INFO - Snowflake configurations loaded
2025-05-08 12:02:12,960 - INFO - AWS configurations loaded
2025-05-08 12:02:32,344 - INFO - Spark session initialized
2025-05-08 12:02:32,346 - INFO - Schema defined
2025-05-08 12:03:05,404 - INFO - Kafka stream initialized
2025-05-08 12:03:09,477 - INFO - JSON parsing completed
2025-05-08 12:03:31,647 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:03:34,221 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:03:34,428 - INFO - Closing down clientserver connection
2025-05-08 12:03:53,507 - INFO - Starting stream_video_interactions.py
2025-05-08 12:03:53,514 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:03:53,546 - INFO - Private key loaded successfully
2025-05-08 12:03:53,547 - INFO - Snowflake configurations loaded
2025-05-08 12:03:53,553 - INFO - AWS configurations loaded
2025-05-08 12:04:06,249 - INFO - Spark session initialized
2025-05-08 12:04:06,251 - INFO - Schema defined
2025-05-08 12:04:24,594 - INFO - Kafka stream initialized
2025-05-08 12:04:26,280 - INFO - JSON parsing completed
2025-05-08 12:04:43,707 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:04:45,497 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:04:45,603 - INFO - Closing down clientserver connection
2025-05-08 12:05:07,219 - INFO - Starting stream_video_interactions.py
2025-05-08 12:05:07,224 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:05:07,288 - INFO - Private key loaded successfully
2025-05-08 12:05:07,290 - INFO - Snowflake configurations loaded
2025-05-08 12:05:07,294 - INFO - AWS configurations loaded
2025-05-08 12:05:18,342 - INFO - Spark session initialized
2025-05-08 12:05:18,344 - INFO - Schema defined
2025-05-08 12:05:38,140 - INFO - Kafka stream initialized
2025-05-08 12:05:41,133 - INFO - JSON parsing completed
2025-05-08 12:05:57,533 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:05:59,445 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:05:59,560 - INFO - Closing down clientserver connection
2025-05-08 12:06:28,908 - INFO - Starting stream_video_interactions.py
2025-05-08 12:06:28,968 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:06:28,975 - INFO - Private key loaded successfully
2025-05-08 12:06:28,975 - INFO - Snowflake configurations loaded
2025-05-08 12:06:28,981 - INFO - AWS configurations loaded
2025-05-08 12:06:38,770 - INFO - Spark session initialized
2025-05-08 12:06:38,771 - INFO - Schema defined
2025-05-08 12:06:57,710 - INFO - Kafka stream initialized
2025-05-08 12:07:00,216 - INFO - JSON parsing completed
2025-05-08 12:07:15,515 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:07:17,053 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:07:17,148 - INFO - Closing down clientserver connection
2025-05-08 12:07:35,037 - INFO - Starting stream_video_interactions.py
2025-05-08 12:07:35,043 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:07:35,049 - INFO - Private key loaded successfully
2025-05-08 12:07:35,050 - INFO - Snowflake configurations loaded
2025-05-08 12:07:35,055 - INFO - AWS configurations loaded
2025-05-08 12:07:46,535 - INFO - Spark session initialized
2025-05-08 12:07:46,536 - INFO - Schema defined
2025-05-08 12:08:05,039 - INFO - Kafka stream initialized
2025-05-08 12:08:07,433 - INFO - JSON parsing completed
2025-05-08 12:08:25,988 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:08:27,796 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:08:28,001 - INFO - Closing down clientserver connection
2025-05-08 12:08:48,699 - INFO - Starting stream_video_interactions.py
2025-05-08 12:08:48,709 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:08:48,719 - INFO - Private key loaded successfully
2025-05-08 12:08:48,720 - INFO - Snowflake configurations loaded
2025-05-08 12:08:48,794 - INFO - AWS configurations loaded
2025-05-08 12:08:58,000 - INFO - Spark session initialized
2025-05-08 12:08:58,001 - INFO - Schema defined
2025-05-08 12:09:17,540 - INFO - Kafka stream initialized
2025-05-08 12:09:20,372 - INFO - JSON parsing completed
2025-05-08 12:09:35,430 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:09:37,135 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:09:37,243 - INFO - Closing down clientserver connection
2025-05-08 12:09:57,082 - INFO - Starting stream_video_interactions.py
2025-05-08 12:09:57,088 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:09:57,094 - INFO - Private key loaded successfully
2025-05-08 12:09:57,095 - INFO - Snowflake configurations loaded
2025-05-08 12:09:57,100 - INFO - AWS configurations loaded
2025-05-08 12:10:07,640 - INFO - Spark session initialized
2025-05-08 12:10:07,643 - INFO - Schema defined
2025-05-08 12:10:27,590 - INFO - Kafka stream initialized
2025-05-08 12:10:30,564 - INFO - JSON parsing completed
2025-05-08 12:10:46,311 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:10:47,539 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:10:47,611 - INFO - Closing down clientserver connection
2025-05-08 12:11:08,006 - INFO - Starting stream_video_interactions.py
2025-05-08 12:11:08,014 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:11:08,018 - INFO - Private key loaded successfully
2025-05-08 12:11:08,019 - INFO - Snowflake configurations loaded
2025-05-08 12:11:08,024 - INFO - AWS configurations loaded
2025-05-08 12:11:20,424 - INFO - Spark session initialized
2025-05-08 12:11:20,426 - INFO - Schema defined
2025-05-08 12:11:39,930 - INFO - Kafka stream initialized
2025-05-08 12:11:43,758 - INFO - JSON parsing completed
2025-05-08 12:11:59,259 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:12:03,353 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:12:03,543 - INFO - Closing down clientserver connection
2025-05-08 12:12:26,166 - INFO - Starting stream_video_interactions.py
2025-05-08 12:12:26,172 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:12:26,177 - INFO - Private key loaded successfully
2025-05-08 12:12:26,178 - INFO - Snowflake configurations loaded
2025-05-08 12:12:26,183 - INFO - AWS configurations loaded
2025-05-08 12:12:37,371 - INFO - Spark session initialized
2025-05-08 12:12:37,372 - INFO - Schema defined
2025-05-08 12:12:59,579 - INFO - Kafka stream initialized
2025-05-08 12:13:01,981 - INFO - JSON parsing completed
2025-05-08 12:13:17,831 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:13:20,012 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:13:20,137 - INFO - Closing down clientserver connection
2025-05-08 12:13:40,731 - INFO - Starting stream_video_interactions.py
2025-05-08 12:13:40,737 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:13:40,742 - INFO - Private key loaded successfully
2025-05-08 12:13:40,743 - INFO - Snowflake configurations loaded
2025-05-08 12:13:40,748 - INFO - AWS configurations loaded
2025-05-08 12:13:51,238 - INFO - Spark session initialized
2025-05-08 12:13:51,239 - INFO - Schema defined
2025-05-08 12:14:11,548 - INFO - Kafka stream initialized
2025-05-08 12:14:14,348 - INFO - JSON parsing completed
2025-05-08 12:14:29,085 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:14:30,478 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:14:30,668 - INFO - Closing down clientserver connection
2025-05-08 12:14:52,766 - INFO - Starting stream_video_interactions.py
2025-05-08 12:14:52,773 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:14:52,779 - INFO - Private key loaded successfully
2025-05-08 12:14:52,780 - INFO - Snowflake configurations loaded
2025-05-08 12:14:52,785 - INFO - AWS configurations loaded
2025-05-08 12:15:03,782 - INFO - Spark session initialized
2025-05-08 12:15:03,783 - INFO - Schema defined
2025-05-08 12:15:23,211 - INFO - Kafka stream initialized
2025-05-08 12:15:26,014 - INFO - JSON parsing completed
2025-05-08 12:15:39,421 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:15:41,047 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:15:41,142 - INFO - Closing down clientserver connection
2025-05-08 12:16:03,739 - INFO - Starting stream_video_interactions.py
2025-05-08 12:16:03,750 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:16:03,826 - INFO - Private key loaded successfully
2025-05-08 12:16:03,829 - INFO - Snowflake configurations loaded
2025-05-08 12:16:03,836 - INFO - AWS configurations loaded
2025-05-08 12:16:19,038 - INFO - Spark session initialized
2025-05-08 12:16:19,040 - INFO - Schema defined
2025-05-08 12:16:43,068 - INFO - Kafka stream initialized
2025-05-08 12:16:45,273 - INFO - JSON parsing completed
2025-05-08 12:17:02,287 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:17:04,464 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:17:04,573 - INFO - Closing down clientserver connection
2025-05-08 12:17:29,104 - INFO - Starting stream_video_interactions.py
2025-05-08 12:17:29,112 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:17:29,189 - INFO - Private key loaded successfully
2025-05-08 12:17:29,190 - INFO - Snowflake configurations loaded
2025-05-08 12:17:29,199 - INFO - AWS configurations loaded
2025-05-08 12:17:40,913 - INFO - Spark session initialized
2025-05-08 12:17:40,914 - INFO - Schema defined
2025-05-08 12:18:03,044 - INFO - Kafka stream initialized
2025-05-08 12:18:05,829 - INFO - JSON parsing completed
2025-05-08 12:18:24,317 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:18:26,529 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:18:26,728 - INFO - Closing down clientserver connection
2025-05-08 12:18:51,163 - INFO - Starting stream_video_interactions.py
2025-05-08 12:18:51,241 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:18:51,250 - INFO - Private key loaded successfully
2025-05-08 12:18:51,251 - INFO - Snowflake configurations loaded
2025-05-08 12:18:51,257 - INFO - AWS configurations loaded
2025-05-08 12:19:02,659 - INFO - Spark session initialized
2025-05-08 12:19:02,661 - INFO - Schema defined
2025-05-08 12:19:23,756 - INFO - Kafka stream initialized
2025-05-08 12:19:26,562 - INFO - JSON parsing completed
2025-05-08 12:19:44,681 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:19:46,493 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:19:46,779 - INFO - Closing down clientserver connection
2025-05-08 12:20:09,914 - INFO - Starting stream_video_interactions.py
2025-05-08 12:20:09,919 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:20:09,924 - INFO - Private key loaded successfully
2025-05-08 12:20:09,924 - INFO - Snowflake configurations loaded
2025-05-08 12:20:09,928 - INFO - AWS configurations loaded
2025-05-08 12:20:09,938 - INFO - Closing down clientserver connection
2025-05-08 12:20:09,939 - ERROR - Error in stream_video_interactions.py: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 72, in <module>
    spark = SparkSession.builder \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/session.py", line 477, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 512, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 198, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 432, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/java_gateway.py", line 150, in launch_gateway
    java_import(gateway.jvm, "org.apache.spark.SparkConf")
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 180, in java_import
    answer = gateway_client.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1036, in send_command
    connection = self._get_connection()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 284, in _get_connection
    connection = self._create_new_connection()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 291, in _create_new_connection
    connection.connect_to_java_server()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 438, in connect_to_java_server
    self.socket.connect((self.java_address, self.java_port))
ConnectionRefusedError: [Errno 111] Connection refused
2025-05-08 12:20:09,972 - INFO - Closing down clientserver connection
2025-05-08 12:20:59,167 - INFO - Starting stream_video_interactions.py
2025-05-08 12:20:59,175 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:20:59,185 - INFO - Private key loaded successfully
2025-05-08 12:20:59,185 - INFO - Snowflake configurations loaded
2025-05-08 12:20:59,193 - INFO - AWS configurations loaded
2025-05-08 12:21:12,846 - INFO - Spark session initialized
2025-05-08 12:21:12,848 - INFO - Schema defined
2025-05-08 12:21:36,270 - INFO - Kafka stream initialized
2025-05-08 12:21:41,480 - INFO - JSON parsing completed
2025-05-08 12:22:00,360 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:22:02,880 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:22:03,089 - INFO - Closing down clientserver connection
2025-05-08 12:22:28,285 - INFO - Starting stream_video_interactions.py
2025-05-08 12:22:28,293 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:22:28,303 - INFO - Private key loaded successfully
2025-05-08 12:22:28,305 - INFO - Snowflake configurations loaded
2025-05-08 12:22:28,382 - INFO - AWS configurations loaded
2025-05-08 12:22:46,401 - INFO - Spark session initialized
2025-05-08 12:22:46,404 - INFO - Schema defined
2025-05-08 12:23:17,925 - INFO - Kafka stream initialized
2025-05-08 12:23:23,148 - INFO - JSON parsing completed
2025-05-08 12:23:48,343 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:23:50,647 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:23:50,835 - INFO - Closing down clientserver connection
2025-05-08 12:24:17,181 - INFO - Starting stream_video_interactions.py
2025-05-08 12:24:17,188 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:24:17,194 - INFO - Private key loaded successfully
2025-05-08 12:24:17,195 - INFO - Snowflake configurations loaded
2025-05-08 12:24:17,200 - INFO - AWS configurations loaded
2025-05-08 12:24:30,680 - INFO - Spark session initialized
2025-05-08 12:24:30,683 - INFO - Schema defined
2025-05-08 12:24:57,701 - INFO - Kafka stream initialized
2025-05-08 12:25:00,172 - INFO - JSON parsing completed
2025-05-08 12:25:18,803 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:25:19,929 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:25:20,029 - INFO - Closing down clientserver connection
2025-05-08 12:25:42,846 - INFO - Starting stream_video_interactions.py
2025-05-08 12:25:42,948 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:25:43,111 - INFO - Private key loaded successfully
2025-05-08 12:25:43,113 - INFO - Snowflake configurations loaded
2025-05-08 12:25:43,118 - INFO - AWS configurations loaded
2025-05-08 12:25:55,325 - INFO - Spark session initialized
2025-05-08 12:25:55,327 - INFO - Schema defined
2025-05-08 12:26:19,227 - INFO - Kafka stream initialized
2025-05-08 12:26:22,641 - INFO - JSON parsing completed
2025-05-08 12:26:38,642 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:26:40,746 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:26:40,861 - INFO - Closing down clientserver connection
2025-05-08 12:27:01,880 - INFO - Starting stream_video_interactions.py
2025-05-08 12:27:01,886 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:27:01,938 - INFO - Private key loaded successfully
2025-05-08 12:27:01,939 - INFO - Snowflake configurations loaded
2025-05-08 12:27:01,944 - INFO - AWS configurations loaded
2025-05-08 12:27:15,762 - INFO - Spark session initialized
2025-05-08 12:27:15,763 - INFO - Schema defined
2025-05-08 12:27:41,092 - INFO - Kafka stream initialized
2025-05-08 12:27:43,808 - INFO - JSON parsing completed
2025-05-08 12:27:59,178 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:28:01,885 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:28:02,129 - INFO - Closing down clientserver connection
2025-05-08 12:28:22,515 - INFO - Starting stream_video_interactions.py
2025-05-08 12:28:22,526 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:28:22,601 - INFO - Private key loaded successfully
2025-05-08 12:28:22,602 - INFO - Snowflake configurations loaded
2025-05-08 12:28:22,611 - INFO - AWS configurations loaded
2025-05-08 12:28:37,820 - INFO - Spark session initialized
2025-05-08 12:28:37,821 - INFO - Schema defined
2025-05-08 12:29:01,444 - INFO - Kafka stream initialized
2025-05-08 12:29:03,047 - INFO - JSON parsing completed
2025-05-08 12:29:23,141 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:29:25,134 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:29:25,246 - INFO - Closing down clientserver connection
2025-05-08 12:29:51,561 - INFO - Starting stream_video_interactions.py
2025-05-08 12:29:51,568 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:29:51,578 - INFO - Private key loaded successfully
2025-05-08 12:29:51,579 - INFO - Snowflake configurations loaded
2025-05-08 12:29:51,652 - INFO - AWS configurations loaded
2025-05-08 12:30:05,475 - INFO - Spark session initialized
2025-05-08 12:30:05,477 - INFO - Schema defined
2025-05-08 12:30:31,275 - INFO - Kafka stream initialized
2025-05-08 12:30:33,696 - INFO - JSON parsing completed
2025-05-08 12:30:50,168 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:30:51,917 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:30:52,009 - INFO - Closing down clientserver connection
2025-05-08 12:31:17,130 - INFO - Starting stream_video_interactions.py
2025-05-08 12:31:17,136 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:31:17,195 - INFO - Private key loaded successfully
2025-05-08 12:31:17,197 - INFO - Snowflake configurations loaded
2025-05-08 12:31:17,204 - INFO - AWS configurations loaded
2025-05-08 12:31:31,206 - INFO - Spark session initialized
2025-05-08 12:31:31,207 - INFO - Schema defined
2025-05-08 12:31:51,912 - INFO - Kafka stream initialized
2025-05-08 12:31:54,334 - INFO - JSON parsing completed
2025-05-08 12:32:10,623 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:32:12,830 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:32:13,028 - INFO - Closing down clientserver connection
2025-05-08 12:32:37,766 - INFO - Starting stream_video_interactions.py
2025-05-08 12:32:37,841 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:32:37,850 - INFO - Private key loaded successfully
2025-05-08 12:32:37,851 - INFO - Snowflake configurations loaded
2025-05-08 12:32:37,859 - INFO - AWS configurations loaded
2025-05-08 12:32:47,732 - INFO - Spark session initialized
2025-05-08 12:32:47,741 - INFO - Schema defined
2025-05-08 12:33:08,875 - INFO - Kafka stream initialized
2025-05-08 12:33:11,552 - INFO - JSON parsing completed
2025-05-08 12:33:29,269 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:33:31,469 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:33:31,583 - INFO - Closing down clientserver connection
2025-05-08 12:34:01,833 - INFO - Starting stream_video_interactions.py
2025-05-08 12:34:01,841 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:34:01,874 - INFO - Private key loaded successfully
2025-05-08 12:34:01,876 - INFO - Snowflake configurations loaded
2025-05-08 12:34:01,884 - INFO - AWS configurations loaded
2025-05-08 12:34:12,684 - INFO - Spark session initialized
2025-05-08 12:34:12,686 - INFO - Schema defined
2025-05-08 12:34:35,015 - INFO - Kafka stream initialized
2025-05-08 12:34:38,320 - INFO - JSON parsing completed
2025-05-08 12:34:59,316 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:35:00,420 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:35:00,467 - INFO - Closing down clientserver connection
2025-05-08 12:35:23,146 - INFO - Starting stream_video_interactions.py
2025-05-08 12:35:23,153 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:35:23,162 - INFO - Private key loaded successfully
2025-05-08 12:35:23,163 - INFO - Snowflake configurations loaded
2025-05-08 12:35:23,222 - INFO - AWS configurations loaded
2025-05-08 12:35:35,935 - INFO - Spark session initialized
2025-05-08 12:35:35,937 - INFO - Schema defined
2025-05-08 12:35:59,141 - INFO - Kafka stream initialized
2025-05-08 12:36:03,248 - INFO - JSON parsing completed
2025-05-08 12:36:21,052 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:36:23,645 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:36:23,961 - INFO - Closing down clientserver connection
2025-05-08 12:36:48,265 - INFO - Starting stream_video_interactions.py
2025-05-08 12:36:48,271 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:36:48,280 - INFO - Private key loaded successfully
2025-05-08 12:36:48,282 - INFO - Snowflake configurations loaded
2025-05-08 12:36:48,290 - INFO - AWS configurations loaded
2025-05-08 12:36:59,969 - INFO - Spark session initialized
2025-05-08 12:36:59,970 - INFO - Schema defined
2025-05-08 12:37:24,184 - INFO - Kafka stream initialized
2025-05-08 12:37:27,085 - INFO - JSON parsing completed
2025-05-08 12:37:47,078 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:37:48,685 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:37:48,736 - INFO - Closing down clientserver connection
2025-05-08 12:38:10,411 - INFO - Starting stream_video_interactions.py
2025-05-08 12:38:10,419 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:38:10,427 - INFO - Private key loaded successfully
2025-05-08 12:38:10,428 - INFO - Snowflake configurations loaded
2025-05-08 12:38:10,494 - INFO - AWS configurations loaded
2025-05-08 12:38:22,897 - INFO - Spark session initialized
2025-05-08 12:38:22,899 - INFO - Schema defined
2025-05-08 12:38:46,825 - INFO - Kafka stream initialized
2025-05-08 12:38:50,205 - INFO - JSON parsing completed
2025-05-08 12:39:06,928 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:39:09,342 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:39:09,618 - INFO - Closing down clientserver connection
2025-05-08 12:39:31,266 - INFO - Starting stream_video_interactions.py
2025-05-08 12:39:31,332 - INFO - Attempting to load private key from: /app/config/snowflake_key.pem
2025-05-08 12:39:31,342 - INFO - Private key loaded successfully
2025-05-08 12:39:31,343 - INFO - Snowflake configurations loaded
2025-05-08 12:39:31,351 - INFO - AWS configurations loaded
2025-05-08 12:39:45,437 - INFO - Spark session initialized
2025-05-08 12:39:45,439 - INFO - Schema defined
2025-05-08 12:40:11,350 - INFO - Kafka stream initialized
2025-05-08 12:40:14,552 - INFO - JSON parsing completed
2025-05-08 12:40:29,658 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:40:32,171 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:40:32,363 - INFO - Closing down clientserver connection
2025-05-08 12:40:56,956 - INFO - Starting stream_video_interactions.py
2025-05-08 12:40:56,962 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:40:56,967 - INFO - Private key loaded successfully
2025-05-08 12:40:56,969 - INFO - Snowflake configurations loaded
2025-05-08 12:40:56,975 - INFO - AWS configurations loaded
2025-05-08 12:41:09,487 - INFO - Spark session initialized
2025-05-08 12:41:09,489 - INFO - Schema defined
2025-05-08 12:41:34,497 - INFO - Kafka stream initialized
2025-05-08 12:41:36,889 - INFO - JSON parsing completed
2025-05-08 12:41:58,618 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:41:59,824 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:41:59,928 - INFO - Closing down clientserver connection
2025-05-08 12:42:24,015 - INFO - Starting stream_video_interactions.py
2025-05-08 12:42:24,105 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:42:24,119 - INFO - Private key loaded successfully
2025-05-08 12:42:24,123 - INFO - Snowflake configurations loaded
2025-05-08 12:42:24,187 - INFO - AWS configurations loaded
2025-05-08 12:42:24,907 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 12:42:24,912 - INFO - Closing down clientserver connection
2025-05-08 12:42:24,913 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 12:42:24,918 - INFO - Closing down clientserver connection
2025-05-08 12:42:24,919 - ERROR - Error in stream_video_interactions.py: An error occurred while calling None.org.apache.spark.SparkConf
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 72, in <module>
    spark = SparkSession.builder \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/session.py", line 477, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 512, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 200, in __init__
    self._do_init(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 242, in _do_init
    self._conf = SparkConf(_jvm=SparkContext._jvm)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/conf.py", line 131, in __init__
    self._jconf = _jvm.SparkConf(loadDefaults)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1587, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.SparkConf
2025-05-08 12:43:16,170 - INFO - Starting stream_video_interactions.py
2025-05-08 12:43:16,205 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:43:16,212 - INFO - Private key loaded successfully
2025-05-08 12:43:16,213 - INFO - Snowflake configurations loaded
2025-05-08 12:43:16,220 - INFO - AWS configurations loaded
2025-05-08 12:43:29,831 - INFO - Spark session initialized
2025-05-08 12:43:29,832 - INFO - Schema defined
2025-05-08 12:43:53,766 - INFO - Kafka stream initialized
2025-05-08 12:43:56,550 - INFO - JSON parsing completed
2025-05-08 12:44:14,554 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:44:16,972 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:44:17,179 - INFO - Closing down clientserver connection
2025-05-08 12:44:40,176 - INFO - Starting stream_video_interactions.py
2025-05-08 12:44:40,185 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:44:40,195 - INFO - Private key loaded successfully
2025-05-08 12:44:40,196 - INFO - Snowflake configurations loaded
2025-05-08 12:44:40,205 - INFO - AWS configurations loaded
2025-05-08 12:44:52,974 - INFO - Spark session initialized
2025-05-08 12:44:52,975 - INFO - Schema defined
2025-05-08 12:45:17,318 - INFO - Kafka stream initialized
2025-05-08 12:45:20,914 - INFO - JSON parsing completed
2025-05-08 12:45:40,404 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:45:42,427 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:45:42,526 - INFO - Closing down clientserver connection
2025-05-08 12:46:04,343 - INFO - Starting stream_video_interactions.py
2025-05-08 12:46:04,350 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:46:04,365 - INFO - Private key loaded successfully
2025-05-08 12:46:04,366 - INFO - Snowflake configurations loaded
2025-05-08 12:46:04,370 - INFO - AWS configurations loaded
2025-05-08 12:46:16,048 - INFO - Spark session initialized
2025-05-08 12:46:16,050 - INFO - Schema defined
2025-05-08 12:46:38,977 - INFO - Kafka stream initialized
2025-05-08 12:46:42,062 - INFO - JSON parsing completed
2025-05-08 12:46:58,275 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:46:59,691 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:46:59,796 - INFO - Closing down clientserver connection
2025-05-08 12:47:23,500 - INFO - Starting stream_video_interactions.py
2025-05-08 12:47:23,601 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:47:23,609 - INFO - Private key loaded successfully
2025-05-08 12:47:23,669 - INFO - Snowflake configurations loaded
2025-05-08 12:47:23,675 - INFO - AWS configurations loaded
2025-05-08 12:47:37,071 - INFO - Spark session initialized
2025-05-08 12:47:37,073 - INFO - Schema defined
2025-05-08 12:48:01,998 - INFO - Kafka stream initialized
2025-05-08 12:48:05,778 - INFO - JSON parsing completed
2025-05-08 12:48:22,398 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:48:24,513 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:48:24,700 - INFO - Closing down clientserver connection
2025-05-08 12:48:48,810 - INFO - Starting stream_video_interactions.py
2025-05-08 12:48:48,817 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:48:48,825 - INFO - Private key loaded successfully
2025-05-08 12:48:48,826 - INFO - Snowflake configurations loaded
2025-05-08 12:48:48,831 - INFO - AWS configurations loaded
2025-05-08 12:48:48,845 - INFO - Closing down clientserver connection
2025-05-08 12:48:48,845 - ERROR - Error in stream_video_interactions.py: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 72, in <module>
    spark = SparkSession.builder \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/session.py", line 477, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 512, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 198, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 432, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/java_gateway.py", line 150, in launch_gateway
    java_import(gateway.jvm, "org.apache.spark.SparkConf")
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 180, in java_import
    answer = gateway_client.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1036, in send_command
    connection = self._get_connection()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 284, in _get_connection
    connection = self._create_new_connection()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 291, in _create_new_connection
    connection.connect_to_java_server()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 438, in connect_to_java_server
    self.socket.connect((self.java_address, self.java_port))
ConnectionRefusedError: [Errno 111] Connection refused
2025-05-08 12:48:48,872 - INFO - Closing down clientserver connection
2025-05-08 12:49:35,076 - INFO - Starting stream_video_interactions.py
2025-05-08 12:49:35,082 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:49:35,087 - INFO - Private key loaded successfully
2025-05-08 12:49:35,088 - INFO - Snowflake configurations loaded
2025-05-08 12:49:35,119 - INFO - AWS configurations loaded
2025-05-08 12:49:47,747 - INFO - Spark session initialized
2025-05-08 12:49:47,749 - INFO - Schema defined
2025-05-08 12:50:11,225 - INFO - Kafka stream initialized
2025-05-08 12:50:14,738 - INFO - JSON parsing completed
2025-05-08 12:50:32,374 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:50:35,051 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:50:35,173 - INFO - Closing down clientserver connection
2025-05-08 12:50:59,299 - INFO - Starting stream_video_interactions.py
2025-05-08 12:50:59,310 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:50:59,318 - INFO - Private key loaded successfully
2025-05-08 12:50:59,319 - INFO - Snowflake configurations loaded
2025-05-08 12:50:59,325 - INFO - AWS configurations loaded
2025-05-08 12:51:11,241 - INFO - Spark session initialized
2025-05-08 12:51:11,245 - INFO - Schema defined
2025-05-08 12:51:37,214 - INFO - Kafka stream initialized
2025-05-08 12:51:41,322 - INFO - JSON parsing completed
2025-05-08 12:52:00,425 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:52:02,830 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:52:02,926 - INFO - Closing down clientserver connection
2025-05-08 12:52:25,745 - INFO - Starting stream_video_interactions.py
2025-05-08 12:52:25,750 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:52:25,756 - INFO - Private key loaded successfully
2025-05-08 12:52:25,758 - INFO - Snowflake configurations loaded
2025-05-08 12:52:25,762 - INFO - AWS configurations loaded
2025-05-08 12:52:38,246 - INFO - Spark session initialized
2025-05-08 12:52:38,247 - INFO - Schema defined
2025-05-08 12:53:02,865 - INFO - Kafka stream initialized
2025-05-08 12:53:05,339 - INFO - JSON parsing completed
2025-05-08 12:53:22,209 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:53:23,289 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:53:23,405 - INFO - Closing down clientserver connection
2025-05-08 12:53:45,371 - INFO - Starting stream_video_interactions.py
2025-05-08 12:53:45,429 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:53:45,439 - INFO - Private key loaded successfully
2025-05-08 12:53:45,443 - INFO - Snowflake configurations loaded
2025-05-08 12:53:45,450 - INFO - AWS configurations loaded
2025-05-08 12:53:57,431 - INFO - Spark session initialized
2025-05-08 12:53:57,432 - INFO - Schema defined
2025-05-08 12:54:19,110 - INFO - Kafka stream initialized
2025-05-08 12:54:22,494 - INFO - JSON parsing completed
2025-05-08 12:54:39,828 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:54:41,325 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:54:41,542 - INFO - Closing down clientserver connection
2025-05-08 12:55:04,141 - INFO - Starting stream_video_interactions.py
2025-05-08 12:55:04,151 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:55:04,225 - INFO - Private key loaded successfully
2025-05-08 12:55:04,230 - INFO - Snowflake configurations loaded
2025-05-08 12:55:04,242 - INFO - AWS configurations loaded
2025-05-08 12:55:10,231 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 12:55:10,233 - INFO - Closing down clientserver connection
2025-05-08 12:55:10,236 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 12:55:10,241 - INFO - Closing down clientserver connection
2025-05-08 12:55:10,243 - ERROR - Error in stream_video_interactions.py: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 72, in <module>
    spark = SparkSession.builder \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/session.py", line 477, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 512, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 200, in __init__
    self._do_init(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 287, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 417, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1587, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
2025-05-08 12:55:10,248 - INFO - Closing down clientserver connection
2025-05-08 12:55:56,979 - INFO - Starting stream_video_interactions.py
2025-05-08 12:55:56,989 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:55:56,999 - INFO - Private key loaded successfully
2025-05-08 12:55:57,000 - INFO - Snowflake configurations loaded
2025-05-08 12:55:57,006 - INFO - AWS configurations loaded
2025-05-08 12:56:10,272 - INFO - Spark session initialized
2025-05-08 12:56:10,273 - INFO - Schema defined
2025-05-08 12:56:34,856 - INFO - Kafka stream initialized
2025-05-08 12:56:38,454 - INFO - JSON parsing completed
2025-05-08 12:56:59,301 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:57:01,574 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:57:01,698 - INFO - Closing down clientserver connection
2025-05-08 12:57:26,414 - INFO - Starting stream_video_interactions.py
2025-05-08 12:57:26,485 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:57:26,498 - INFO - Private key loaded successfully
2025-05-08 12:57:26,499 - INFO - Snowflake configurations loaded
2025-05-08 12:57:26,504 - INFO - AWS configurations loaded
2025-05-08 12:57:38,094 - INFO - Spark session initialized
2025-05-08 12:57:38,095 - INFO - Schema defined
2025-05-08 12:58:00,976 - INFO - Kafka stream initialized
2025-05-08 12:58:06,176 - INFO - JSON parsing completed
2025-05-08 12:58:35,114 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 12:58:37,394 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 12:58:37,602 - INFO - Closing down clientserver connection
2025-05-08 12:59:13,206 - INFO - Starting stream_video_interactions.py
2025-05-08 12:59:13,214 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 12:59:13,224 - INFO - Private key loaded successfully
2025-05-08 12:59:13,225 - INFO - Snowflake configurations loaded
2025-05-08 12:59:13,291 - INFO - AWS configurations loaded
2025-05-08 12:59:33,308 - INFO - Spark session initialized
2025-05-08 12:59:33,309 - INFO - Schema defined
2025-05-08 13:00:06,696 - INFO - Kafka stream initialized
2025-05-08 13:00:11,490 - INFO - JSON parsing completed
2025-05-08 13:00:33,408 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:00:34,417 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:00:34,521 - INFO - Closing down clientserver connection
2025-05-08 13:00:58,622 - INFO - Starting stream_video_interactions.py
2025-05-08 13:00:58,632 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:00:58,695 - INFO - Private key loaded successfully
2025-05-08 13:00:58,696 - INFO - Snowflake configurations loaded
2025-05-08 13:00:58,703 - INFO - AWS configurations loaded
2025-05-08 13:01:10,405 - INFO - Spark session initialized
2025-05-08 13:01:10,406 - INFO - Schema defined
2025-05-08 13:01:33,194 - INFO - Kafka stream initialized
2025-05-08 13:01:36,599 - INFO - JSON parsing completed
2025-05-08 13:01:51,598 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:01:53,509 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:01:53,897 - INFO - Closing down clientserver connection
2025-05-08 13:02:16,101 - INFO - Starting stream_video_interactions.py
2025-05-08 13:02:16,108 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:02:16,116 - INFO - Private key loaded successfully
2025-05-08 13:02:16,118 - INFO - Snowflake configurations loaded
2025-05-08 13:02:16,127 - INFO - AWS configurations loaded
2025-05-08 13:02:27,994 - INFO - Spark session initialized
2025-05-08 13:02:27,995 - INFO - Schema defined
2025-05-08 13:02:49,023 - INFO - Kafka stream initialized
2025-05-08 13:02:51,617 - INFO - JSON parsing completed
2025-05-08 13:03:07,743 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:03:09,639 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:03:09,820 - INFO - Closing down clientserver connection
2025-05-08 13:03:30,267 - INFO - Starting stream_video_interactions.py
2025-05-08 13:03:30,322 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:03:30,330 - INFO - Private key loaded successfully
2025-05-08 13:03:30,332 - INFO - Snowflake configurations loaded
2025-05-08 13:03:30,339 - INFO - AWS configurations loaded
2025-05-08 13:03:43,954 - INFO - Spark session initialized
2025-05-08 13:03:43,955 - INFO - Schema defined
2025-05-08 13:04:01,963 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 13:04:01,965 - INFO - Closing down clientserver connection
2025-05-08 13:04:01,967 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 13:04:02,031 - INFO - Closing down clientserver connection
2025-05-08 13:04:02,031 - ERROR - Error in stream_video_interactions.py: An error occurred while calling o42.load
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 120, in <module>
    kafka_df = spark.readStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 277, in load
    return self._df(self._jreader.load())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 169, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o42.load
2025-05-08 13:04:02,042 - INFO - Closing down clientserver connection
2025-05-08 13:04:48,085 - INFO - Starting stream_video_interactions.py
2025-05-08 13:04:48,094 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:04:48,106 - INFO - Private key loaded successfully
2025-05-08 13:04:48,107 - INFO - Snowflake configurations loaded
2025-05-08 13:04:48,115 - INFO - AWS configurations loaded
2025-05-08 13:05:01,046 - INFO - Spark session initialized
2025-05-08 13:05:01,047 - INFO - Schema defined
2025-05-08 13:05:23,234 - INFO - Kafka stream initialized
2025-05-08 13:05:26,434 - INFO - JSON parsing completed
2025-05-08 13:05:48,333 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:05:51,517 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:05:51,819 - INFO - Closing down clientserver connection
2025-05-08 13:06:23,301 - INFO - Starting stream_video_interactions.py
2025-05-08 13:06:23,310 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:06:23,318 - INFO - Private key loaded successfully
2025-05-08 13:06:23,320 - INFO - Snowflake configurations loaded
2025-05-08 13:06:23,398 - INFO - AWS configurations loaded
2025-05-08 13:06:41,537 - INFO - Spark session initialized
2025-05-08 13:06:41,538 - INFO - Schema defined
2025-05-08 13:07:18,333 - INFO - Kafka stream initialized
2025-05-08 13:07:22,634 - INFO - JSON parsing completed
2025-05-08 13:07:41,623 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:07:43,625 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:07:43,737 - INFO - Closing down clientserver connection
2025-05-08 13:08:05,709 - INFO - Starting stream_video_interactions.py
2025-05-08 13:08:05,716 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:08:05,722 - INFO - Private key loaded successfully
2025-05-08 13:08:05,723 - INFO - Snowflake configurations loaded
2025-05-08 13:08:05,728 - INFO - AWS configurations loaded
2025-05-08 13:08:17,304 - INFO - Spark session initialized
2025-05-08 13:08:17,306 - INFO - Schema defined
2025-05-08 13:08:40,507 - INFO - Kafka stream initialized
2025-05-08 13:08:43,702 - INFO - JSON parsing completed
2025-05-08 13:09:01,237 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:09:02,998 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:09:03,107 - INFO - Closing down clientserver connection
2025-05-08 13:09:24,217 - INFO - Starting stream_video_interactions.py
2025-05-08 13:09:24,227 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:09:24,238 - INFO - Private key loaded successfully
2025-05-08 13:09:24,286 - INFO - Snowflake configurations loaded
2025-05-08 13:09:24,294 - INFO - AWS configurations loaded
2025-05-08 13:09:35,793 - INFO - Spark session initialized
2025-05-08 13:09:35,794 - INFO - Schema defined
2025-05-08 13:09:58,181 - INFO - Kafka stream initialized
2025-05-08 13:10:01,574 - INFO - JSON parsing completed
2025-05-08 13:10:17,970 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:10:19,378 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:10:19,573 - INFO - Closing down clientserver connection
2025-05-08 13:10:42,008 - INFO - Starting stream_video_interactions.py
2025-05-08 13:10:42,018 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:10:42,067 - INFO - Private key loaded successfully
2025-05-08 13:10:42,068 - INFO - Snowflake configurations loaded
2025-05-08 13:10:42,076 - INFO - AWS configurations loaded
2025-05-08 13:10:55,467 - INFO - Spark session initialized
2025-05-08 13:10:55,468 - INFO - Schema defined
2025-05-08 13:11:18,256 - INFO - Kafka stream initialized
2025-05-08 13:11:19,753 - INFO - JSON parsing completed
2025-05-08 13:11:38,547 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:11:40,555 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:11:40,672 - INFO - Closing down clientserver connection
2025-05-08 13:12:01,970 - INFO - Starting stream_video_interactions.py
2025-05-08 13:12:02,034 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:12:02,045 - INFO - Private key loaded successfully
2025-05-08 13:12:02,046 - INFO - Snowflake configurations loaded
2025-05-08 13:12:02,063 - INFO - AWS configurations loaded
2025-05-08 13:12:15,650 - INFO - Spark session initialized
2025-05-08 13:12:15,651 - INFO - Schema defined
2025-05-08 13:12:37,322 - INFO - Kafka stream initialized
2025-05-08 13:12:39,435 - INFO - JSON parsing completed
2025-05-08 13:12:56,038 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:12:57,940 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:12:58,044 - INFO - Closing down clientserver connection
2025-05-08 13:13:23,258 - INFO - Starting stream_video_interactions.py
2025-05-08 13:13:23,266 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:13:23,275 - INFO - Private key loaded successfully
2025-05-08 13:13:23,276 - INFO - Snowflake configurations loaded
2025-05-08 13:13:23,307 - INFO - AWS configurations loaded
2025-05-08 13:13:37,693 - INFO - Spark session initialized
2025-05-08 13:13:37,694 - INFO - Schema defined
2025-05-08 13:13:57,816 - INFO - Kafka stream initialized
2025-05-08 13:14:00,902 - INFO - JSON parsing completed
2025-05-08 13:14:20,209 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:14:22,107 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:14:22,279 - INFO - Closing down clientserver connection
2025-05-08 13:14:48,081 - INFO - Starting stream_video_interactions.py
2025-05-08 13:14:48,087 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:14:48,094 - INFO - Private key loaded successfully
2025-05-08 13:14:48,095 - INFO - Snowflake configurations loaded
2025-05-08 13:14:48,105 - INFO - AWS configurations loaded
2025-05-08 13:15:00,491 - INFO - Spark session initialized
2025-05-08 13:15:00,493 - INFO - Schema defined
2025-05-08 13:15:21,233 - INFO - Kafka stream initialized
2025-05-08 13:15:24,758 - INFO - JSON parsing completed
2025-05-08 13:15:28,581 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 13:15:28,632 - INFO - Closing down clientserver connection
2025-05-08 13:15:28,634 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 13:15:28,644 - INFO - Closing down clientserver connection
2025-05-08 13:15:28,644 - ERROR - Error in stream_video_interactions.py: An error occurred while calling o166.withColumn
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 216, in <module>
    cleaned_df = cleaned_df.withColumn(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 4789, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 169, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o166.withColumn
2025-05-08 13:15:28,663 - INFO - Closing down clientserver connection
2025-05-08 13:16:16,723 - INFO - Starting stream_video_interactions.py
2025-05-08 13:16:16,732 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:16:16,738 - INFO - Private key loaded successfully
2025-05-08 13:16:16,739 - INFO - Snowflake configurations loaded
2025-05-08 13:16:16,745 - INFO - AWS configurations loaded
2025-05-08 13:16:29,843 - INFO - Spark session initialized
2025-05-08 13:16:29,844 - INFO - Schema defined
2025-05-08 13:16:51,405 - INFO - Kafka stream initialized
2025-05-08 13:16:54,997 - INFO - JSON parsing completed
2025-05-08 13:17:14,003 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:17:16,683 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:17:16,878 - INFO - Closing down clientserver connection
2025-05-08 13:17:41,656 - INFO - Starting stream_video_interactions.py
2025-05-08 13:17:41,662 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:17:41,669 - INFO - Private key loaded successfully
2025-05-08 13:17:41,670 - INFO - Snowflake configurations loaded
2025-05-08 13:17:41,676 - INFO - AWS configurations loaded
2025-05-08 13:17:43,879 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 13:17:43,880 - INFO - Closing down clientserver connection
2025-05-08 13:17:43,881 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 13:17:43,888 - INFO - Closing down clientserver connection
2025-05-08 13:17:43,889 - ERROR - Error in stream_video_interactions.py: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 72, in <module>
    spark = SparkSession.builder \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/session.py", line 477, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 512, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 200, in __init__
    self._do_init(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 287, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 417, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1587, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
2025-05-08 13:17:43,896 - INFO - Closing down clientserver connection
2025-05-08 13:18:32,166 - INFO - Starting stream_video_interactions.py
2025-05-08 13:18:32,235 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:18:32,241 - INFO - Private key loaded successfully
2025-05-08 13:18:32,242 - INFO - Snowflake configurations loaded
2025-05-08 13:18:32,247 - INFO - AWS configurations loaded
2025-05-08 13:18:46,416 - INFO - Spark session initialized
2025-05-08 13:18:46,418 - INFO - Schema defined
2025-05-08 13:19:08,620 - INFO - Kafka stream initialized
2025-05-08 13:19:11,693 - INFO - JSON parsing completed
2025-05-08 13:19:31,393 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:19:33,911 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:19:34,100 - INFO - Closing down clientserver connection
2025-05-08 13:19:58,382 - INFO - Starting stream_video_interactions.py
2025-05-08 13:19:58,391 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:19:58,399 - INFO - Private key loaded successfully
2025-05-08 13:19:58,400 - INFO - Snowflake configurations loaded
2025-05-08 13:19:58,408 - INFO - AWS configurations loaded
2025-05-08 13:20:09,850 - INFO - Spark session initialized
2025-05-08 13:20:09,852 - INFO - Schema defined
2025-05-08 13:20:36,239 - INFO - Kafka stream initialized
2025-05-08 13:20:40,834 - INFO - JSON parsing completed
2025-05-08 13:21:08,396 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:21:10,515 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:21:10,634 - INFO - Closing down clientserver connection
2025-05-08 13:21:36,197 - INFO - Starting stream_video_interactions.py
2025-05-08 13:21:36,203 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:21:36,212 - INFO - Private key loaded successfully
2025-05-08 13:21:36,213 - INFO - Snowflake configurations loaded
2025-05-08 13:21:36,272 - INFO - AWS configurations loaded
2025-05-08 13:21:49,873 - INFO - Spark session initialized
2025-05-08 13:21:49,875 - INFO - Schema defined
2025-05-08 13:22:16,754 - INFO - Kafka stream initialized
2025-05-08 13:22:19,670 - INFO - JSON parsing completed
2025-05-08 13:22:38,523 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:22:40,147 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:22:40,264 - INFO - Closing down clientserver connection
2025-05-08 13:23:03,317 - INFO - Starting stream_video_interactions.py
2025-05-08 13:23:03,324 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:23:03,331 - INFO - Private key loaded successfully
2025-05-08 13:23:03,332 - INFO - Snowflake configurations loaded
2025-05-08 13:23:03,338 - INFO - AWS configurations loaded
2025-05-08 13:23:16,715 - INFO - Spark session initialized
2025-05-08 13:23:16,717 - INFO - Schema defined
2025-05-08 13:23:41,703 - INFO - Kafka stream initialized
2025-05-08 13:23:45,686 - INFO - JSON parsing completed
2025-05-08 13:24:00,471 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:24:02,359 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:24:02,570 - INFO - Closing down clientserver connection
2025-05-08 13:24:26,571 - INFO - Starting stream_video_interactions.py
2025-05-08 13:24:26,578 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:24:26,591 - INFO - Private key loaded successfully
2025-05-08 13:24:26,592 - INFO - Snowflake configurations loaded
2025-05-08 13:24:26,598 - INFO - AWS configurations loaded
2025-05-08 13:24:40,434 - INFO - Spark session initialized
2025-05-08 13:24:40,441 - INFO - Schema defined
2025-05-08 13:25:05,914 - INFO - Kafka stream initialized
2025-05-08 13:25:08,711 - INFO - JSON parsing completed
2025-05-08 13:25:27,000 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:25:28,155 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:25:28,267 - INFO - Closing down clientserver connection
2025-05-08 13:25:51,972 - INFO - Starting stream_video_interactions.py
2025-05-08 13:25:51,982 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:25:52,049 - INFO - Private key loaded successfully
2025-05-08 13:25:52,051 - INFO - Snowflake configurations loaded
2025-05-08 13:25:52,058 - INFO - AWS configurations loaded
2025-05-08 13:26:07,647 - INFO - Spark session initialized
2025-05-08 13:26:07,650 - INFO - Schema defined
2025-05-08 13:26:30,333 - INFO - Kafka stream initialized
2025-05-08 13:26:33,129 - INFO - JSON parsing completed
2025-05-08 13:26:36,357 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/opt/bitnami/python/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [Errno 104] Connection reset by peer
2025-05-08 13:26:36,358 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
2025-05-08 13:26:36,361 - INFO - Closing down clientserver connection
2025-05-08 13:26:36,361 - INFO - Closing down clientserver connection
2025-05-08 13:26:36,363 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 13:26:36,362 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/opt/bitnami/python/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 13:26:36,366 - INFO - Closing down clientserver connection
2025-05-08 13:26:36,367 - INFO - Closing down clientserver connection
2025-05-08 13:26:36,368 - ERROR - Error in stream_video_interactions.py: An error occurred while calling o149.withColumn
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 207, in <module>
    cleaned_df = cleaned_df.withColumn(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py", line 4789, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 169, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o149.withColumn
2025-05-08 13:27:41,786 - INFO - Starting stream_video_interactions.py
2025-05-08 13:27:41,795 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:27:41,810 - INFO - Private key loaded successfully
2025-05-08 13:27:41,811 - INFO - Snowflake configurations loaded
2025-05-08 13:27:41,861 - INFO - AWS configurations loaded
2025-05-08 13:27:55,446 - INFO - Spark session initialized
2025-05-08 13:27:55,450 - INFO - Schema defined
2025-05-08 13:28:19,144 - INFO - Kafka stream initialized
2025-05-08 13:28:22,241 - INFO - JSON parsing completed
2025-05-08 13:28:40,117 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:28:40,644 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:28:40,695 - INFO - Closing down clientserver connection
2025-05-08 13:31:10,557 - INFO - Starting stream_video_interactions.py
2025-05-08 13:31:10,563 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:31:10,569 - INFO - Private key loaded successfully
2025-05-08 13:31:10,570 - INFO - Snowflake configurations loaded
2025-05-08 13:31:10,576 - INFO - AWS configurations loaded
2025-05-08 13:31:24,028 - INFO - Spark session initialized
2025-05-08 13:31:24,035 - INFO - Schema defined
2025-05-08 13:31:45,320 - INFO - Kafka stream initialized
2025-05-08 13:31:47,856 - INFO - JSON parsing completed
2025-05-08 13:32:04,968 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:32:05,441 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:32:05,517 - INFO - Closing down clientserver connection
2025-05-08 13:36:16,459 - INFO - Starting stream_video_interactions.py
2025-05-08 13:36:16,465 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:36:16,472 - INFO - Private key loaded successfully
2025-05-08 13:36:16,473 - INFO - Snowflake configurations loaded
2025-05-08 13:36:16,479 - INFO - AWS configurations loaded
2025-05-08 13:36:30,122 - INFO - Spark session initialized
2025-05-08 13:36:30,123 - INFO - Schema defined
2025-05-08 13:36:51,202 - INFO - Kafka stream initialized
2025-05-08 13:36:54,375 - INFO - JSON parsing completed
2025-05-08 13:37:11,420 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:37:11,893 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:37:11,941 - INFO - Closing down clientserver connection
2025-05-08 13:42:35,138 - INFO - Starting stream_video_interactions.py
2025-05-08 13:42:35,143 - INFO - Attempting to load private key from: /app/config/rsa_key.pem
2025-05-08 13:42:35,151 - INFO - Private key loaded successfully
2025-05-08 13:42:35,152 - INFO - Snowflake configurations loaded
2025-05-08 13:42:35,157 - INFO - AWS configurations loaded
2025-05-08 13:42:48,241 - INFO - Spark session initialized
2025-05-08 13:42:48,244 - INFO - Schema defined
2025-05-08 13:43:11,588 - INFO - Kafka stream initialized
2025-05-08 13:43:14,981 - INFO - JSON parsing completed
2025-05-08 13:43:31,134 - INFO - Writing DataFrame to Snowflake table DIM_TIME
2025-05-08 13:43:31,665 - ERROR - Error in stream_video_interactions.py: Input PEM private key is invalid
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 462, in <module>
    write_to_snowflake(time_df, "DIM_TIME")
  File "/app/scripts/stream_video_interactions.py", line 453, in write_to_snowflake
    dataframe.writeStream \
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/readwriter.py", line 1385, in start
    return self._sq(self._jwrite.start())
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.IllegalArgumentException: Input PEM private key is invalid
2025-05-08 13:43:31,710 - INFO - Closing down clientserver connection
2025-05-08 13:47:21,258 - INFO - Starting stream_video_interactions.py
2025-05-08 13:47:21,264 - INFO - Attempting to load private key from: /app/config/rsa_key.der
2025-05-08 13:47:21,273 - ERROR - Failed to read private key file: 'utf-8' codec can't decode byte 0x82 in position 1: invalid start byte
2025-05-08 13:47:21,273 - ERROR - Error in stream_video_interactions.py: 'utf-8' codec can't decode byte 0x82 in position 1: invalid start byte
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 43, in <module>
    private_key = key_file.read()
  File "/opt/bitnami/python/lib/python3.9/codecs.py", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x82 in position 1: invalid start byte
2025-05-08 14:18:33,052 - INFO - Starting stream_video_interactions.py
2025-05-08 14:18:33,119 - INFO - Attempting to load private key from: /app/config/rsa_key.der
2025-05-08 14:18:33,129 - ERROR - Failed to read private key file: 'utf-8' codec can't decode byte 0x82 in position 1: invalid start byte
2025-05-08 14:18:33,130 - ERROR - Error in stream_video_interactions.py: 'utf-8' codec can't decode byte 0x82 in position 1: invalid start byte
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 43, in <module>
    private_key = key_file.read()
  File "/opt/bitnami/python/lib/python3.9/codecs.py", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x82 in position 1: invalid start byte
2025-05-08 14:52:31,283 - INFO - Starting stream_video_interactions.py
2025-05-08 14:52:31,291 - INFO - AWS configurations loaded
2025-05-08 14:52:34,727 - INFO - Spark session initialized
2025-05-08 14:52:34,728 - INFO - Schema defined
2025-05-08 14:52:40,113 - INFO - Kafka stream initialized
2025-05-08 14:52:40,870 - INFO - JSON parsing completed
2025-05-08 14:52:42,372 - INFO - Writing cleaned data to s3a://datastreaming-analytics-1/staging/video_interactions
2025-05-08 20:00:33,265 - INFO - Starting stream_video_interactions.py
2025-05-08 20:00:33,331 - INFO - AWS configurations loaded
2025-05-08 20:00:49,253 - INFO - Spark session initialized
2025-05-08 20:00:49,256 - INFO - Schema defined
2025-05-08 20:01:14,679 - INFO - Kafka stream initialized
2025-05-08 20:01:20,558 - INFO - JSON parsing completed
2025-05-08 20:01:28,114 - INFO - Writing cleaned data to s3a://datastreaming-analytics-1/staging/video_interactions
2025-05-08 20:01:51,221 - ERROR - Error in stream_video_interactions.py: [STREAM_FAILED] Query [id = d61e0a96-a6d0-49c4-9b57-5f60d4d2a3ff, runId = 5f325c93-4d45-4964-ac70-1fa4f117cf15] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 247, in <module>
    query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 201, in awaitTermination
    return self._jsq.awaitTermination()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = d61e0a96-a6d0-49c4-9b57-5f60d4d2a3ff, runId = 5f325c93-4d45-4964-ac70-1fa4f117cf15] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2025-05-08 20:01:51,657 - INFO - Spark session stopped
2025-05-08 20:01:51,676 - INFO - Closing down clientserver connection
2025-05-08 20:03:35,979 - INFO - Starting stream_video_interactions.py
2025-05-08 20:03:35,986 - INFO - AWS configurations loaded
2025-05-08 20:03:46,050 - INFO - Spark session initialized
2025-05-08 20:03:46,053 - INFO - Schema defined
2025-05-08 20:04:06,315 - INFO - Kafka stream initialized
2025-05-08 20:04:09,395 - INFO - JSON parsing completed
2025-05-08 20:04:17,008 - INFO - Writing cleaned data to s3a://datastreaming-analytics-1/staging/video_interactions
2025-05-08 20:05:15,209 - ERROR - Error in stream_video_interactions.py: [STREAM_FAILED] Query [id = d61e0a96-a6d0-49c4-9b57-5f60d4d2a3ff, runId = 0e445195-cbb2-4797-a403-6b103f2b92ef] terminated with exception: Unable to find batch s3a://datastreaming-analytics-1/staging/video_interactions/_spark_metadata/0.
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 247, in <module>
    query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 201, in awaitTermination
    return self._jsq.awaitTermination()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = d61e0a96-a6d0-49c4-9b57-5f60d4d2a3ff, runId = 0e445195-cbb2-4797-a403-6b103f2b92ef] terminated with exception: Unable to find batch s3a://datastreaming-analytics-1/staging/video_interactions/_spark_metadata/0.
2025-05-08 20:05:15,596 - INFO - Spark session stopped
2025-05-08 20:05:15,615 - INFO - Closing down clientserver connection
2025-05-08 20:19:37,248 - INFO - Starting stream_video_interactions.py
2025-05-08 20:19:37,255 - INFO - AWS configurations loaded
2025-05-08 20:19:42,325 - INFO - Spark session initialized
2025-05-08 20:19:42,327 - INFO - Schema defined
2025-05-08 20:19:48,066 - INFO - Kafka stream initialized
2025-05-08 20:19:49,032 - INFO - JSON parsing completed
2025-05-08 20:19:51,650 - INFO - Writing cleaned data to s3a://datastreaming-analytics-1/staging/video_interactions
2025-05-08 20:19:56,413 - INFO - Streaming query started: None, ID: 9d9eda95-8298-4e3d-8575-e069bb453ddf
2025-05-08 20:42:20,424 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
RuntimeError: reentrant call inside <_io.BufferedReader name=4>
2025-05-08 20:42:20,431 - INFO - Closing down clientserver connection
2025-05-08 20:42:20,432 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
RuntimeError: reentrant call inside <_io.BufferedReader name=4>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 20:42:20,439 - INFO - Error while receiving.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/opt/bitnami/python/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 377, in signal_handler
    self.cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 2255, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 169, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o25.sc
2025-05-08 20:42:20,443 - INFO - Closing down clientserver connection
2025-05-08 20:42:20,446 - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/opt/bitnami/python/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 377, in signal_handler
    self.cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 2255, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 169, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o25.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-05-08 20:42:20,448 - INFO - Closing down clientserver connection
2025-05-08 20:42:20,449 - ERROR - Error in stream_video_interactions.py: An error occurred while calling o376.awaitTermination
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 274, in <module>
    query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 201, in awaitTermination
    return self._jsq.awaitTermination()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 169, in deco
    return f(*a, **kw)
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o376.awaitTermination
2025-05-09 01:04:38,147 - INFO - Starting stream_video_interactions.py
2025-05-09 01:04:38,151 - INFO - AWS configurations loaded
2025-05-09 01:04:46,762 - INFO - Spark session initialized
2025-05-09 01:04:46,763 - INFO - Schema defined
2025-05-09 01:04:59,245 - INFO - Kafka stream initialized
2025-05-09 01:05:02,106 - INFO - JSON parsing completed
2025-05-09 01:05:08,742 - INFO - Writing cleaned data to s3a://datastreaming-analytics-1/staging/video_interactions
2025-05-09 01:05:16,122 - INFO - Streaming query started: None, ID: 9d9eda95-8298-4e3d-8575-e069bb453ddf
2025-05-09 01:05:23,130 - ERROR - Error in stream_video_interactions.py: [STREAM_FAILED] Query [id = 9d9eda95-8298-4e3d-8575-e069bb453ddf, runId = 5e7b8c07-3921-407e-87f6-19431405142c] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 274, in <module>
    query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 201, in awaitTermination
    return self._jsq.awaitTermination()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 9d9eda95-8298-4e3d-8575-e069bb453ddf, runId = 5e7b8c07-3921-407e-87f6-19431405142c] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2025-05-09 01:05:23,721 - INFO - Spark session stopped
2025-05-09 01:05:23,810 - INFO - Closing down clientserver connection
2025-05-09 13:48:56,713 - INFO - Starting stream_video_interactions.py
2025-05-09 13:48:56,730 - INFO - AWS configurations loaded
2025-05-09 13:49:01,598 - INFO - Spark session initialized
2025-05-09 13:49:01,599 - INFO - Schema defined
2025-05-09 13:49:08,940 - INFO - Kafka stream initialized
2025-05-09 13:49:10,102 - INFO - JSON parsing completed
2025-05-09 13:49:13,207 - INFO - Writing cleaned data to s3a://datastreaming-analytics-1/staging/video_interactions
2025-05-09 13:49:16,376 - INFO - Streaming query started: None, ID: 9d9eda95-8298-4e3d-8575-e069bb453ddf
2025-05-09 13:50:39,175 - ERROR - Error in stream_video_interactions.py: [STREAM_FAILED] Query [id = 9d9eda95-8298-4e3d-8575-e069bb453ddf, runId = d23897dc-02c8-48e5-8bcd-4088a4f13b8b] terminated with exception: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1) (54fce359733d executor driver): java.lang.IllegalStateException: Error reading delta file file:/app/checkpoints/stream_video_clean/state/0/0/1.delta of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/app/checkpoints/stream_video_clean/state/0/0]: file:/app/checkpoints/stream_video_clean/state/0/0/1.delta does not exist
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:461)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$4(HDFSBackedStateStoreProvider.scala:417)
	at scala.runtime.java8.JFunction1$mcVJ$sp.apply(JFunction1$mcVJ$sp.java:23)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:75)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$2(HDFSBackedStateStoreProvider.scala:416)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:388)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getLoadedMapForStore(HDFSBackedStateStoreProvider.scala:224)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:208)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:500)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:125)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:139)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.io.FileNotFoundException: File file:/app/checkpoints/stream_video_clean/state/0/0/1.delta does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:274)
	at org.apache.hadoop.fs.DelegateToFileSystem.open(DelegateToFileSystem.java:192)
	at org.apache.hadoop.fs.AbstractFileSystem.open(AbstractFileSystem.java:670)
	at org.apache.hadoop.fs.FilterFs.open(FilterFs.java:227)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:874)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:870)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.open(FileContext.java:876)
	at org.apache.spark.sql.execution.streaming.AbstractFileContextBasedCheckpointFileManager.open(CheckpointFileManager.scala:328)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:457)
	... 24 more

Driver stacktrace:
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 274, in <module>
    query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 201, in awaitTermination
    return self._jsq.awaitTermination()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 9d9eda95-8298-4e3d-8575-e069bb453ddf, runId = d23897dc-02c8-48e5-8bcd-4088a4f13b8b] terminated with exception: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1) (54fce359733d executor driver): java.lang.IllegalStateException: Error reading delta file file:/app/checkpoints/stream_video_clean/state/0/0/1.delta of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/app/checkpoints/stream_video_clean/state/0/0]: file:/app/checkpoints/stream_video_clean/state/0/0/1.delta does not exist
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:461)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$4(HDFSBackedStateStoreProvider.scala:417)
	at scala.runtime.java8.JFunction1$mcVJ$sp.apply(JFunction1$mcVJ$sp.java:23)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:75)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$2(HDFSBackedStateStoreProvider.scala:416)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:388)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getLoadedMapForStore(HDFSBackedStateStoreProvider.scala:224)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:208)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:500)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:125)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:139)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.io.FileNotFoundException: File file:/app/checkpoints/stream_video_clean/state/0/0/1.delta does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:274)
	at org.apache.hadoop.fs.DelegateToFileSystem.open(DelegateToFileSystem.java:192)
	at org.apache.hadoop.fs.AbstractFileSystem.open(AbstractFileSystem.java:670)
	at org.apache.hadoop.fs.FilterFs.open(FilterFs.java:227)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:874)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:870)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.open(FileContext.java:876)
	at org.apache.spark.sql.execution.streaming.AbstractFileContextBasedCheckpointFileManager.open(CheckpointFileManager.scala:328)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:457)
	... 24 more

Driver stacktrace:
2025-05-09 13:50:39,753 - INFO - Spark session stopped
2025-05-09 13:50:39,781 - INFO - Closing down clientserver connection
2025-05-09 14:10:43,835 - INFO - Starting stream_video_interactions.py
2025-05-09 14:10:43,852 - INFO - AWS configurations loaded
2025-05-09 14:10:54,736 - INFO - Spark session initialized
2025-05-09 14:10:54,751 - INFO - Schema defined
2025-05-09 14:11:09,710 - INFO - Kafka stream initialized
2025-05-09 14:11:12,934 - INFO - JSON parsing completed
2025-05-09 14:11:21,910 - INFO - Writing cleaned data to s3a://datastreaming-analytics-1/staging/video_interactions
2025-05-09 14:11:36,076 - INFO - Streaming query started: None, ID: 9d9eda95-8298-4e3d-8575-e069bb453ddf
2025-05-09 14:12:14,770 - ERROR - Error in stream_video_interactions.py: [STREAM_FAILED] Query [id = 9d9eda95-8298-4e3d-8575-e069bb453ddf, runId = 54525bb6-9a21-4b96-8271-ab438146b9e7] terminated with exception: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1) (a4f4c66b7846 executor driver): java.lang.IllegalStateException: Error reading delta file file:/app/checkpoints/stream_video_clean/state/0/0/1.delta of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/app/checkpoints/stream_video_clean/state/0/0]: file:/app/checkpoints/stream_video_clean/state/0/0/1.delta does not exist
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:461)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$4(HDFSBackedStateStoreProvider.scala:417)
	at scala.runtime.java8.JFunction1$mcVJ$sp.apply(JFunction1$mcVJ$sp.java:23)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:75)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$2(HDFSBackedStateStoreProvider.scala:416)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:388)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getLoadedMapForStore(HDFSBackedStateStoreProvider.scala:224)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:208)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:500)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:125)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:139)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.io.FileNotFoundException: File file:/app/checkpoints/stream_video_clean/state/0/0/1.delta does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:274)
	at org.apache.hadoop.fs.DelegateToFileSystem.open(DelegateToFileSystem.java:192)
	at org.apache.hadoop.fs.AbstractFileSystem.open(AbstractFileSystem.java:670)
	at org.apache.hadoop.fs.FilterFs.open(FilterFs.java:227)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:874)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:870)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.open(FileContext.java:876)
	at org.apache.spark.sql.execution.streaming.AbstractFileContextBasedCheckpointFileManager.open(CheckpointFileManager.scala:328)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:457)
	... 24 more

Driver stacktrace:
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 274, in <module>
    query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 201, in awaitTermination
    return self._jsq.awaitTermination()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 9d9eda95-8298-4e3d-8575-e069bb453ddf, runId = 54525bb6-9a21-4b96-8271-ab438146b9e7] terminated with exception: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1) (a4f4c66b7846 executor driver): java.lang.IllegalStateException: Error reading delta file file:/app/checkpoints/stream_video_clean/state/0/0/1.delta of HDFSStateStoreProvider[id = (op=0,part=0),dir = file:/app/checkpoints/stream_video_clean/state/0/0]: file:/app/checkpoints/stream_video_clean/state/0/0/1.delta does not exist
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:461)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$4(HDFSBackedStateStoreProvider.scala:417)
	at scala.runtime.java8.JFunction1$mcVJ$sp.apply(JFunction1$mcVJ$sp.java:23)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:75)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.$anonfun$loadMap$2(HDFSBackedStateStoreProvider.scala:416)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:640)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.loadMap(HDFSBackedStateStoreProvider.scala:388)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getLoadedMapForStore(HDFSBackedStateStoreProvider.scala:224)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.getStore(HDFSBackedStateStoreProvider.scala:208)
	at org.apache.spark.sql.execution.streaming.state.StateStore$.get(StateStore.scala:500)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:125)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:139)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.io.FileNotFoundException: File file:/app/checkpoints/stream_video_clean/state/0/0/1.delta does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)
	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:274)
	at org.apache.hadoop.fs.DelegateToFileSystem.open(DelegateToFileSystem.java:192)
	at org.apache.hadoop.fs.AbstractFileSystem.open(AbstractFileSystem.java:670)
	at org.apache.hadoop.fs.FilterFs.open(FilterFs.java:227)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:874)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:870)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.open(FileContext.java:876)
	at org.apache.spark.sql.execution.streaming.AbstractFileContextBasedCheckpointFileManager.open(CheckpointFileManager.scala:328)
	at org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider.updateFromDeltaFile(HDFSBackedStateStoreProvider.scala:457)
	... 24 more

Driver stacktrace:
2025-05-09 14:12:15,569 - INFO - Spark session stopped
2025-05-09 14:12:15,654 - INFO - Closing down clientserver connection
2025-05-09 15:01:23,815 - INFO - Starting stream_video_interactions.py
2025-05-09 15:01:23,822 - INFO - AWS configurations loaded
2025-05-09 15:01:32,760 - INFO - Spark session initialized
2025-05-09 15:01:32,761 - INFO - Schema defined
2025-05-09 15:01:44,645 - INFO - Kafka stream initialized
2025-05-09 15:01:47,117 - INFO - JSON parsing completed
2025-05-09 15:01:52,960 - INFO - Writing cleaned data to s3a://datastreaming-analytics-1/staging/video_interactions
2025-05-09 15:01:59,104 - INFO - Streaming query started: None, ID: 73f9b9e4-7dd6-4c98-9520-029ceb4304d9
2025-05-09 15:02:03,565 - ERROR - Error in stream_video_interactions.py: [STREAM_FAILED] Query [id = 73f9b9e4-7dd6-4c98-9520-029ceb4304d9, runId = 28f95530-1fbc-43c8-9ac9-ab5e43da0dc3] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 274, in <module>
    query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 201, in awaitTermination
    return self._jsq.awaitTermination()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 73f9b9e4-7dd6-4c98-9520-029ceb4304d9, runId = 28f95530-1fbc-43c8-9ac9-ab5e43da0dc3] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2025-05-09 15:02:04,293 - INFO - Spark session stopped
2025-05-09 15:02:04,358 - INFO - Closing down clientserver connection
2025-05-09 15:56:16,733 - INFO - Starting stream_video_interactions.py
2025-05-09 15:56:16,741 - INFO - AWS configurations loaded
2025-05-09 15:56:29,113 - INFO - Spark session initialized
2025-05-09 15:56:29,114 - INFO - Schema defined
2025-05-09 15:56:45,210 - INFO - Kafka stream initialized
2025-05-09 15:56:48,524 - INFO - JSON parsing completed
2025-05-09 15:56:57,525 - INFO - Writing cleaned data to s3a://datastreaming-analytics-1/staging/video_interactions
2025-05-09 15:57:06,735 - INFO - Streaming query started: None, ID: 73f9b9e4-7dd6-4c98-9520-029ceb4304d9
2025-05-09 15:57:12,949 - ERROR - Error in stream_video_interactions.py: [STREAM_FAILED] Query [id = 73f9b9e4-7dd6-4c98-9520-029ceb4304d9, runId = 794a3284-780b-4eac-a638-c59200e36b36] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
Traceback (most recent call last):
  File "/app/scripts/stream_video_interactions.py", line 274, in <module>
    query.awaitTermination()
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 201, in awaitTermination
    return self._jsq.awaitTermination()
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 175, in deco
    raise converted from None
pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 73f9b9e4-7dd6-4c98-9520-029ceb4304d9, runId = 794a3284-780b-4eac-a638-c59200e36b36] terminated with exception: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
2025-05-09 15:57:13,817 - INFO - Spark session stopped
2025-05-09 15:57:13,887 - INFO - Closing down clientserver connection
